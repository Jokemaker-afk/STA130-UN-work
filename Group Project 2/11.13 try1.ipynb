{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "596f706f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sowc_demographics__population-thousands-2021_total</th>\n",
       "      <th>sowc_demographics__population-thousands-2021_under-18</th>\n",
       "      <th>sowc_demographics__population-thousands-2021_under-5</th>\n",
       "      <th>sowc_demographics__annual-population-growth-rate_2000-2020</th>\n",
       "      <th>sowc_demographics__annual-population-growth-rate_2020-2030-a</th>\n",
       "      <th>sowc_demographics__annual-number-of-births-thousands-2021_2020-2030-a</th>\n",
       "      <th>sowc_demographics__total-fertility-live-births-per-woman-2021_2020-2030-a</th>\n",
       "      <th>sowc_demographics__life-expectancy-at-birth-years_1970</th>\n",
       "      <th>sowc_demographics__life-expectancy-at-birth-years_2000-0</th>\n",
       "      <th>...</th>\n",
       "      <th>fsi_e3:_human_flight_and_brain_drain</th>\n",
       "      <th>fsi_e2:_economic_inequality</th>\n",
       "      <th>fsi_e1:_economy</th>\n",
       "      <th>fsi_p1:_state_legitimacy</th>\n",
       "      <th>fsi_p2:_public_services</th>\n",
       "      <th>fsi_p3:_human_rights</th>\n",
       "      <th>fsi_c1:_security_apparatus</th>\n",
       "      <th>fsi_c2:_factionalized_elites</th>\n",
       "      <th>fsi_x1:_external_intervention</th>\n",
       "      <th>fsi_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40099.4620</td>\n",
       "      <td>20297.8860</td>\n",
       "      <td>6490.5540</td>\n",
       "      <td>3.286824</td>\n",
       "      <td>2.325169</td>\n",
       "      <td>1440.941</td>\n",
       "      <td>4.6434</td>\n",
       "      <td>37.4178</td>\n",
       "      <td>55.2978</td>\n",
       "      <td>...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Alert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2854.7100</td>\n",
       "      <td>574.3875</td>\n",
       "      <td>141.3930</td>\n",
       "      <td>0.496681</td>\n",
       "      <td>0.248324</td>\n",
       "      <td>29.289</td>\n",
       "      <td>1.3897</td>\n",
       "      <td>64.8239</td>\n",
       "      <td>75.4043</td>\n",
       "      <td>...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>Stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>44177.9685</td>\n",
       "      <td>15526.2050</td>\n",
       "      <td>4870.8425</td>\n",
       "      <td>1.642661</td>\n",
       "      <td>1.237367</td>\n",
       "      <td>950.888</td>\n",
       "      <td>2.8886</td>\n",
       "      <td>43.1597</td>\n",
       "      <td>70.4779</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>79.0340</td>\n",
       "      <td>12.7765</td>\n",
       "      <td>2.5385</td>\n",
       "      <td>0.770116</td>\n",
       "      <td>0.437249</td>\n",
       "      <td>0.567</td>\n",
       "      <td>1.1254</td>\n",
       "      <td>74.2557</td>\n",
       "      <td>80.9193</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>34503.7735</td>\n",
       "      <td>17832.9760</td>\n",
       "      <td>5983.4065</td>\n",
       "      <td>3.392806</td>\n",
       "      <td>2.684447</td>\n",
       "      <td>1338.792</td>\n",
       "      <td>5.3044</td>\n",
       "      <td>40.1904</td>\n",
       "      <td>46.0236</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218 rows × 1332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  sowc_demographics__population-thousands-2021_total  \\\n",
       "0             0                                         40099.4620    \n",
       "1             1                                          2854.7100    \n",
       "2             2                                         44177.9685    \n",
       "3             3                                            79.0340    \n",
       "4             4                                         34503.7735    \n",
       "..          ...                                                ...    \n",
       "213         213                                                NaN    \n",
       "214         214                                                NaN    \n",
       "215         215                                                NaN    \n",
       "216         216                                                NaN    \n",
       "217         217                                                NaN    \n",
       "\n",
       "     sowc_demographics__population-thousands-2021_under-18  \\\n",
       "0                                           20297.8860       \n",
       "1                                             574.3875       \n",
       "2                                           15526.2050       \n",
       "3                                              12.7765       \n",
       "4                                           17832.9760       \n",
       "..                                                 ...       \n",
       "213                                                NaN       \n",
       "214                                                NaN       \n",
       "215                                                NaN       \n",
       "216                                                NaN       \n",
       "217                                                NaN       \n",
       "\n",
       "     sowc_demographics__population-thousands-2021_under-5  \\\n",
       "0                                            6490.5540      \n",
       "1                                             141.3930      \n",
       "2                                            4870.8425      \n",
       "3                                               2.5385      \n",
       "4                                            5983.4065      \n",
       "..                                                 ...      \n",
       "213                                                NaN      \n",
       "214                                                NaN      \n",
       "215                                                NaN      \n",
       "216                                                NaN      \n",
       "217                                                NaN      \n",
       "\n",
       "     sowc_demographics__annual-population-growth-rate_2000-2020  \\\n",
       "0                                             3.286824            \n",
       "1                                             0.496681            \n",
       "2                                             1.642661            \n",
       "3                                             0.770116            \n",
       "4                                             3.392806            \n",
       "..                                                 ...            \n",
       "213                                                NaN            \n",
       "214                                                NaN            \n",
       "215                                                NaN            \n",
       "216                                                NaN            \n",
       "217                                                NaN            \n",
       "\n",
       "     sowc_demographics__annual-population-growth-rate_2020-2030-a  \\\n",
       "0                                             2.325169              \n",
       "1                                             0.248324              \n",
       "2                                             1.237367              \n",
       "3                                             0.437249              \n",
       "4                                             2.684447              \n",
       "..                                                 ...              \n",
       "213                                                NaN              \n",
       "214                                                NaN              \n",
       "215                                                NaN              \n",
       "216                                                NaN              \n",
       "217                                                NaN              \n",
       "\n",
       "     sowc_demographics__annual-number-of-births-thousands-2021_2020-2030-a  \\\n",
       "0                                             1440.941                       \n",
       "1                                               29.289                       \n",
       "2                                              950.888                       \n",
       "3                                                0.567                       \n",
       "4                                             1338.792                       \n",
       "..                                                 ...                       \n",
       "213                                                NaN                       \n",
       "214                                                NaN                       \n",
       "215                                                NaN                       \n",
       "216                                                NaN                       \n",
       "217                                                NaN                       \n",
       "\n",
       "     sowc_demographics__total-fertility-live-births-per-woman-2021_2020-2030-a  \\\n",
       "0                                               4.6434                           \n",
       "1                                               1.3897                           \n",
       "2                                               2.8886                           \n",
       "3                                               1.1254                           \n",
       "4                                               5.3044                           \n",
       "..                                                 ...                           \n",
       "213                                                NaN                           \n",
       "214                                                NaN                           \n",
       "215                                                NaN                           \n",
       "216                                                NaN                           \n",
       "217                                                NaN                           \n",
       "\n",
       "     sowc_demographics__life-expectancy-at-birth-years_1970  \\\n",
       "0                                              37.4178        \n",
       "1                                              64.8239        \n",
       "2                                              43.1597        \n",
       "3                                              74.2557        \n",
       "4                                              40.1904        \n",
       "..                                                 ...        \n",
       "213                                                NaN        \n",
       "214                                                NaN        \n",
       "215                                                NaN        \n",
       "216                                                NaN        \n",
       "217                                                NaN        \n",
       "\n",
       "     sowc_demographics__life-expectancy-at-birth-years_2000-0  ...  \\\n",
       "0                                              55.2978         ...   \n",
       "1                                              75.4043         ...   \n",
       "2                                              70.4779         ...   \n",
       "3                                              80.9193         ...   \n",
       "4                                              46.0236         ...   \n",
       "..                                                 ...         ...   \n",
       "213                                                NaN         ...   \n",
       "214                                                NaN         ...   \n",
       "215                                                NaN         ...   \n",
       "216                                                NaN         ...   \n",
       "217                                                NaN         ...   \n",
       "\n",
       "     fsi_e3:_human_flight_and_brain_drain  fsi_e2:_economic_inequality  \\\n",
       "0                                     8.5                          8.2   \n",
       "1                                     8.5                          2.9   \n",
       "2                                     5.1                          5.2   \n",
       "3                                     NaN                          NaN   \n",
       "4                                     5.6                          8.8   \n",
       "..                                    ...                          ...   \n",
       "213                                   NaN                          NaN   \n",
       "214                                   NaN                          NaN   \n",
       "215                                   NaN                          NaN   \n",
       "216                                   NaN                          NaN   \n",
       "217                                   NaN                          NaN   \n",
       "\n",
       "     fsi_e1:_economy  fsi_p1:_state_legitimacy  fsi_p2:_public_services  \\\n",
       "0                9.6                       9.4                     10.0   \n",
       "1                6.1                       5.0                      3.8   \n",
       "2                6.2                       7.6                      5.0   \n",
       "3                NaN                       NaN                      NaN   \n",
       "4                8.2                       8.1                      8.8   \n",
       "..               ...                       ...                      ...   \n",
       "213              NaN                       NaN                      NaN   \n",
       "214              NaN                       NaN                      NaN   \n",
       "215              NaN                       NaN                      NaN   \n",
       "216              NaN                       NaN                      NaN   \n",
       "217              NaN                       NaN                      NaN   \n",
       "\n",
       "     fsi_p3:_human_rights  fsi_c1:_security_apparatus  \\\n",
       "0                     8.7                         9.7   \n",
       "1                     3.6                         4.8   \n",
       "2                     6.9                         5.8   \n",
       "3                     NaN                         NaN   \n",
       "4                     6.3                         6.6   \n",
       "..                    ...                         ...   \n",
       "213                   NaN                         NaN   \n",
       "214                   NaN                         NaN   \n",
       "215                   NaN                         NaN   \n",
       "216                   NaN                         NaN   \n",
       "217                   NaN                         NaN   \n",
       "\n",
       "     fsi_c2:_factionalized_elites  fsi_x1:_external_intervention  fsi_category  \n",
       "0                             8.7                            7.7         Alert  \n",
       "1                             6.2                            5.5        Stable  \n",
       "2                             6.9                            3.1       Warning  \n",
       "3                             NaN                            NaN           NaN  \n",
       "4                             7.2                            4.0       Warning  \n",
       "..                            ...                            ...           ...  \n",
       "213                           NaN                            NaN           NaN  \n",
       "214                           NaN                            NaN           NaN  \n",
       "215                           NaN                            NaN           NaN  \n",
       "216                           NaN                            NaN           NaN  \n",
       "217                           NaN                            NaN           NaN  \n",
       "\n",
       "[218 rows x 1332 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources = [{'name': 'unicef_sowc',\n",
    "            'url': 'https://data.unicef.org/wp-content/uploads/2023/04/SOWC-2023-Statistical-tables-All-EN.xlsx'}, \n",
    "           {'name': 'undp_hdr',\n",
    "            'url': 'https://hdr.undp.org/sites/default/files/2021-22_HDR/HDR21-22_Composite_indices_complete_time_series.csv'},\n",
    "           {'name': 'worldbank_wbi',\n",
    "            'url': 'https://datacatalogfiles.worldbank.org/ddh-published/0037712/DR0090755/CLASS.xlsx'},\n",
    "           {'name': 'fundforpeace_fsi',\n",
    "            'url': 'https://fragilestatesindex.org/wp-content/uploads/2023/06/FSI-2023-DOWNLOAD.xlsx'}]\n",
    "import pandas as pd\n",
    "df_indicators = pd.read_csv('country_indicators.csv')\n",
    "df_indicators # 218 rows × 1332 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25d6bd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearmonth</th>\n",
       "      <th>fips</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>y_pred_proba_transformer</th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_xgboost</th>\n",
       "      <th>y_pred_proba_xgboost</th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_ffnn</th>\n",
       "      <th>y_pred_proba_ffnn</th>\n",
       "      <th>y_true_ffnn</th>\n",
       "      <th>iso3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202211</td>\n",
       "      <td>FJ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.183897</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.409958</td>\n",
       "      <td>False</td>\n",
       "      <td>FJI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202212</td>\n",
       "      <td>FJ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.267831</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.099643</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.406696</td>\n",
       "      <td>False</td>\n",
       "      <td>FJI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202211</td>\n",
       "      <td>TZ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.482585</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.704086</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.545236</td>\n",
       "      <td>False</td>\n",
       "      <td>TZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202212</td>\n",
       "      <td>TZ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.187792</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.638444</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.534560</td>\n",
       "      <td>False</td>\n",
       "      <td>TZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202301</td>\n",
       "      <td>TZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.539319</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.608380</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.538583</td>\n",
       "      <td>True</td>\n",
       "      <td>TZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>202211</td>\n",
       "      <td>MJ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.182196</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.079453</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.291874</td>\n",
       "      <td>False</td>\n",
       "      <td>MNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>202212</td>\n",
       "      <td>MJ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.203236</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.060189</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.300321</td>\n",
       "      <td>False</td>\n",
       "      <td>MNE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>202211</td>\n",
       "      <td>TD</td>\n",
       "      <td>True</td>\n",
       "      <td>0.527107</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.697625</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.335496</td>\n",
       "      <td>False</td>\n",
       "      <td>TTO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>202212</td>\n",
       "      <td>TD</td>\n",
       "      <td>True</td>\n",
       "      <td>0.555677</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.729246</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>False</td>\n",
       "      <td>TTO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>202301</td>\n",
       "      <td>TD</td>\n",
       "      <td>True</td>\n",
       "      <td>0.565700</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.591722</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.332455</td>\n",
       "      <td>True</td>\n",
       "      <td>TTO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     yearmonth fips  y_pred_transformer  y_pred_proba_transformer  \\\n",
       "0       202211   FJ               False                  0.183897   \n",
       "1       202212   FJ               False                  0.267831   \n",
       "2       202211   TZ               False                  0.482585   \n",
       "3       202212   TZ               False                  0.187792   \n",
       "4       202301   TZ                True                  0.539319   \n",
       "..         ...  ...                 ...                       ...   \n",
       "359     202211   MJ               False                  0.182196   \n",
       "360     202212   MJ               False                  0.203236   \n",
       "361     202211   TD                True                  0.527107   \n",
       "362     202212   TD                True                  0.555677   \n",
       "363     202301   TD                True                  0.565700   \n",
       "\n",
       "     y_true_transformer  y_pred_xgboost  y_pred_proba_xgboost  y_true_xgboost  \\\n",
       "0                 False           False              0.066500           False   \n",
       "1                 False           False              0.099643           False   \n",
       "2                 False            True              0.704086            True   \n",
       "3                 False            True              0.638444            True   \n",
       "4                  True            True              0.608380           False   \n",
       "..                  ...             ...                   ...             ...   \n",
       "359               False           False              0.079453           False   \n",
       "360               False           False              0.060189           False   \n",
       "361               False            True              0.697625            True   \n",
       "362               False            True              0.729246           False   \n",
       "363                True            True              0.591722           False   \n",
       "\n",
       "     y_pred_ffnn  y_pred_proba_ffnn  y_true_ffnn iso3  \n",
       "0          False           0.409958        False  FJI  \n",
       "1          False           0.406696        False  FJI  \n",
       "2           True           0.545236        False  TZA  \n",
       "3           True           0.534560        False  TZA  \n",
       "4           True           0.538583         True  TZA  \n",
       "..           ...                ...          ...  ...  \n",
       "359        False           0.291874        False  MNE  \n",
       "360        False           0.300321        False  MNE  \n",
       "361        False           0.335496        False  TTO  \n",
       "362        False           0.324000        False  TTO  \n",
       "363        False           0.332455         True  TTO  \n",
       "\n",
       "[364 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds = pd.read_csv('test_predictions.csv')\n",
    "df_preds #original test_predictions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "254f77f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a7a1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to find out all Asian country in the 'country_indicators.csv'\n",
    "selected_iso3 = ['CHN','SGP','PAK','PHL','IND','IRN','THA','JPN','PRK','KOR','VNM','SAU','ISR','MDV',\n",
    "                 'IDN','TWN','BGD','ARM','MYS','LKA','AFG','IRQ','ARE','QAT','MMR','LBN','SYR','KHM',\n",
    "                'YEM','UZB','NPL','KWT','OMN','MNG','MAC','BHR','JOR','KGZ','LAO']\n",
    "selected_rows = df_preds[df_preds['iso3'].isin(selected_iso3)]\n",
    "new_df = selected_rows\n",
    "new_df.to_csv('selected_rows.csv',index=False) #out put the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a32f842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearmonth</th>\n",
       "      <th>fips</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>y_pred_proba_transformer</th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_xgboost</th>\n",
       "      <th>y_pred_proba_xgboost</th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_ffnn</th>\n",
       "      <th>y_pred_proba_ffnn</th>\n",
       "      <th>y_true_ffnn</th>\n",
       "      <th>iso3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202211</td>\n",
       "      <td>UZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.535385</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.660580</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.381938</td>\n",
       "      <td>False</td>\n",
       "      <td>UZB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202212</td>\n",
       "      <td>UZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.538211</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.579952</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.364793</td>\n",
       "      <td>False</td>\n",
       "      <td>UZB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202301</td>\n",
       "      <td>UZ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.204810</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.652542</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.364343</td>\n",
       "      <td>False</td>\n",
       "      <td>UZB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202211</td>\n",
       "      <td>ID</td>\n",
       "      <td>False</td>\n",
       "      <td>0.461546</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.480096</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.398537</td>\n",
       "      <td>False</td>\n",
       "      <td>IDN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202212</td>\n",
       "      <td>ID</td>\n",
       "      <td>False</td>\n",
       "      <td>0.346367</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.589674</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>False</td>\n",
       "      <td>IDN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>202211</td>\n",
       "      <td>JA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.163859</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.205914</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.273060</td>\n",
       "      <td>False</td>\n",
       "      <td>JPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>202212</td>\n",
       "      <td>JA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191392</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.209022</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.272838</td>\n",
       "      <td>False</td>\n",
       "      <td>JPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>202211</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.450048</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.495618</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.365198</td>\n",
       "      <td>False</td>\n",
       "      <td>SAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>202212</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.443690</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.428008</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.366745</td>\n",
       "      <td>False</td>\n",
       "      <td>SAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>202301</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.315053</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.618117</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.367574</td>\n",
       "      <td>True</td>\n",
       "      <td>SAU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    yearmonth fips  y_pred_transformer  y_pred_proba_transformer  \\\n",
       "0      202211   UZ                True                  0.535385   \n",
       "1      202212   UZ                True                  0.538211   \n",
       "2      202301   UZ               False                  0.204810   \n",
       "3      202211   ID               False                  0.461546   \n",
       "4      202212   ID               False                  0.346367   \n",
       "..        ...  ...                 ...                       ...   \n",
       "71     202211   JA               False                  0.163859   \n",
       "72     202212   JA               False                  0.191392   \n",
       "73     202211   SA               False                  0.450048   \n",
       "74     202212   SA               False                  0.443690   \n",
       "75     202301   SA               False                  0.315053   \n",
       "\n",
       "    y_true_transformer  y_pred_xgboost  y_pred_proba_xgboost  y_true_xgboost  \\\n",
       "0                False            True              0.660580           False   \n",
       "1                False            True              0.579952           False   \n",
       "2                False            True              0.652542           False   \n",
       "3                False           False              0.480096           False   \n",
       "4                False            True              0.589674            True   \n",
       "..                 ...             ...                   ...             ...   \n",
       "71               False           False              0.205914           False   \n",
       "72               False           False              0.209022           False   \n",
       "73               False           False              0.495618            True   \n",
       "74               False           False              0.428008           False   \n",
       "75                True            True              0.618117           False   \n",
       "\n",
       "    y_pred_ffnn  y_pred_proba_ffnn  y_true_ffnn iso3  \n",
       "0         False           0.381938        False  UZB  \n",
       "1         False           0.364793        False  UZB  \n",
       "2         False           0.364343        False  UZB  \n",
       "3         False           0.398537        False  IDN  \n",
       "4         False           0.395459        False  IDN  \n",
       "..          ...                ...          ...  ...  \n",
       "71        False           0.273060        False  JPN  \n",
       "72        False           0.272838        False  JPN  \n",
       "73        False           0.365198        False  SAU  \n",
       "74        False           0.366745        False  SAU  \n",
       "75        False           0.367574         True  SAU  \n",
       "\n",
       "[76 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.read_csv('selected_rows.csv')\n",
    "df_new \n",
    "# This the the new Dataframe for Asian country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b389de62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = ConfusionMatrixDisplay.from_predictions(df_new.y_true_ffnn, df_new.y_pred_ffnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "174562b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold = 0.3\n",
    "_ = ConfusionMatrixDisplay.from_predictions(df_new.y_true_ffnn, \n",
    "                                            df_new.y_pred_proba_ffnn>threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "785d94c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAGwCAYAAADFZj2cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA280lEQVR4nO3deXxU9dn///cJkEkImSBLNgkQdpRVoICtJqgg0fJjcW1oBQWqLFKkCkWKhJuSCL2hbBIp9k6iwg2oRa0KQougiNQkgCBQBA0YlAgiEAgkJJnz+yM383UMMJnMSTIZXs/H4zxuzvI55xrvKXNxfZZjmKZpCgAA4BoCajoAAADg+0gYAACAWyQMAADALRIGAADgFgkDAABwi4QBAAC4RcIAAADcqlvTAdQGDodD3377rUJDQ2UYRk2HAwDwkGmaOnfunKKjoxUQUHX/Vi4sLNSlS5e8vk9gYKCCgoIsiMg6JAwV8O233yomJqamwwAAeCk3N1fNmjWrknsXFhYqtkUD5Z0o9fpekZGRysnJ8amkgYShAkJDQyVJR3e2lL0BvTjwT7f+ZXRNhwBUmdJLhfrib//l/Pu8Kly6dEl5J0p1NLul7KGV/63IP+dQix5HdOnSJRKG2uZyN4S9QYBXXwLAl9Wx+c5fTEBVqY5u5QahhhqEVv45Dvlm1zcJAwAAFio1HSr14i1NpabDumAsRMIAAICFHDLlUOUzBm/aViXq6wAAwC0qDAAAWMghh7zpVPCuddUhYQAAwEKlpqlSs/LdCt60rUp0SQAAALeoMAAAYCF/HfRIwgAAgIUcMlXqhwkDXRIAAMAtKgwAAFiILgkAAOAWsyQAAMB1iwoDAAAWcvzf5k17X0TCAACAhUq9nCXhTduqRMIAAICFSk15+bZK62KxEmMYAACAW1QYAACwEGMYAACAWw4ZKpXhVXtfRJcEAABwiwoDAAAWcphlmzftfREJAwAAFir1skvCm7ZViS4JAADgFhUGAAAs5K8VBhIGAAAs5DANOUwvZkl40bYq0SUBAADcosIAAICF6JIAAABulSpApV4U8EstjMVKJAwAAFjI9HIMg8kYBgAAUFtRYQAAwEKMYQAAAG6VmgEqNb0Yw+CjS0PTJQEAANwiYQAAwEIOGXIowIut8l0SKSkpMgxDkyZNch4zTVNJSUmKjo5WcHCw4uPjtW/fPo/vTcIAAICFLo9h8GarjMzMTP31r39Vly5dXI7PmzdPCxYs0NKlS5WZmanIyEj1799f586d8+j+JAwAANRy58+f1/Dhw7VixQrdcMMNzuOmaWrhwoWaPn26hg0bpk6dOikjI0MXLlzQqlWrPHoGCQMAABa6POjRm02S8vPzXbaioqKrPnP8+PG69957ddddd7kcz8nJUV5engYMGOA8ZrPZFBcXp+3bt3v0uUgYAACwUNkYBu82SYqJiVFYWJhzS0lJueLzVq9erZ07d17xfF5eniQpIiLC5XhERITzXEUxrRIAAB+Um5sru93u3LfZbFe85ne/+502btyooKCgq97LMFzHRZimWe6YOyQMAABYyOHluyQcKluIwW63uyQMV5Kdna0TJ06oR48ezmOlpaX68MMPtXTpUh08eFBSWaUhKirKec2JEyfKVR3coUsCAAALWTWGoSLuvPNO7d27V7t373ZuPXv21PDhw7V79261atVKkZGR2rRpk7PNpUuXtHXrVt16660efS4qDAAAWOjyegqVb1/xpR5DQ0PVqVMnl2MhISFq3Lix8/ikSZOUnJystm3bqm3btkpOTlb9+vWVmJjoUVwkDAAA+LEpU6bo4sWLGjdunE6fPq3evXtr48aNCg0N9eg+JAwAAFio1DRU6sUrqr1pK0lbtmxx2TcMQ0lJSUpKSvLqviQMAABYqNTLQY+lHnRJVCcGPQIAALeoMAAAYCGHGSCHF6+3dpi+WWEgYQAAwEJ0SQAAgOsWFQYAACzkkHczHRzWhWIpEgYAACzk/cJNvln8982oAACAT6HCAACAhTx9H8SV2vsiEgYAACzkkCGHvBnD4N1Kj1WFhAEAAAv5a4XBN6MCAAA+hQoDAAAW8n7hJt/8tzwJAwAAFnKYhhzerMPg5dsqq4pvpjEAAMCnUGEAAMBCDi+7JHx14SYSBgAALOT92yp9M2HwzagAAIBPocIAAICFSmWo1IvFl7xpW5VIGAAAsBBdEgAA4LpFhQEAAAuVyrtuhVLrQrEUCQMAABby1y4JEgYAACzEy6cAAMB1iwoDAAAWMmXI4cUYBpNplQAA+D+6JAAAwHWLCgMAABby19dbkzAAAGChUi/fVulN26rkm1EBAACfQoUBAAAL0SUBAADccihADi8K+N60rUq+GRUAAPApVBgAALBQqWmo1ItuBW/aViUSBgAALMQYBgAA4Jbp5dsqTVZ6BAAAtRUJAwAAFiqV4fXmidTUVHXp0kV2u112u119+/bV+vXrnedHjhwpwzBctj59+nj8ueiSAADAQg7Tu3EIDtOz65s1a6bnn39ebdq0kSRlZGRo8ODB2rVrl26++WZJ0sCBA5WWluZsExgY6HFcJAwAANRigwYNctmfM2eOUlNTtWPHDmfCYLPZFBkZ6dVzSBjgE1YvCVdaSrSGjD6psf/1Tbnzi6Y003uvNtHjs77RsDEnayBCwDOP9dmpO9t9pdhGZ1RUUke7v4nUwq19dPSHG350laknfp6l+7rulz2oSHuPRyhl02368vtGNRY3vOfwctDj5bb5+fkux202m2w22zXblpaW6rXXXlNBQYH69u3rPL5lyxaFh4erYcOGiouL05w5cxQeHu5RXLVyDEN6eroaNmxY02HAIgd3B+u9Vxsr9qaLVzy/fX2Y/rMzRI0jL1VzZEDl9Yz5Vmt2dtJvXh2mx9cMUt0AUy8++I6C6xU7r3m09279ptdnev6ft2n4y/fpVEF9vfjgP1Q/kO96beaQ4fUmSTExMQoLC3NuKSkpV33m3r171aBBA9lsNj3xxBNat26dbrrpJklSQkKCVq5cqc2bN2v+/PnKzMzUHXfcoaKiIo8+V40mDFcaiGEYhg4fPlyTYaEaXSwI0NwJLTTpz7kKDSstd/774/X0wh9v1NQXjqou9TDUIuNe+6Xe/ryDvvy+kb442UTPvddP0WHn1THicoXM1PCee/TSJz30ry9a6fD3jfXHd+9QUL0S3dPxUI3GDt+Qm5urs2fPOrdp06Zd9dr27dtr9+7d2rFjh8aOHasRI0Zo//79kqSHHnpI9957rzp16qRBgwZp/fr1+uKLL/Tuu+96FE+NVxgGDhyo48ePu2yxsbE1HRaqydJnm+lnd+brltvPlzvncEjzJjbX/WNPqGX7whqIDrBOA1tZ1SC/sKykfGPYOTVtcEGf5DRzXlNcWkfZudHqemNejcQIa1xe6dGbTZJz1sPl7VrdEYGBgWrTpo169uyplJQUde3aVYsWLbritVFRUWrRooUOHfIsMa3xhOHyQIwfb4sWLVLnzp0VEhKimJgYjRs3TufPl/9Bueyzzz5Tv379FBoaKrvdrh49eigrK8t5fvv27br99tsVHBysmJgYTZw4UQUFBdXx8XANW95sqMN7g/XYtONXPL/2hXDVqWNqyKjvqzkywGqmnr7jY+3MjdTh7xtLkpo0uCBJOnWhvsuVpwqC1aTBlbvnUDtcHsPgzeYt0zSv2uVw6tQp5ebmKioqyqN71njCcCUBAQFavHixPv/8c2VkZGjz5s2aMmXKVa8fPny4mjVrpszMTGVnZ+sPf/iD6tWrJ6msX+fuu+/WsGHDtGfPHq1Zs0bbtm3ThAkTrnq/oqIi5efnu2yw1olv6in1uRs1ZclRBQaVn0N0aE+w3nypqZ5e+LUM31wlFaiwaf0/UtvwHzT1H/3LnTN/8vU3jPLHgGt59tln9dFHH+nIkSPau3evpk+fri1btmj48OE6f/68nn76aX3yySc6cuSItmzZokGDBqlJkyYaOnSoR8+p8V7hd955Rw0aNHDuJyQk6LXXXnPux8bGavbs2Ro7dqyWLVt2xXt8/fXXeuaZZ9ShQwdJUtu2bZ3n/vznPysxMVGTJk1ynlu8eLHi4uKUmpqqoKCgcvdLSUnRrFmzrPh4uIrDe+rrzPf1NGFge+cxR6mhvTtC9HZaE42a/q3OfF9Xv+51s8v5FbOi9eaKpnr50/01ETbgsT/c9ZHi2xzRY6uG6MS5//d33ffnyyoLTUIu6PuCEOfxRvUv6lRBcLXHCes45OW7JDxcuOm7777Tb37zGx0/flxhYWHq0qWLNmzYoP79++vixYvau3evXn75ZZ05c0ZRUVHq16+f1qxZo9DQUI+eU+MJQ79+/ZSamurcDwkJ0QcffKDk5GTt379f+fn5KikpUWFhoQoKChQSElLuHpMnT9bo0aP1yiuv6K677tIDDzyg1q1bS5Kys7N1+PBhrVy50nm9aZpyOBzKyclRx44dy91v2rRpmjx5snM/Pz9fMTExVn7s6163285p+eb/uByb/1RzxbQp1IPjT6hReLF6xp9zOf9sYivded9pDXjoh+oMFagkU9Pu2qY72uVo1P/+f/rmrN3l7DdnQ3XyfH31aXlM/znRVJJUN6BUPWK+1aItnq/CB99h/mimQ2Xbe+Jvf/vbVc8FBwfr/fffr3QsP1bjCUNISIhzdSpJOnr0qO655x498cQTmj17tho1aqRt27Zp1KhRKi4uvuI9kpKSlJiYqHfffVfr16/XzJkztXr1ag0dOlQOh0OPP/64Jk6cWK5d8+bNr3i/isx1hXfqN3CoZQfXgYxB9R0KvaHUedzeyHXWRN260g3hJYpp49lUIKAmPNv/IyXcdEiT/p6ggkuBahxSNmbhfFGgikrqSjK0MquLRvXdqa9Ph+nr02Ea1XenCovr6r0Dba99c/g03lZZTbKyslRSUqL58+crIKBsiMXatWvdtmvXrp3atWunp556Sr/61a+UlpamoUOH6pZbbtG+fftckhIAqGoP3bJPkvQ/iW+5HJ/xbj+9/XlZ92nav7vJVrdEzw74qGzhpm/DNXbtL3XhkufL9gJVzecShtatW6ukpERLlizRoEGD9PHHH+vFF1+86vUXL17UM888o/vvv1+xsbE6duyYMjMzdd9990mSpk6dqj59+mj8+PEaM2aMQkJCdODAAW3atElLliypro+FCvjzG9def4NxC6hNus4dW4GrDL34cS+9+HGvKo8H1ceqlR59jc9F1a1bNy1YsEBz585Vp06dtHLlymuublWnTh2dOnVKjzzyiNq1a6cHH3xQCQkJzkGLXbp00datW3Xo0CHddttt6t69u2bMmOHxdBIAACricpeEN5svMkyTCTzu5OfnKywsTKe/aCV7qM/lWIAlus4dV9MhAFWmtKhQB1Kf1dmzZ2W32903qITLvxWDNz6meiGV71YqLriktwb8T5XGWhk+1yUBAEBt5vByloQ3basSCQMAABby11kS1NcBAIBbVBgAALCQv1YYSBgAALCQvyYMdEkAAAC3qDAAAGAhf60wkDAAAGAhU95NjfTVxZFIGAAAsJC/VhgYwwAAANyiwgAAgIX8tcJAwgAAgIX8NWGgSwIAALhFhQEAAAv5a4WBhAEAAAuZpiHTix99b9pWJbokAACAW1QYAACwkEOGVws3edO2KpEwAABgIX8dw0CXBAAAcIsKAwAAFvLXQY8kDAAAWMhfuyRIGAAAsJC/VhgYwwAAANyiwgAAgIVML7skfLXCQMIAAICFTEmm6V17X0SXBAAAcIsKAwAAFnLIkMFKjwAA4FqYJQEAAK5bVBgAALCQwzRksHATAAC4FtP0cpaEj06ToEsCAAC4RYUBAAALMegRAAC4dTlh8GbzRGpqqrp06SK73S673a6+fftq/fr1P4rHVFJSkqKjoxUcHKz4+Hjt27fP489FwgAAgIUuv63Sm80TzZo10/PPP6+srCxlZWXpjjvu0ODBg51Jwbx587RgwQItXbpUmZmZioyMVP/+/XXu3DmPnkPCAACAD8rPz3fZioqKrnjdoEGDdM8996hdu3Zq166d5syZowYNGmjHjh0yTVMLFy7U9OnTNWzYMHXq1EkZGRm6cOGCVq1a5VE8JAwAAFjo8iwJbzZJiomJUVhYmHNLSUlx++zS0lKtXr1aBQUF6tu3r3JycpSXl6cBAwY4r7HZbIqLi9P27ds9+lwMegQAwEJlP/reDHos+7+5ubmy2+3O4zab7apt9u7dq759+6qwsFANGjTQunXrdNNNNzmTgoiICJfrIyIidPToUY/iImEAAMAHXR7EWBHt27fX7t27debMGb3xxhsaMWKEtm7d6jxvGK4JjGma5Y65Q8IAAICFamJaZWBgoNq0aSNJ6tmzpzIzM7Vo0SJNnTpVkpSXl6eoqCjn9SdOnChXdXCHMQwAAFjItGDzOgbTVFFRkWJjYxUZGalNmzY5z126dElbt27Vrbfe6tE9qTAAAFCLPfvss0pISFBMTIzOnTun1atXa8uWLdqwYYMMw9CkSZOUnJystm3bqm3btkpOTlb9+vWVmJjo0XNIGAAAsFB1d0l89913+s1vfqPjx48rLCxMXbp00YYNG9S/f39J0pQpU3Tx4kWNGzdOp0+fVu/evbVx40aFhoZ69BwSBgAArORtv4KHbf/2t79d87xhGEpKSlJSUlLlYxIJAwAA1vKywiDeJQEAAGorKgwAAFjox6s1Vra9LyJhAADAQrzeGgAAXLeoMAAAYCXT8G7goo9WGEgYAACwkL+OYaBLAgAAuEWFAQAAK1Xzwk3VhYQBAAAL+essiQolDIsXL67wDSdOnFjpYAAAgG+qUMLwl7/8pUI3MwyDhAEAAB/tVvBGhRKGnJycqo4DAAC/4K9dEpWeJXHp0iUdPHhQJSUlVsYDAEDtZlqw+SCPE4YLFy5o1KhRql+/vm6++WZ9/fXXksrGLjz//POWBwgAAGqexwnDtGnT9Nlnn2nLli0KCgpyHr/rrru0Zs0aS4MDAKD2MSzYfI/H0yrffPNNrVmzRn369JFh/L8PddNNN+nLL7+0NDgAAGodP12HweMKw8mTJxUeHl7ueEFBgUsCAQAA/IfHCUOvXr307rvvOvcvJwkrVqxQ3759rYsMAIDayE8HPXrcJZGSkqKBAwdq//79Kikp0aJFi7Rv3z598skn2rp1a1XECABA7eGnb6v0uMJw66236uOPP9aFCxfUunVrbdy4UREREfrkk0/Uo0ePqogRAADUsEq9S6Jz587KyMiwOhYAAGo9f329daUShtLSUq1bt04HDhyQYRjq2LGjBg8erLp1eZcVAOA656ezJDz+hf/88881ePBg5eXlqX379pKkL774Qk2bNtXbb7+tzp07Wx4kAACoWR6PYRg9erRuvvlmHTt2TDt37tTOnTuVm5urLl266Le//W1VxAgAQO1xedCjN5sP8rjC8NlnnykrK0s33HCD89gNN9ygOXPmqFevXpYGBwBAbWOYZZs37X2RxxWG9u3b67vvvit3/MSJE2rTpo0lQQEAUGv56ToMFUoY8vPznVtycrImTpyo119/XceOHdOxY8f0+uuva9KkSZo7d25VxwsAAGpAhbokGjZs6LLss2maevDBB53HzP+bAzJo0CCVlpZWQZgAANQSfrpwU4UShg8++KCq4wAAwD9cz9Mq4+LiqjoOAADgwyq90tKFCxf09ddf69KlSy7Hu3Tp4nVQAADUWtdzheHHTp48qUcffVTr16+/4nnGMAAArmt+mjB4PK1y0qRJOn36tHbs2KHg4GBt2LBBGRkZatu2rd5+++2qiBEAANQwjysMmzdv1ltvvaVevXopICBALVq0UP/+/WW325WSkqJ77723KuIEAKB28NNZEh5XGAoKChQeHi5JatSokU6ePCmp7A2WO3futDY6AABqmcsrPXqz+aJKrfR48OBBSVK3bt20fPlyffPNN3rxxRcVFRVleYAAAKDmVWoMw/HjxyVJM2fO1IYNG9S8eXMtXrxYycnJlgcIAECtUs1LQ6ekpKhXr14KDQ1VeHi4hgwZ4vyH/WUjR46UYRguW58+fTx6jsdjGIYPH+78c/fu3XXkyBH95z//UfPmzdWkSRNPbwcAALywdetWjR8/Xr169VJJSYmmT5+uAQMGaP/+/QoJCXFeN3DgQKWlpTn3AwMDPXpOpddhuKx+/fq65ZZbvL0NAAB+wZCXb6v08PoNGza47KelpSk8PFzZ2dm6/fbbncdtNpsiIyMrHVeFEobJkydX+IYLFiyodDAAAKBMfn6+y77NZpPNZnPb7uzZs5LKJib82JYtWxQeHq6GDRsqLi5Oc+bMcU5iqIgKJQy7du2q0M1+/IIqfzS0XWfVNerVdBhAlYjU9poOAagyJWaxDlTXwyyaVhkTE+NyeObMmUpKSrp2U9PU5MmT9Ytf/EKdOnVyHk9ISNADDzygFi1aKCcnRzNmzNAdd9yh7OzsCiUhEi+fAgDAWhat9Jibmyu73e48XJEf9gkTJmjPnj3atm2by/GHHnrI+edOnTqpZ8+eatGihd59910NGzasQmF5PYYBAABYz263uyQM7jz55JN6++239eGHH6pZs2bXvDYqKkotWrTQoUOHKnx/EgYAAKxUze+SME1TTz75pNatW6ctW7YoNjbWbZtTp04pNzfXo/WTPF6HAQAAXF11r/Q4fvx4vfrqq1q1apVCQ0OVl5envLw8Xbx4UZJ0/vx5Pf300/rkk0905MgRbdmyRYMGDVKTJk00dOjQCj+HCgMAALVYamqqJCk+Pt7leFpamkaOHKk6depo7969evnll3XmzBlFRUWpX79+WrNmjUJDQyv8HBIGAACsVANdEtcSHBys999/34uAylSqS+KVV17Rz3/+c0VHR+vo0aOSpIULF+qtt97yOiAAAGq1al4aurp4nDCkpqZq8uTJuueee3TmzBmVlpZKkho2bKiFCxdaHR8AAPABHicMS5Ys0YoVKzR9+nTVqVPHebxnz57au3evpcEBAFDb+OvrrT0ew5CTk6Pu3buXO26z2VRQUGBJUAAA1FoWrfToazyuMMTGxmr37t3ljq9fv1433XSTFTEBAFB7+ekYBo8rDM8884zGjx+vwsJCmaapTz/9VP/7v/+rlJQUvfTSS1URIwAAqGEeJwyPPvqoSkpKNGXKFF24cEGJiYm68cYbtWjRIj388MNVESMAALWGt+MQ/GYMgySNGTNGY8aM0ffffy+Hw+HR6zEBAPBr1bwOQ3XxauGmJk2aWBUHAADwYR4nDLGxsTKMq4/g/Oqrr7wKCACAWs3bqZH+UmGYNGmSy35xcbF27dqlDRs26JlnnrEqLgAAaie6JMr87ne/u+LxF154QVlZWV4HBAAAfI9lr7dOSEjQG2+8YdXtAAConViH4dpef/11NWrUyKrbAQBQKzGt8v90797dZdCjaZrKy8vTyZMntWzZMkuDAwAAvsHjhGHIkCEu+wEBAWratKni4+PVoUMHq+ICAAA+xKOEoaSkRC1bttTdd9+tyMjIqooJAIDay09nSXg06LFu3boaO3asioqKqioeAABqNX99vbXHsyR69+6tXbt2VUUsAADAR3k8hmHcuHH6/e9/r2PHjqlHjx4KCQlxOd+lSxfLggMAoFby0SqBNyqcMDz22GNauHChHnroIUnSxIkTnecMw5BpmjIMQ6WlpdZHCQBAbeGnYxgqnDBkZGTo+eefV05OTlXGAwAAfFCFEwbTLEt5WrRoUWXBAABQ27Fwk3TNt1QCAADRJSFJ7dq1c5s0/PDDD14FBAAAfI9HCcOsWbMUFhZWVbEAAFDr0SUh6eGHH1Z4eHhVxQIAQO3np10SFV64ifELAABcvzyeJQEAAK7BTysMFU4YHA5HVcYBAIBfYAwDAABwz08rDB6/fAoAAFx/qDAAAGAlP60wkDAAAGAhfx3DQJcEAABwiwoDAABWoksCAAC4Q5cEAAC4bpEwAABgJdOCzQMpKSnq1auXQkNDFR4eriFDhujgwYOuIZmmkpKSFB0dreDgYMXHx2vfvn0ePYeEAQAAK1VzwrB161aNHz9eO3bs0KZNm1RSUqIBAwaooKDAec28efO0YMECLV26VJmZmYqMjFT//v117ty5Cj+HMQwAANRiGzZscNlPS0tTeHi4srOzdfvtt8s0TS1cuFDTp0/XsGHDJEkZGRmKiIjQqlWr9Pjjj1foOVQYAACwkGHBJkn5+fkuW1FRUYWef/bsWUlSo0aNJEk5OTnKy8vTgAEDnNfYbDbFxcVp+/btFf5cJAwAAFjJoi6JmJgYhYWFObeUlBT3jzZNTZ48Wb/4xS/UqVMnSVJeXp4kKSIiwuXaiIgI57mKoEsCAAALWTWtMjc3V3a73XncZrO5bTthwgTt2bNH27ZtK39fw3DZN02z3LFrIWEAAMAH2e12l4TBnSeffFJvv/22PvzwQzVr1sx5PDIyUlJZpSEqKsp5/MSJE+WqDtdClwQAAFaq5lkSpmlqwoQJ+vvf/67NmzcrNjbW5XxsbKwiIyO1adMm57FLly5p69atuvXWWyv8HCoMAABYrRpXaxw/frxWrVqlt956S6Ghoc5xCWFhYQoODpZhGJo0aZKSk5PVtm1btW3bVsnJyapfv74SExMr/BwSBgAAarHU1FRJUnx8vMvxtLQ0jRw5UpI0ZcoUXbx4UePGjdPp06fVu3dvbdy4UaGhoRV+DgkDAAAWqu53SZim+waGYSgpKUlJSUmVC0okDAAAWMtP31bJoEcAAOAWFQYAACzkr6+3JmEAAMBKdEkAAIDrFRUGAAAsRJcEAABwz0+7JEgYAACwkp8mDIxhAAAAblFhAADAQoxhAAAA7tElAQAArldUGAAAsJBhmjIq8EKoa7X3RSQMAABYiS4JAABwvaLCAACAhZglAQAA3KNLAgAAXK+oMAAAYCG6JAAAgHt+2iVBwgAAgIX8tcLAGAYAAOAWFQYAAKxElwQAAKgIX+1W8AZdEgAAwC0qDAAAWMk0yzZv2vsgEgYAACzELAkAAHDdosIAAICVmCUBAADcMRxlmzftfRFdEgAAwC0qDPApjSOLNWr6t+rV75wCgx365iubFkyO0eG99Ws6NMASfMevA3RJAFWrQViJFrx1SHu2N9Aff91KZ76vq6iWRSrIr1PToQGW4Dt+ffDXWRI+lTAYhnHN8yNGjFB6enr1BINq9+D4E/r+20DNf6q589h3xwJrMCLAWnzHrxOsw1D1jh8/7vzzmjVr9Nxzz+ngwYPOY8HBwS7XFxcXq169etUWH6pWnwH5yt4SqunLj6hL3wJ9n1dX76Q30fpVjWs6NMASfMdRm/nUoMfIyEjnFhYWJsMwnPuFhYVq2LCh1q5dq/j4eAUFBenVV19VUlKSunXr5nKfhQsXqmXLli7H0tLS1LFjRwUFBalDhw5atmzZVeMoKipSfn6+y4aqF9X8kn75yCl9m2PTs4mxevflJho7+xvddf8PNR0aYAm+49eHy10S3my+yKcqDBUxdepUzZ8/X2lpabLZbPrrX//qts2KFSs0c+ZMLV26VN27d9euXbs0ZswYhYSEaMSIEeWuT0lJ0axZs6oifFyDESAd2hOstOejJElffl5fLdoX6t5HTumfrzeq4egA7/Edv0746aBHn6owVMSkSZM0bNgwxcbGKjo6ukJtZs+erfnz5zvbDRs2TE899ZSWL19+xeunTZums2fPOrfc3FwrPwKu4ocTdXX0iyCXY7mHbAq/8VINRQRYi+84arNalzD07NnTo+tPnjyp3NxcjRo1Sg0aNHBuf/rTn/Tll19esY3NZpPdbnfZUPX2Z4YopnWRy7EbWxXpxDcMCoN/4Dt+fajuLokPP/xQgwYNUnR0tAzD0JtvvulyfuTIkTIMw2Xr06ePx5+r1nVJhISEuOwHBATI/MmI0uLiYuefHY6yJbNWrFih3r17u1xXpw5TmXzJ3//aVH95+5AefvI7ffiPhmrf/YLu+fUPWvhMs5oODbAE3/HrRDXPkigoKFDXrl316KOP6r777rviNQMHDlRaWppzPzDQ8yS11iUMP9W0aVPl5eXJNE3ntMzdu3c7z0dEROjGG2/UV199peHDh9dQlKiILz6rr/8aFatHpx3X8Ke+U15uoF58LlofrLuhpkMDLMF3HJ746YB7m80mm81W7rqEhAQlJCRc8142m02RkZFexVPrE4b4+HidPHlS8+bN0/33368NGzZo/fr1Lt0ISUlJmjhxoux2uxISElRUVKSsrCydPn1akydPrsHo8VP//qdd//4nXUDwX3zH/Z9VCzfFxMS4HJ85c6aSkpIqdc8tW7YoPDxcDRs2VFxcnObMmaPw8HCP7lHrxjD8VMeOHbVs2TK98MIL6tq1qz799FM9/fTTLteMHj1aL730ktLT09W5c2fFxcUpPT1dsbGxNRQ1AMBvmRZsknJzc10G4E+bNq1S4SQkJGjlypXavHmz5s+fr8zMTN1xxx0qKipy3/hHDPOnAwBQTn5+vsLCwhSvwaprsFAUANQ2JWaxtugtnT17tsoGsl/+reg78L9Ut16Q+wZXUVJcqE82PFepWA3D0Lp16zRkyJCrXnP8+HG1aNFCq1ev1rBhwyp871rfJQEAgC/x9XdJREVFqUWLFjp06JBH7UgYAACwksMs27xpX4VOnTql3NxcRUVFedSOhAEAACtV80qP58+f1+HDh537OTk52r17txo1aqRGjRopKSlJ9913n6KionTkyBE9++yzatKkiYYOHerRc0gYAACoxbKystSvXz/n/uXZfyNGjFBqaqr27t2rl19+WWfOnFFUVJT69eunNWvWKDQ01KPnkDAAAGAhQ16OYfDw+vj4+HILGP7Y+++/X/lgfoSEAQAAK1XzSo/VpdavwwAAAKoeFQYAACzk69MqK4uEAQAAK1XzLInqQpcEAABwiwoDAAAWMkxThhcDF71pW5VIGAAAsJLj/zZv2vsguiQAAIBbVBgAALAQXRIAAMA9P50lQcIAAICVWOkRAABcr6gwAABgIVZ6BAAA7tElAQAArldUGAAAsJDhKNu8ae+LSBgAALASXRIAAOB6RYUBAAArsXATAABwx1+XhqZLAgAAuEWFAQAAK/npoEcSBgAArGRK8mZqpG/mCyQMAABYiTEMAADgukWFAQAAK5nycgyDZZFYioQBAAAr+emgR7okAACAW1QYAACwkkOS4WV7H0TCAACAhZglAQAArltUGAAAsJKfDnokYQAAwEp+mjDQJQEAANyiwgAAgJX8tMJAwgAAgJWYVgkAANxhWiUAAPA5H374oQYNGqTo6GgZhqE333zT5bxpmkpKSlJ0dLSCg4MVHx+vffv2efwcEgYAAKx0eQyDN5sHCgoK1LVrVy1duvSK5+fNm6cFCxZo6dKlyszMVGRkpPr3769z58559By6JAAAsJLDlAwvuhUcnrVNSEhQQkLCFc+ZpqmFCxdq+vTpGjZsmCQpIyNDERERWrVqlR5//PEKP4cKAwAAPig/P99lKyoq8vgeOTk5ysvL04ABA5zHbDab4uLitH37do/uRcIAAICVLOqSiImJUVhYmHNLSUnxOJS8vDxJUkREhMvxiIgI57mKoksCAABLebkOg8ra5ubmym63O4/abLZK39EwXOd5mqZZ7pg7JAwAAPggu93ukjBURmRkpKSySkNUVJTz+IkTJ8pVHdyhSwIAACtV8yyJa4mNjVVkZKQ2bdrkPHbp0iVt3bpVt956q0f3osIAAICVHKYudytUvn3FnT9/XocPH3bu5+TkaPfu3WrUqJGaN2+uSZMmKTk5WW3btlXbtm2VnJys+vXrKzEx0aPnkDAAAFCLZWVlqV+/fs79yZMnS5JGjBih9PR0TZkyRRcvXtS4ceN0+vRp9e7dWxs3blRoaKhHzyFhAADASqajbPOmvQfi4+NlXqMbwzAMJSUlKSkpqfIxiYQBAABr8bZKAADgVjWPYaguzJIAAABuUWEAAMBKdEkAAAC3THmZMFgWiaXokgAAAG5RYQAAwEp0SQAAALccDklerMPg8KJtFaJLAgAAuEWFAQAAK9ElAQAA3PLThIEuCQAA4BYVBgAArOSnS0OTMAAAYCHTdMj04m2V3rStSiQMAABYyTS9qxIwhgEAANRWVBgAALCS6eUYBh+tMJAwAABgJYdDMrwYh+CjYxjokgAAAG5RYQAAwEp0SQAAAHdMh0OmF10Svjqtki4JAADgFhUGAACsRJcEAABwy2FKhv8lDHRJAAAAt6gwAABgJdOU5M06DL5ZYSBhAADAQqbDlOlFl4RJwgAAwHXAdMi7CgPTKgEAQC1FhQEAAAvRJQEAANzz0y4JEoYKuJztlajYq7U4AAA1o0TFkqrnX+/e/lZcjtXXkDBUwLlz5yRJ2/ReDUcCAPDGuXPnFBYWViX3DgwMVGRkpLblef9bERkZqcDAQAuiso5h+mpniQ9xOBz69ttvFRoaKsMwajqc60J+fr5iYmKUm5sru91e0+EAluL7Xf1M09S5c+cUHR2tgICqG+9fWFioS5cueX2fwMBABQUFWRCRdagwVEBAQICaNWtW02Fcl+x2O3+hwm/x/a5eVVVZ+LGgoCCf+6G3CtMqAQCAWyQMAADALRIG+CSbzaaZM2fKZrPVdCiA5fh+ozZi0CMAAHCLCgMAAHCLhAEAALhFwgAAANwiYYBPSU9PV8OGDWs6DADAT5AwoEqMHDlShmGU2w4fPlzToQGWutL3/MfbyJEjazpEwBKs9IgqM3DgQKWlpbkca9q0aQ1FA1SN48ePO/+8Zs0aPffcczp48KDzWHBwsMv1xcXFqlevXrXFB1iFCgOqjM1mU2RkpMu2aNEide7cWSEhIYqJidG4ceN0/vz5q97js88+U79+/RQaGiq73a4ePXooKyvLeX779u26/fbbFRwcrJiYGE2cOFEFBQXV8fEASXL5foeFhckwDOd+YWGhGjZsqLVr1yo+Pl5BQUF69dVXlZSUpG7durncZ+HChWrZsqXLsbS0NHXs2FFBQUHq0KGDli1bVn0fDPgJEgZUq4CAAC1evFiff/65MjIytHnzZk2ZMuWq1w8fPlzNmjVTZmamsrOz9Yc//MH5r7O9e/fq7rvv1rBhw7Rnzx6tWbNG27Zt04QJE6rr4wAVMnXqVE2cOFEHDhzQ3XffXaE2K1as0PTp0zVnzhwdOHBAycnJmjFjhjIyMqo4WuDK6JJAlXnnnXfUoEED535CQoJee+01535sbKxmz56tsWPHXvVfTl9//bWeeeYZdejQQZLUtm1b57k///nPSkxM1KRJk5znFi9erLi4OKWmpvrtC2BQ+0yaNEnDhg3zqM3s2bM1f/58Z7vY2Fjt379fy5cv14gRI6oiTOCaSBhQZfr166fU1FTnfkhIiD744AMlJydr//79ys/PV0lJiQoLC1VQUKCQkJBy95g8ebJGjx6tV155RXfddZceeOABtW7dWpKUnZ2tw4cPa+XKlc7rTdOUw+FQTk6OOnbsWPUfEqiAnj17enT9yZMnlZubq1GjRmnMmDHO4yUlJdXyxkXgSkgYUGVCQkLUpk0b5/7Ro0d1zz336IknntDs2bPVqFEjbdu2TaNGjVJxcfEV75GUlKTExES9++67Wr9+vWbOnKnVq1dr6NChcjgcevzxxzVx4sRy7Zo3b15lnwvw1E+T4YCAAP10Vf4f/2/A4XBIKuuW6N27t8t1derUqaIogWsjYUC1ycrKUklJiebPn6+AgLLhM2vXrnXbrl27dmrXrp2eeuop/epXv1JaWpqGDh2qW265Rfv27XNJSoDaoGnTpsrLy5NpmjIMQ5K0e/du5/mIiAjdeOON+uqrrzR8+PAaihJwRcKAatO6dWuVlJRoyZIlGjRokD7++GO9+OKLV73+4sWLeuaZZ3T//fcrNjZWx44dU2Zmpu677z5JZQPJ+vTpo/Hjx2vMmDEKCQnRgQMHtGnTJi1ZsqS6Phbgsfj4eJ08eVLz5s3T/fffrw0bNmj9+vWy2+3Oa5KSkjRx4kTZ7XYlJCSoqKhIWVlZOn36tCZPnlyD0eN6xSwJVJtu3bppwYIFmjt3rjp16qSVK1cqJSXlqtfXqVNHp06d0iOPPKJ27drpwQcfVEJCgmbNmiVJ6tKli7Zu3apDhw7ptttuU/fu3TVjxgxFRUVV10cCKqVjx45atmyZXnjhBXXt2lWffvqpnn76aZdrRo8erZdeeknp6enq3Lmz4uLilJ6ertjY2BqKGtc7Xm8NAADcosIAAADcImEAAABukTAAAAC3SBgAAIBbJAwAAMAtEgYAAOAWCQMAAHCLhAEAALhFwgDUEklJSerWrZtzf+TIkRoyZEi1x3HkyBEZhuHy7oOfatmypRYuXFjhe6anp6thw4Zex2YYht58802v7wOgPBIGwAsjR46UYRgyDEP16tVTq1at9PTTT6ugoKDKn71o0SKlp6dX6NqK/MgDwLXw8inASwMHDlRaWpqKi4v10UcfafTo0SooKFBqamq5a4uLi1WvXj1LnhsWFmbJfQCgIqgwAF6y2WyKjIxUTEyMEhMTNXz4cGdZ/HI3wv/8z/+oVatWstlsMk1TZ8+e1W9/+1uFh4fLbrfrjjvu0GeffeZy3+eff14REREKDQ3VqFGjVFhY6HL+p10SDodDc+fOVZs2bWSz2dS8eXPNmTNHkpwvLOrevbsMw1B8fLyzXVpamjp27KigoCB16NBBy5Ytc3nOp59+qu7duysoKEg9e/bUrl27PP5vtGDBAnXu3FkhISGKiYnRuHHjdP78+XLXvfnmm2rXrp2CgoLUv39/5ebmupz/xz/+oR49eigoKEitWrXSrFmzVFJS4nE8ADxHwgBYLDg4WMXFxc79w4cPa+3atXrjjTecXQL33nuv8vLy9N577yk7O1u33HKL7rzzTv3www+SpLVr12rmzJmaM2eOsrKyFBUVVe6H/KemTZumuXPnasaMGdq/f79WrVqliIgISWU/+pL0z3/+U8ePH9ff//53SdKKFSs0ffp0zZkzRwcOHFBycrJmzJihjIwMSVJBQYF++ctfqn379srOzlZSUlK5typWREBAgBYvXqzPP/9cGRkZ2rx5s6ZMmeJyzYULFzRnzhxlZGTo448/Vn5+vh5++GHn+ffff1+//vWvNXHiRO3fv1/Lly9Xenq6MykCUMVMAJU2YsQIc/Dgwc79f//732bjxo3NBx980DRN05w5c6ZZr14988SJE85r/vWvf5l2u90sLCx0uVfr1q3N5cuXm6Zpmn379jWfeOIJl/O9e/c2u3btesVn5+fnmzabzVyxYsUV48zJyTElmbt27XI5HhMTY65atcrl2OzZs82+ffuapmmay5cvNxs1amQWFBQ4z6empl7xXj/WokUL8y9/+ctVz69du9Zs3Lixcz8tLc2UZO7YscN57MCBA6Yk89///rdpmqZ52223mcnJyS73eeWVV8yoqCjnviRz3bp1V30ugMpjDAPgpXfeeUcNGjRQSUmJiouLNXjwYC1ZssR5vkWLFmratKlzPzs7W+fPn1fjxo1d7nPx4kV9+eWXkqQDBw7oiSeecDnft29fffDBB1eM4cCBAyoqKtKdd95Z4bhPnjyp3NxcjRo1SmPGjHEeLykpcY6POHDggLp27ar69eu7xOGpDz74QMnJydq/f7/y8/NVUlKiwsJCFRQUKCQkRJJUt25d9ezZ09mmQ4cOatiwoQ4cOKCf/exnys7OVmZmpktFobS0VIWFhbpw4YJLjACsR8IAeKlfv35KTU1VvXr1FB0dXW5Q4+UfxMscDoeioqK0ZcuWcveq7NTC4OBgj9s4HA5JZd0SvXv3djlXp04dSZJpmpWK58eOHj2qe+65R0888YRmz56tRo0aadu2bRo1apRL141UNi3ypy4fczgcmjVrloYNG1bumqCgIK/jBHBtJAyAl0JCQtSmTZsKX3/LLbcoLy9PdevWVcuWLa94TceOHbVjxw498sgjzmM7duy46j3btm2r4OBg/etf/9Lo0aPLnQ8MDJRU9i/yyyIiInTjjTfqq6++0vDhw69435tuukmvvPKKLl686ExKrhXHlWRlZamkpETz589XQEDZsKm1a9eWu66kpERZWVn62c9+Jkk6ePCgzpw5ow4dOkgq++928OBBj/5bA7AOCQNQze666y717dtXQ4YM0dy5c9W+fXt9++23eu+99zRkyBD17NlTv/vd7zRixAj17NlTv/jFL7Ry5Urt27dPrVq1uuI9g4KCNHXqVE2ZMkWBgYH6+c9/rpMnT2rfvn0aNWqUwsPDFRwcrA0bNqhZs2YKCgpSWFiYkpKSNHHiRNntdiUkJKioqEhZWVk6ffq0Jk+erMTERE2fPl2jRo3SH//4Rx05ckT//d//7dHnbd26tUpKSrRkyRINGjRIH3/8sV588cVy19WrV09PPvmkFi9erHr16mnChAnq06ePM4F47rnn9Mtf/lIxMTF64IEHFBAQoD179mjv3r3605/+5Pn/IwB4hFkSQDUzDEPvvfeebr/9dj322GNq166dHn74YR05csQ5q+Ghhx7Sc889p6lTp6pHjx46evSoxo4de837zpgxQ7///e/13HPPqWPHjnrooYd04sQJSWXjAxYvXqzly5crOjpagwcPliSNHj1aL730ktLT09W5c2fFxcUpPT3dOQ2zQYMG+sc//qH9+/ere/fumj59uubOnevR5+3WrZsWLFiguXPnqlOnTlq5cqVSUlLKXVe/fn1NnTpViYmJ6tu3r4KDg7V69Wrn+bvvvlvvvPOONm3apF69eqlPnz5asGCBWrRo4VE8ACrHMK3opAQAAH6NCgMAAHCLhAEAALhFwgAAANwiYQAAAG6RMAAAALdIGAAAgFskDAAAwC0SBgAA4BYJAwAAcIuEAQAAuEXCAAAA3Pr/AQQSnJS4kHqHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold = 0.4\n",
    "_ = ConfusionMatrixDisplay.from_predictions(df_new.y_true_ffnn, \n",
    "                                            df_new.y_pred_proba_ffnn>threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14ac1b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAGwCAYAAADFZj2cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAzsElEQVR4nO3deXhU5fn/8c8JyySETBCFhEiAAAmLgKxlqUqoAgKlKHUNrdACRcHGlArUUmT8IYnQiiwKUvyWpAoV1LpWESpIi4gmCIiQUpAIQUlBRAOBLJM5vz8oU8cAk8mcyUyG9+u6znVxlufMPYrmzn0/zzmGaZqmAAAALiEi2AEAAIDQR8IAAAC8ImEAAABekTAAAACvSBgAAIBXJAwAAMArEgYAAOBV/WAHUBe4XC598cUXiomJkWEYwQ4HAOAj0zR16tQpJSQkKCIicL8rl5aWqry83O/7NGzYUJGRkRZEZB0Shmr44osvlJiYGOwwAAB+KiwsVMuWLQNy79LSUiW1bqyiY5V+3ys+Pl4FBQUhlTSQMFRDTEyMJOnQR21kb0wXB+Hp9htuCnYIQMA4XeV691i2+//ngVBeXq6iY5U6tL2N7DE1/1lRfMql1r0+U3l5OQlDXXO+DWFvHOHXXwIglNWPaBjsEICAq422cuMYQ41jav45LoVm65uEAQAAC1WaLlX68ZamStNlXTAWImEAAMBCLplyqeYZgz9jA4n6OgAA8IoKAwAAFnLJJX+aCv6NDhwSBgAALFRpmqo0a95W8GdsINGSAAAAXlFhAADAQuE66ZGEAQAAC7lkqjIMEwZaEgAAwCsqDAAAWIiWBAAA8IpVEgAA4LJFhQEAAAu5/rv5Mz4UkTAAAGChSj9XSfgzNpBIGAAAsFClKT/fVmldLFZiDgMAAPCKCgMAABZiDgMAAPDKJUOVMvwaH4poSQAAAK+oMAAAYCGXeW7zZ3woImEAAMBClX62JPwZG0i0JAAAgFdUGAAAsFC4VhhIGAAAsJDLNOQy/Vgl4cfYQKIlAQAAvKLCAACAhWhJAAAAryoVoUo/CviVFsZiJRIGAAAsZPo5h8FkDgMAAKirqDAAAGAh5jAAAACvKs0IVZp+zGEI0UdD05IAAABeUWEAAMBCLhly+fH7uEuhWWIgYQAAwELhOoeBlgQAAPCKCgMAABbyf9IjLQkAAMLeuTkMfrx8ipYEAACoq6gwAABgIZef75JglQQAAJcB5jAAAACvXIoIy+cwMIcBAIA6zOFwyDAMjy0+Pt593jRNORwOJSQkKCoqSqmpqdqzZ4/Pn0PCAACAhSpNw+/NV9dcc42OHj3q3nbv3u0+N3/+fC1YsEBPPvmkcnNzFR8fr8GDB+vUqVM+fQYtCQAALFTp56THyhq0JOrXr+9RVTjPNE0tXLhQM2fO1OjRoyVJOTk5iouL0+rVqzVp0qRqfwYVBgAAQlBxcbHHVlZWdtFr9+/fr4SEBCUlJemuu+7SwYMHJUkFBQUqKirSkCFD3NfabDYNHDhQW7du9SkeEgYAACzkMiP83iQpMTFRsbGx7i0rK+uCn9e3b1/9+c9/1ttvv60VK1aoqKhIAwYM0IkTJ1RUVCRJiouL8xgTFxfnPlddtCQAALCQVS2JwsJC2e1293GbzXbB64cNG+b+c9euXdW/f3+1a9dOOTk56tevnyTJMDznRZimWeWYN1QYAAAIQXa73WO7WMLwXdHR0eratav279/vntfw3WrCsWPHqlQdvCFhAADAQi75t1LC5efnl5WVKT8/Xy1atFBSUpLi4+O1YcMG9/ny8nJt3rxZAwYM8Om+tCQAALCQ/w9u8m3sgw8+qJEjR6pVq1Y6duyYHn30URUXF2vs2LEyDEMZGRnKzMxUcnKykpOTlZmZqUaNGiktLc2nzyFhAACgDjty5Ijuvvtuffnll2rWrJn69eunbdu2qXXr1pKk6dOn6+zZs5o8ebJOnjypvn37av369YqJifHpc0gYAACwkP/vkvBt7PPPP3/J84ZhyOFwyOFw1DgmiYQBAABLuWTIJd+f1vjt8aGIhAEAAAvVdoWhtoRmVAAAIKRQYQAAwEL+P7gpNH+XJ2EAAMBCLtOQqwZvnPz2+FAUmmkMAAAIKVQYAACwkMvPloQ/D30KJBIGAAAs9O03TtZ0fCgKzagAAEBIocIAAICFKmWo0o+HL/kzNpBIGAAAsBAtCQAAcNmiwgAAgIUq5V9bodK6UCxFwgAAgIXCtSVBwgAAgIV4+RQAALhsUWEAAMBCpgy5/JjDYLKsEgCA8EdLAgAAXLaoMAAAYKFwfb01CQMAABaq9PNtlf6MDaTQjAoAAIQUKgwAAFiIlgQAAPDKpQi5/Cjg+zM2kEIzKgAAEFKoMAAAYKFK01ClH20Ff8YGEgkDAAAWYg4DAADwyvTzbZUmT3oEAAB1FRUGAAAsVClDlX68QMqfsYFEwgAAgIVcpn/zEFymhcFYiJYEAADwigoDgubZP8TruQXxHseuaFah53ftkSQNTeh+wXETfve5bp98PNDhAZb70+ubFZdQWuX4G2sTtWxe5yBEhEBw+Tnp0Z+xgVQnE4bs7GxlZGTo66+/DnYo8FPrDmf12JpP3fsR9f5Xi/vLzk88rs3daNcTv07UdSO+qbX4ACtl/LS/6n3r73jrdqc1d1metvw9/hKjUNe4ZMjlxzwEf8YGUlDTmHHjxskwjCrbgQMHghkWalG9elLT5k731uTKSve5bx9v2typ99+O1bXfP60WrcuDGDFQc8VfN9TJEzb31uf6Y/qiMEq7t18R7NAAr4JeYbj55pu1cuVKj2PNmjULUjSobZ8XNNTdPa5Rg4YudexxRj976OgFE4KTx+vrw3fsenDhoSBECVivfn2XBg0/qleeayOF6G+UqJlwfdJj0BslNptN8fHxHtuiRYvUtWtXRUdHKzExUZMnT9bp06cveo9du3Zp0KBBiomJkd1uV69evZSXl+c+v3XrVt1www2KiopSYmKi0tPTVVJSUhtfD5fQsWeJpi0+rMzVnyrj94U6ebyBfvWjZBV/Va/KtRvWNlVU40pdN5x2BMJDv0HH1LixU39/PSHYocBi5+cw+LOFopCMKiIiQosXL9Ynn3yinJwcbdy4UdOnT7/o9WPGjFHLli2Vm5ur7du36ze/+Y0aNGggSdq9e7eGDh2q0aNH6+OPP9aaNWu0ZcsW3X///Re9X1lZmYqLiz02WK/PD07p+hHfKKlTqXrecFpznj0oSdrwQtMq1779fFP94NaTahgZouuNAB8NGXVEeVuv0ldfRgY7FKBagt6SeOONN9S4cWP3/rBhw/TCCy+495OSkjRnzhzdd999Wrp06QXvcfjwYU2bNk0dO3aUJCUnJ7vP/f73v1daWpoyMjLc5xYvXqyBAwdq2bJlioys+h9rVlaWHnnkESu+HnwQ2cilNh1L9XmBzeP47g+ideTTSP326c+CExhgsWbxZ9X9eyeUOa1HsENBALjk57skQrRFFfSEYdCgQVq2bJl7Pzo6Wps2bVJmZqb27t2r4uJiOZ1OlZaWqqSkRNHR0VXuMXXqVE2YMEHPPvusbrrpJt1+++1q166dJGn79u06cOCAVq1a5b7eNE25XC4VFBSoU6dOVe730EMPaerUqe794uJiJSYmWvm1cQHlZYYKD9jUpa9n++ntv1yp5G5n1O6aqsvRgLpo8I8+1zcnG+rDLVcFOxQEgOnnKgkzRBOGoLckoqOj1b59e/dWXl6u4cOHq0uXLnrppZe0fft2PfXUU5KkioqKC97D4XBoz549GjFihDZu3KjOnTvr5ZdfliS5XC5NmjRJO3fudG+7du3S/v373UnFd9lsNtntdo8N1vvjIwn6+P1oFR1uqH991EiPTmyjM6fqafAdX7mvKTkVoX+8Hqub004EMVLAOoZhavCPPtc7b1wtV2XQ/xeMADj/tkp/tlAU9ArDd+Xl5cnpdOrxxx9XRMS5/5jWrl3rdVxKSopSUlL0q1/9SnfffbdWrlypW2+9VT179tSePXvUvn37QIcOH315tIGyJrdR8Vf1FHulUx17ntHCN/6tuJb/Sww3v3qFZBoadMvJIEYKWKd73xNq3qJU61+9OtihAD4JuYShXbt2cjqdWrJkiUaOHKn33ntPTz/99EWvP3v2rKZNm6bbbrtNSUlJOnLkiHJzc/XjH/9YkjRjxgz169dPU6ZM0cSJExUdHa38/Hxt2LBBS5Ysqa2vhQv47dPel0gO/8kJDf8J1QWEjx3brtKIXkODHQYCKFyf9BhyUXXv3l0LFizQvHnz1KVLF61atUpZWVkXvb5evXo6ceKE7rnnHqWkpOiOO+7QsGHD3JMWu3Xrps2bN2v//v26/vrr1aNHD82aNUstWrSora8EALiMhGtLwjBNk3VqXhQXFys2NlYn/91W9piQy7EAS4zodXOwQwACxukq19+L/qhvvvkmYPPSzv+sGLX+52oQ3bDG96koKderQ/4U0FhrIuRaEgAA1GXh+i4JEgYAACzkb1shVFsS1NcBAIBXVBgAALBQuFYYSBgAALBQuCYMtCQAAIBXVBgAALBQuFYYSBgAALCQKf+WRobqw5FIGAAAsFC4VhiYwwAAALyiwgAAgIXCtcJAwgAAgIXCNWGgJQEAALwiYQAAwELBfL11VlaWDMNQRkaG+5hpmnI4HEpISFBUVJRSU1O1Z88en+9NwgAAgIVM0/B7q4nc3Fz98Y9/VLdu3TyOz58/XwsWLNCTTz6p3NxcxcfHa/DgwTp16pRP9ydhAAAgBBUXF3tsZWVlF7329OnTGjNmjFasWKErrrjCfdw0TS1cuFAzZ87U6NGj1aVLF+Xk5OjMmTNavXq1T/GQMAAAYCGXDL83SUpMTFRsbKx7y8rKuuhnTpkyRSNGjNBNN93kcbygoEBFRUUaMmSI+5jNZtPAgQO1detWn74XqyQAALCQVaskCgsLZbfb3cdtNtsFr3/++ef10UcfKTc3t8q5oqIiSVJcXJzH8bi4OB06dMinuEgYAAAIQXa73SNhuJDCwkI98MADWr9+vSIjIy96nWF4JjCmaVY55g0tCQAALFSbkx63b9+uY8eOqVevXqpfv77q16+vzZs3a/Hixapfv767snC+0nDesWPHqlQdvCFhAADAQrW5rPLGG2/U7t27tXPnTvfWu3dvjRkzRjt37lTbtm0VHx+vDRs2uMeUl5dr8+bNGjBggE/fi5YEAAAW8mdp5Pnx1RUTE6MuXbp4HIuOjtaVV17pPp6RkaHMzEwlJycrOTlZmZmZatSokdLS0nyKi4QBAIAwNn36dJ09e1aTJ0/WyZMn1bdvX61fv14xMTE+3YeEAQAAC5l+rpLwpzohSe+++67HvmEYcjgccjgcft2XhAEAAAuZkkzTv/GhiEmPAADAKyoMAABYyCVDhvx4cJMfYwOJhAEAAAvV5iqJ2kRLAgAAeEWFAQAAC7lMQ4YF75IINSQMAABYyDT9XCURosskaEkAAACvqDAAAGChcJ30SMIAAICFSBgAAIBX4TrpkTkMAADAKyoMAABYKFxXSZAwAABgoXMJgz9zGCwMxkK0JAAAgFdUGAAAsBCrJAAAgFfmfzd/xociWhIAAMArKgwAAFiIlgQAAPAuTHsSJAwAAFjJzwqDQrTCwBwGAADgFRUGAAAsxJMeAQCAV+E66ZGWBAAA8IoKAwAAVjIN/yYuhmiFgYQBAAALhescBloSAADAKyoMAABYiQc3AQAAb8J1lUS1EobFixdX+4bp6ek1DgYAAISmaiUMTzzxRLVuZhgGCQMAACHaVvBHtRKGgoKCQMcBAEBYCNeWRI1XSZSXl2vfvn1yOp1WxgMAQN1mWrCFIJ8ThjNnzmj8+PFq1KiRrrnmGh0+fFjSubkLjz32mOUBAgCA4PM5YXjooYe0a9cuvfvuu4qMjHQfv+mmm7RmzRpLgwMAoO4xLNhCj8/LKl955RWtWbNG/fr1k2H870t17txZn376qaXBAQBQ54Tpcxh8rjAcP35czZs3r3K8pKTEI4EAAADhw+eEoU+fPvrb3/7m3j+fJKxYsUL9+/e3LjIAAOqiMJ306HNLIisrSzfffLP27t0rp9OpRYsWac+ePXr//fe1efPmQMQIAEDdEaZvq/S5wjBgwAC99957OnPmjNq1a6f169crLi5O77//vnr16hWIGAEAQJDV6F0SXbt2VU5OjtWxAABQ54Xr661rlDBUVlbq5ZdfVn5+vgzDUKdOnTRq1CjVr8+7rAAAl7kwXSXh80/4Tz75RKNGjVJRUZE6dOggSfr3v/+tZs2a6bXXXlPXrl0tDxIAAASXz3MYJkyYoGuuuUZHjhzRRx99pI8++kiFhYXq1q2bfvGLXwQiRgAA6o7zkx792UKQzxWGXbt2KS8vT1dccYX72BVXXKG5c+eqT58+lgYHAEBdY5jnNn/GhyKfKwwdOnTQf/7znyrHjx07pvbt21sSFAAAdVaYPoehWglDcXGxe8vMzFR6erpefPFFHTlyREeOHNGLL76ojIwMzZs3L9DxAgCAIKhWS6JJkyYej302TVN33HGH+5j53zUgI0eOVGVlZQDCBACgjgjTBzdVK2HYtGlToOMAACA8XM7LKgcOHBjoOAAAQAir8ZOWzpw5o8OHD6u8vNzjeLdu3fwOCgCAOutyrjB82/Hjx/Wzn/1Mb7311gXPM4cBAHBZC9OEwedllRkZGTp58qS2bdumqKgorVu3Tjk5OUpOTtZrr70WiBgBAECQ+Vxh2Lhxo1599VX16dNHERERat26tQYPHiy73a6srCyNGDEiEHECAFA3hOkqCZ8rDCUlJWrevLkkqWnTpjp+/Likc2+w/Oijj6yNDgCAOub8kx792UJRjZ70uG/fPklS9+7dtXz5cn3++ed6+umn1aJFC8sDBAAAwVejOQxHjx6VJM2ePVvr1q1Tq1attHjxYmVmZloeIAAAdUotPxp62bJl6tatm+x2u+x2u/r37++xMME0TTkcDiUkJCgqKkqpqanas2ePz1/L5zkMY8aMcf+5R48e+uyzz/Svf/1LrVq10lVXXeVzAAAAoOZatmypxx57zP0+p5ycHI0aNUo7duzQNddco/nz52vBggXKzs5WSkqKHn30UQ0ePFj79u1TTExMtT/H5wrDdzVq1Eg9e/YkWQAAQJIhP+cw+Ph5I0eO1PDhw5WSkqKUlBTNnTtXjRs31rZt22SaphYuXKiZM2dq9OjR6tKli3JycnTmzBmtXr3ap8+pVoVh6tSp1b7hggULfAoAAABUVVxc7LFvs9lks9kuOaayslIvvPCCSkpK1L9/fxUUFKioqEhDhgzxuM/AgQO1detWTZo0qdrxVCth2LFjR7Vu9u0XVIWj24b/SPXrXfpfFlBXVR79NNghAAHjNCtq78MsWlaZmJjocXj27NlyOBwXHLJ79271799fpaWlaty4sV5++WV17txZW7dulSTFxcV5XB8XF6dDhw75FBYvnwIAwEoWPemxsLBQdrvdffhS1YUOHTpo586d+vrrr/XSSy9p7Nix2rx5s/v8d3+hN03T51/ya/wuCQAAEDjnVz1UR8OGDd2THnv37q3c3FwtWrRIM2bMkCQVFRV5PPrg2LFjVaoO3vg96REAAHxLLS+rvGAIpqmysjIlJSUpPj5eGzZscJ8rLy/X5s2bNWDAAJ/uSYUBAAAL+fu0Rl/H/va3v9WwYcOUmJioU6dO6fnnn9e7776rdevWyTAMZWRkKDMzU8nJyUpOTlZmZqYaNWqktLQ0nz6HhAEAgDrsP//5j37605/q6NGjio2NVbdu3bRu3ToNHjxYkjR9+nSdPXtWkydP1smTJ9W3b1+tX7/ep2cwSCQMAABYq5Zfb/1///d/lzxvGIYcDsdFV1hUV43mMDz77LP6/ve/r4SEBPeyjIULF+rVV1/1KxgAAOq8EJjDEAg+JwzLli3T1KlTNXz4cH399deqrKyUJDVp0kQLFy60Oj4AABACfE4YlixZohUrVmjmzJmqV6+e+3jv3r21e/duS4MDAKCuCdfXW/s8h6GgoEA9evSoctxms6mkpMSSoAAAqLMsetJjqPG5wpCUlKSdO3dWOf7WW2+pc+fOVsQEAEDdFaZzGHyuMEybNk1TpkxRaWmpTNPUhx9+qL/85S/KysrSM888E4gYAQBAkPmcMPzsZz+T0+nU9OnTdebMGaWlpenqq6/WokWLdNdddwUiRgAA6ozafnBTbanRcxgmTpyoiRMn6ssvv5TL5VLz5s2tjgsAgLqplp/DUFv8enDTVVddZVUcAAAghPmcMCQlJV3ylZgHDx70KyAAAOo0f5dGhkuFISMjw2O/oqJCO3bs0Lp16zRt2jSr4gIAoG6iJXHOAw88cMHjTz31lPLy8vwOCAAAhJ4avUviQoYNG6aXXnrJqtsBAFA38RyGS3vxxRfVtGlTq24HAECdxLLK/+rRo4fHpEfTNFVUVKTjx49r6dKllgYHAABCg88Jwy233OKxHxERoWbNmik1NVUdO3a0Ki4AABBCfEoYnE6n2rRpo6FDhyo+Pj5QMQEAUHeF6SoJnyY91q9fX/fdd5/KysoCFQ8AAHVauL7e2udVEn379tWOHTsCEQsAAAhRPs9hmDx5sn7961/ryJEj6tWrl6Kjoz3Od+vWzbLgAACok0K0SuCPaicMP//5z7Vw4ULdeeedkqT09HT3OcMwZJqmDMNQZWWl9VECAFBXhOkchmonDDk5OXrsscdUUFAQyHgAAEAIqnbCYJrnUp7WrVsHLBgAAOo6HtwkXfItlQAAQLQkJCklJcVr0vDVV1/5FRAAAAg9PiUMjzzyiGJjYwMVCwAAdR4tCUl33XWXmjdvHqhYAACo+8K0JVHtBzcxfwEAgMuXz6skAADAJYRphaHaCYPL5QpkHAAAhAXmMAAAAO/CtMLg88unAADA5YcKAwAAVgrTCgMJAwAAFgrXOQy0JAAAgFdUGAAAsBItCQAA4A0tCQAAcNmiwgAAgJVoSQAAAK/CNGGgJQEAALyiwgAAgIWM/27+jA9FJAwAAFgpTFsSJAwAAFiIZZUAAOCyRYUBAAAr0ZIAAADVEqI/9P1BSwIAAHhFhQEAAAuF66RHEgYAAKwUpnMYaEkAAACvqDAAAGAhWhIAAMA7WhIAAOByRYUBAAAL0ZIAAADehWlLgoQBAAArhWnCwBwGAADgFQkDAAAWOj+HwZ/NF1lZWerTp49iYmLUvHlz3XLLLdq3b5/HNaZpyuFwKCEhQVFRUUpNTdWePXt8+hwSBgAArGRasPlg8+bNmjJlirZt26YNGzbI6XRqyJAhKikpcV8zf/58LViwQE8++aRyc3MVHx+vwYMH69SpU9X+HOYwAAAQgoqLiz32bTabbDZblevWrVvnsb9y5Uo1b95c27dv1w033CDTNLVw4ULNnDlTo0ePliTl5OQoLi5Oq1ev1qRJk6oVDxUGAAAsZJim35skJSYmKjY21r1lZWVV6/O/+eYbSVLTpk0lSQUFBSoqKtKQIUPc19hsNg0cOFBbt26t9veiwgAAgJUsWiVRWFgou93uPnyh6kKVoaapqVOn6rrrrlOXLl0kSUVFRZKkuLg4j2vj4uJ06NChaodFwgAAQAiy2+0eCUN13H///fr444+1ZcuWKucMw/DYN02zyrFLoSUBAICFanuVxHm//OUv9dprr2nTpk1q2bKl+3h8fLyk/1Uazjt27FiVqsOlkDAAAGClWl4lYZqm7r//fv31r3/Vxo0blZSU5HE+KSlJ8fHx2rBhg/tYeXm5Nm/erAEDBlT7c2hJAABQh02ZMkWrV6/Wq6++qpiYGHclITY2VlFRUTIMQxkZGcrMzFRycrKSk5OVmZmpRo0aKS0trdqfQ8IAAICFavvlU8uWLZMkpaamehxfuXKlxo0bJ0maPn26zp49q8mTJ+vkyZPq27ev1q9fr5iYmGp/DgkDAABWquV3SZim9wGGYcjhcMjhcNQsJpEwAABgqXB9vTWTHgEAgFdUGAAAsFKYvt6ahAEAAIuFalvBH7QkAACAV1QYAACwkmme2/wZH4JIGAAAsBCrJAAAwGWLCgMAAFZilQQAAPDGcJ3b/BkfimhJAAAAr6gwIKRERVXop+P3asB1Xyj2ijJ9ur+Jli/ppv37mgY7NMBvP7znS42454TiEsslSYf2RWrVE3HK22QPcmSwFC0JIPAemPaRWicV6w+ZfXTiRKR+MPiwMh/fonvHDdaJL6OCHR7gl+NHG+hPmS30xWc2SdLg27+SY+VnmjIkRYf+HRnk6GAVVknUAsMwLrmdf00nwlPDhpX6/sAv9KflXfTJx1fp6OeNtSq7s4qKojVi1MFghwf47YMNscrdaNfnB236/KBN2fNaqLQkQh17lQQ7NFjp/HMY/NlCUEhVGI4ePer+85o1a/Twww9r37597mNRUZ6/YVZUVKhBgwa1Fh8Cq149l+rVM1VeXs/jeHlZPXXueiJIUQGBERFh6vqRX8vWyKX8vOhghwN4FVIVhvj4ePcWGxsrwzDc+6WlpWrSpInWrl2r1NRURUZG6rnnnpPD4VD37t097rNw4UK1adPG49jKlSvVqVMnRUZGqmPHjlq6dOlF4ygrK1NxcbHHhsA7e7aB9n7SVHff8y81vfKsIiJMDRp8WB06faWmTUuDHR5giTYdz+qV/bv1xmcfK/2xI/p/49vo8H7aEeHkfEvCny0UhVTCUB0zZsxQenq68vPzNXTo0GqNWbFihWbOnKm5c+cqPz9fmZmZmjVrlnJyci54fVZWlmJjY91bYmKilV8Bl/CHzN4yJD330lt6dcMr+tHoT/XuO4lyuYxghwZY4sinNk0enKIHfpisN/58lR5cdFitkkmIw4ppwRaCQqolUR0ZGRkaPXq0T2PmzJmjxx9/3D0uKSlJe/fu1fLlyzV27Ngq1z/00EOaOnWqe7+4uJikoZYUfdFYMzJukC3SqUaNKnTyqyj95uEPVHS0UbBDAyzhrIhwT3rc/3Ejdeh+RrdMOK7FM/h/DEJbnUsYevfu7dP1x48fV2FhocaPH6+JEye6jzudTsXGxl5wjM1mk81m8ytO+KestL7KSuurceNy9fzeMf3p6S7BDgkImAYNQ/RXStRIuK6SqHMJQ3S05+SgiIgImd+ZUVpRUeH+s8t17pFZK1asUN++fT2uq1fPc3Idgq9nn//IMEwdORyjhKtP6+f3faLPDzfWhrdaBzs0wG8/+81R5W6M0fEvGiqqcaVSR32tbgNO63dj2gY7NFiJt1WGpmbNmqmoqEimacowzvW5d+7c6T4fFxenq6++WgcPHtSYMWOCFCWqKzq6QuMm7tFVzc7q1KkGeu8fVyvnmWtUWVnnptsAVTRp5tS0JYfVtLlTZ07VU0F+pH43pq0++kdMsEMDvKrzCUNqaqqOHz+u+fPn67bbbtO6dev01ltvyW7/35PTHA6H0tPTZbfbNWzYMJWVlSkvL08nT570mKuA4Pvnuy31z3dbBjsMICCe+DXzFC4H4dqSqPO/tnXq1ElLly7VU089pWuvvVYffvihHnzwQY9rJkyYoGeeeUbZ2dnq2rWrBg4cqOzsbCUlJQUpagBA2ArTVRKG+d0JAKiiuLhYsbGxurF9hurXYzIkwlPlvz8NdghAwDjNCr2rV/XNN994VKCtdP5nRf+b/5/qN6j5szWcFaV6f93DAY21Jup8SwIAgFASri0JEgYAAKzkMs9t/owPQSQMAABYKUxfb13nJz0CAIDAo8IAAICFDPk5h8GySKxFwgAAgJXC9EmPtCQAAIBXVBgAALAQyyoBAIB3rJIAAACXKyoMAABYyDBNGX5MXPRnbCCRMAAAYCXXfzd/xocgWhIAAMArKgwAAFiIlgQAAPAuTFdJkDAAAGAlnvQIAAAuV1QYAACwEE96BAAA3tGSAAAAlysqDAAAWMhwndv8GR+KSBgAALASLQkAAHC5osIAAICVeHATAADwJlwfDU1LAgAAeEWFAQAAK4XppEcSBgAArGRK8mdpZGjmCyQMAABYiTkMAADgskWFAQAAK5nycw6DZZFYioQBAAArhemkR1oSAADAKxIGAACs5LJg88E//vEPjRw5UgkJCTIMQ6+88orHedM05XA4lJCQoKioKKWmpmrPnj0+fy0SBgAALHR+lYQ/my9KSkp07bXX6sknn7zg+fnz52vBggV68sknlZubq/j4eA0ePFinTp3y6XOYwwAAQB02bNgwDRs27ILnTNPUwoULNXPmTI0ePVqSlJOTo7i4OK1evVqTJk2q9udQYQAAwErnJz36s0kqLi722MrKynwOpaCgQEVFRRoyZIj7mM1m08CBA7V161af7kXCAACAlSxKGBITExUbG+vesrKyfA6lqKhIkhQXF+dxPC4uzn2uumhJAAAQggoLC2W32937NputxvcyDMNj3zTNKse8IWEAAMBKFj2HwW63eyQMNREfHy/pXKWhRYsW7uPHjh2rUnXwhpYEAABWquVllZeSlJSk+Ph4bdiwwX2svLxcmzdv1oABA3y6FxUGAAAsVNsvnzp9+rQOHDjg3i8oKNDOnTvVtGlTtWrVShkZGcrMzFRycrKSk5OVmZmpRo0aKS0tzafPIWEAAKAOy8vL06BBg9z7U6dOlSSNHTtW2dnZmj59us6ePavJkyfr5MmT6tu3r9avX6+YmBifPoeEAQAAK9XyuyRSU1NlXmKMYRhyOBxyOBw1j0kkDAAAWMtlSoYfCYOLl08BAIA6igoDAABWCtPXW5MwAABgKT8TBoVmwkBLAgAAeEWFAQAAK9GSAAAAXrlM+dVWYJUEAACoq6gwAABgJdN1bvNnfAgiYQAAwErMYQAAAF4xhwEAAFyuqDAAAGAlWhIAAMArU34mDJZFYilaEgAAwCsqDAAAWImWBAAA8MrlkuTHsxRcofkcBloSAADAKyoMAABYiZYEAADwKkwTBloSAADAKyoMAABYKUwfDU3CAACAhUzTJdOPN076MzaQSBgAALCSafpXJWAOAwAAqKuoMAAAYCXTzzkMIVphIGEAAMBKLpdk+DEPIUTnMNCSAAAAXlFhAADASrQkAACAN6bLJdOPlkSoLqukJQEAALyiwgAAgJVoSQAAAK9cpmSEX8JASwIAAHhFhQEAACuZpiR/nsMQmhUGEgYAACxkukyZfrQkTBIGAAAuA6ZL/lUYWFYJAADqKCoMAABYiJYEAADwLkxbEiQM1XA+23O6yoIcCRA4lWZFsEMAAsapc3+/a+O3d6cq/Hpu0/lYQw0JQzWcOnVKkrT54LIgRwIA8MepU6cUGxsbkHs3bNhQ8fHx2lL0pt/3io+PV8OGDS2IyjqGGarNkhDicrn0xRdfKCYmRoZhBDucy0JxcbESExNVWFgou90e7HAAS/H3u/aZpqlTp04pISFBERGBm+9fWlqq8vJyv+/TsGFDRUZGWhCRdagwVENERIRatmwZ7DAuS3a7nf+hImzx97t2Baqy8G2RkZEh94PeKiyrBAAAXpEwAAAAr0gYEJJsNptmz54tm80W7FAAy/H3G3URkx4BAIBXVBgAAIBXJAwAAMArEgYAAOAVCQNCSnZ2tpo0aRLsMAAA30HCgIAYN26cDMOosh04cCDYoQGWutDf829v48aNC3aIgCV40iMC5uabb9bKlSs9jjVr1ixI0QCBcfToUfef16xZo4cfflj79u1zH4uKivK4vqKiQg0aNKi1+ACrUGFAwNhsNsXHx3tsixYtUteuXRUdHa3ExERNnjxZp0+fvug9du3apUGDBikmJkZ2u129evVSXl6e+/zWrVt1ww03KCoqSomJiUpPT1dJSUltfD1Akjz+fsfGxsowDPd+aWmpmjRporVr1yo1NVWRkZF67rnn5HA41L17d4/7LFy4UG3atPE4tnLlSnXq1EmRkZHq2LGjli5dWntfDPgOEgbUqoiICC1evFiffPKJcnJytHHjRk2fPv2i148ZM0YtW7ZUbm6utm/frt/85jfu3852796toUOHavTo0fr444+1Zs0abdmyRffff39tfR2gWmbMmKH09HTl5+dr6NCh1RqzYsUKzZw5U3PnzlV+fr4yMzM1a9Ys5eTkBDha4MJoSSBg3njjDTVu3Ni9P2zYML3wwgvu/aSkJM2ZM0f33XffRX9zOnz4sKZNm6aOHTtKkpKTk93nfv/73ystLU0ZGRnuc4sXL9bAgQO1bNmysH0BDOqejIwMjR492qcxc+bM0eOPP+4el5SUpL1792r58uUaO3ZsIMIELomEAQEzaNAgLVu2zL0fHR2tTZs2KTMzU3v37lVxcbGcTqdKS0tVUlKi6OjoKveYOnWqJkyYoGeffVY33XSTbr/9drVr106StH37dh04cECrVq1yX2+aplwulwoKCtSpU6fAf0mgGnr37u3T9cePH1dhYaHGjx+viRMnuo87nc5aeeMicCEkDAiY6OhotW/f3r1/6NAhDR8+XPfee6/mzJmjpk2basuWLRo/frwqKioueA+Hw6G0tDT97W9/01tvvaXZs2fr+eef16233iqXy6VJkyYpPT29yrhWrVoF7HsBvvpuMhwREaHvPpX/2/8NuFwuSefaEn379vW4rl69egGKErg0EgbUmry8PDmdTj3++OOKiDg3fWbt2rVex6WkpCglJUW/+tWvdPfdd2vlypW69dZb1bNnT+3Zs8cjKQHqgmbNmqmoqEimacowDEnSzp073efj4uJ09dVX6+DBgxozZkyQogQ8kTCg1rRr105Op1NLlizRyJEj9d577+npp5++6PVnz57VtGnTdNtttykpKUlHjhxRbm6ufvzjH0s6N5GsX79+mjJliiZOnKjo6Gjl5+drw4YNWrJkSW19LcBnqampOn78uObPn6/bbrtN69at01tvvSW73e6+xuFwKD09XXa7XcOGDVNZWZny8vJ08uRJTZ06NYjR43LFKgnUmu7du2vBggWaN2+eunTpolWrVikrK+ui19erV08nTpzQPffco5SUFN1xxx0aNmyYHnnkEUlSt27dtHnzZu3fv1/XX3+9evTooVmzZqlFixa19ZWAGunUqZOWLl2qp556Stdee60+/PBDPfjggx7XTJgwQc8884yys7PVtWtXDRw4UNnZ2UpKSgpS1Ljc8XprAADgFRUGAADgFQkDAADwioQBAAB4RcIAAAC8ImEAAABekTAAAACvSBgAAIBXJAwAAMArEgagjnA4HOrevbt7f9y4cbrllltqPY7PPvtMhmF4vPvgu9q0aaOFCxdW+57Z2dlq0qSJ37EZhqFXXnnF7/sAqIqEAfDDuHHjZBiGDMNQgwYN1LZtWz344IMqKSkJ+GcvWrRI2dnZ1bq2Oj/kAeBSePkU4Kebb75ZK1euVEVFhf75z39qwoQJKikp0bJly6pcW1FRoQYNGljyubGxsZbcBwCqgwoD4Cebzab4+HglJiYqLS1NY8aMcZfFz7cR/vSnP6lt27ay2WwyTVPffPONfvGLX6h58+ay2+36wQ9+oF27dnnc97HHHlNcXJxiYmI0fvx4lZaWepz/bkvC5XJp3rx5at++vWw2m1q1aqW5c+dKkvuFRT169JBhGEpNTXWPW7lypTp16qTIyEh17NhRS5cu9ficDz/8UD169FBkZKR69+6tHTt2+PzPaMGCBeratauio6OVmJioyZMn6/Tp01Wue+WVV5SSkqLIyEgNHjxYhYWFHudff/119erVS5GRkWrbtq0eeeQROZ1On+MB4DsSBsBiUVFRqqiocO8fOHBAa9eu1UsvveRuCYwYMUJFRUV68803tX37dvXs2VM33nijvvrqK0nS2rVrNXv2bM2dO1d5eXlq0aJFlR/k3/XQQw9p3rx5mjVrlvbu3avVq1crLi5O0rkf+pL097//XUePHtVf//pXSdKKFSs0c+ZMzZ07V/n5+crMzNSsWbOUk5MjSSopKdEPf/hDdejQQdu3b5fD4ajyVsXqiIiI0OLFi/XJJ58oJydHGzdu1PTp0z2uOXPmjObOnaucnBy99957Ki4u1l133eU+//bbb+snP/mJ0tPTtXfvXi1fvlzZ2dnupAhAgJkAamzs2LHmqFGj3PsffPCBeeWVV5p33HGHaZqmOXv2bLNBgwbmsWPH3Ne88847pt1uN0tLSz3u1a5dO3P58uWmaZpm//79zXvvvdfjfN++fc1rr732gp9dXFxs2mw2c8WKFReMs6CgwJRk7tixw+N4YmKiuXr1ao9jc+bMMfv372+apmkuX77cbNq0qVlSUuI+v2zZsgve69tat25tPvHEExc9v3btWvPKK690769cudKUZG7bts19LD8/35RkfvDBB6Zpmub1119vZmZmetzn2WefNVu0aOHel2S+/PLLF/1cADXHHAbAT2+88YYaN24sp9OpiooKjRo1SkuWLHGfb926tZo1a+be3759u06fPq0rr7zS4z5nz57Vp59+KknKz8/Xvffe63G+f//+2rRp0wVjyM/PV1lZmW688cZqx338+HEVFhZq/Pjxmjhxovu40+l0z4/Iz8/Xtddeq0aNGnnE4atNmzYpMzNTe/fuVXFxsZxOp0pLS1VSUqLo6GhJUv369dW7d2/3mI4dO6pJkybKz8/X9773PW3fvl25ubkeFYXKykqVlpbqzJkzHjECsB4JA+CnQYMGadmyZWrQoIESEhKqTGo8/wPxPJfLpRYtWujdd9+tcq+aLi2MioryeYzL5ZJ0ri3Rt29fj3P16tWTJJmmWaN4vu3QoUMaPny47r33Xs2ZM0dNmzbVli1bNH78eI/WjXRuWeR3nT/mcrn0yCOPaPTo0VWuiYyM9DtOAJdGwgD4KTo6Wu3bt6/29T179lRRUZHq16+vNm3aXPCaTp06adu2bbrnnnvcx7Zt23bReyYnJysqKkrvvPOOJkyYUOV8w4YNJZ37jfy8uLg4XX311Tp48KDGjBlzwft27txZzz77rM6ePetOSi4Vx4Xk5eXJ6XTq8ccfV0TEuWlTa9eurXKd0+lUXl6evve970mS9u3bp6+//lodO3aUdO6f2759+3z6Zw3AOiQMQC276aab1L9/f91yyy2aN2+eOnTooC+++EJvvvmmbrnlFvXu3VsPPPCAxo4dq969e+u6667TqlWrtGfPHrVt2/aC94yMjNSMGTM0ffp0NWzYUN///vd1/Phx7dmzR+PHj1fz5s0VFRWldevWqWXLloqMjFRsbKwcDofS09Nlt9s1bNgwlZWVKS8vTydPntTUqVOVlpammTNnavz48frd736nzz77TH/4wx98+r7t2rWT0+nUkiVLNHLkSL333nt6+umnq1zXoEED/fKXv9TixYvVoEED3X///erXr587gXj44Yf1wx/+UImJibr99tsVERGhjz/+WLt379ajjz7q+78IAD5hlQRQywzD0JtvvqkbbrhBP//5z5WSkqK77rpLn332mXtVw5133qmHH35YM2bMUK9evXTo0CHdd999l7zvrFmz9Otf/1oPP/ywOnXqpDvvvFPHjh2TdG5+wOLFi7V8+XIlJCRo1KhRkqQJEybomWeeUXZ2trp27aqBAwcqOzvbvQyzcePGev3117V371716NFDM2fO1Lx583z6vt27d9eCBQs0b948denSRatWrVJWVlaV6xo1aqQZM2YoLS1N/fv3V1RUlJ5//nn3+aFDh+qNN97Qhg0b1KdPH/Xr108LFixQ69atfYoHQM0YphVNSgAAENaoMAAAAK9IGAAAgFckDAAAwCsSBgAA4BUJAwAA8IqEAQAAeEXCAAAAvCJhAAAAXpEwAAAAr0gYAACAVyQMAADAq/8PkUyDiXzTBQAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "_ = ConfusionMatrixDisplay.from_predictions(df_new.y_true_ffnn, \n",
    "                                            df_new.y_pred_proba_ffnn>threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aeee57",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "833997d8",
   "metadata": {},
   "source": [
    "## Accuracy is a common metric used to evaluate the performance of a classification model\n",
    "## Except accuracy, other metrics like sensitivity and specificity are equally important.\n",
    "\n",
    "\n",
    ">Sensitivity measures the model's ability to correctly identify positive cases (True Positives) out of all actual positive cases (True Positives + False Negatives).\n",
    "It's calculated as Sensitivity $= TP / (TP + FN)$.\n",
    "Sensitivity is particularly important when the cost of missing a positive case is high. Sensitivity reduces the mistake of False Negative(Type2 mistake). For example,you want to minimize false negatives to avoid missing potentially threatens to some particular countries.\n",
    "\n",
    "\n",
    ">Specificity measures the model's ability to correctly identify negative cases (True Negatives) out of all actual negative cases (True Negatives + False Positives).\n",
    "It's calculated as Specificity $= TN / (TN + FP)$.\n",
    "Specificity is important when the cost of incorrectly identifying a negative case as positive is high. The specificity gets higher, the False Positive mistakes(Type1 mistake) would be more impossible than before to happen.For example, you want to minimize false positives to avoid unnecessary waste resources to those countries or areas which won’t be under attack, this could help to allocate resources more efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cffd863",
   "metadata": {},
   "source": [
    "## How sensitivity and specificity effect UNICEF\n",
    "Sensitivity is the true positive rate, specificity is the true negative rate. Both of them are true, but one predicts that the conflict will escalate, the other predicts that the conflict will not escalate. This means that sensitivity and specificity are content that we have successfully predicted, and as data scientists, we want to have as many correct data as possible, so a high value of these two means that we have a high probability of successfully predicting future events, which means we can prepare for them in advance. On the other hand, if the number of these data are low, it means that our preparation is meaningless. \n",
    ">Since our prediction is wrong, we can only improvise in the future rather than directly lock the target. It is important for UNICEF to predict conflict escalation because they don't have the resources to cover all the countries in the world, so they can only predict which countries are most likely to experience conflict escalation, and place the resources in advance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d1f5c1",
   "metadata": {},
   "source": [
    "## We want to examin the effect of classificaiton thresholding on sensitivity and specificity. \n",
    "\n",
    "Sensitivity  ：$TP / (TP + FN)$\n",
    "\n",
    "Specificity  ：$TN / (TN + FP)$\n",
    "\n",
    "For a thresholding of 0.5：\n",
    "\n",
    "Sensitivity $= TP / (TP + FN) = 3 / (3 + 57) = 0.05$\n",
    "\n",
    "Specificity $= TN / (TN + FP) = 9 / (9 + 7) = 0.56$\n",
    "\n",
    "For a thresholding of 0.4：\n",
    "\n",
    "Sensitivity $= TP / (TP + FN) = 6 / (6 + 44) = 0.12$\n",
    "\n",
    "Specificity $= TN / (TN + FP) = 6 / (6 + 20) = 0.23$\n",
    "\n",
    "For a thresholding of 0.3：\n",
    "\n",
    "Sensitivity $= TP / (TP + FN) = 11 / (11 + 8) = 0.3$\n",
    "\n",
    "Specificity $= TN / (TN + FP) = 1 / (1 + 56) = 0.02$\n",
    "***\n",
    "|thresholding|Sensitivity|Specificity|\n",
    "|---|---|---|\n",
    "|0.5|0.05|0.56|\n",
    "|0.4|0.12|0.23|\n",
    "|0.3|0.3|0.02|\n",
    "\n",
    ">We found that when the thresholding was lowered, sensitivity increased and specificity decreased. Increased sensitivity is usually accompanied by a decrease in specificity, which increases the risk of False Positive errors (Type 1 errors). Because it is easier for the model to classify samples as positive examples, it may mistakenly misclassify some negative examples as positive examples. If we value more accurate predictions of conflicts in Asia, then we may pay more attention to the sensitivity of the model. In this context, high sensitivity means that we want the model to be able to detect as many actual regional conflict events as possible. This is because in the prediction of regional conflicts, missing any real conflict event may lead to major social and humanitarian crises. Therefore, we are willing to tolerate some false positives to ensure that potential conflict events are not missed.\n",
    "\n",
    ">When we are more concerned with reducing false negatives, we usually choose a lower classification thresholding, which increases the sensitivity of the model. But be aware that this may increase the number of false positives, so there is a trade-off in practical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e183ea18",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51ff59ae",
   "metadata": {},
   "source": [
    "## Assignment 1 next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f81a5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2309f0e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearmonth</th>\n",
       "      <th>fips</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>y_pred_proba_transformer</th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_xgboost</th>\n",
       "      <th>y_pred_proba_xgboost</th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_ffnn</th>\n",
       "      <th>y_pred_proba_ffnn</th>\n",
       "      <th>y_true_ffnn</th>\n",
       "      <th>iso3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202211</td>\n",
       "      <td>UZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.535385</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.660580</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.381938</td>\n",
       "      <td>False</td>\n",
       "      <td>UZB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202212</td>\n",
       "      <td>UZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.538211</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.579952</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.364793</td>\n",
       "      <td>False</td>\n",
       "      <td>UZB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202301</td>\n",
       "      <td>UZ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.204810</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.652542</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.364343</td>\n",
       "      <td>False</td>\n",
       "      <td>UZB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202211</td>\n",
       "      <td>ID</td>\n",
       "      <td>False</td>\n",
       "      <td>0.461546</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.480096</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.398537</td>\n",
       "      <td>False</td>\n",
       "      <td>IDN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202212</td>\n",
       "      <td>ID</td>\n",
       "      <td>False</td>\n",
       "      <td>0.346367</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.589674</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>False</td>\n",
       "      <td>IDN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>202211</td>\n",
       "      <td>JA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.163859</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.205914</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.273060</td>\n",
       "      <td>False</td>\n",
       "      <td>JPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>202212</td>\n",
       "      <td>JA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191392</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.209022</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.272838</td>\n",
       "      <td>False</td>\n",
       "      <td>JPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>202211</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.450048</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.495618</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.365198</td>\n",
       "      <td>False</td>\n",
       "      <td>SAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>202212</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.443690</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.428008</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.366745</td>\n",
       "      <td>False</td>\n",
       "      <td>SAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>202301</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.315053</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.618117</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.367574</td>\n",
       "      <td>True</td>\n",
       "      <td>SAU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    yearmonth fips  y_pred_transformer  y_pred_proba_transformer  \\\n",
       "0      202211   UZ                True                  0.535385   \n",
       "1      202212   UZ                True                  0.538211   \n",
       "2      202301   UZ               False                  0.204810   \n",
       "3      202211   ID               False                  0.461546   \n",
       "4      202212   ID               False                  0.346367   \n",
       "..        ...  ...                 ...                       ...   \n",
       "71     202211   JA               False                  0.163859   \n",
       "72     202212   JA               False                  0.191392   \n",
       "73     202211   SA               False                  0.450048   \n",
       "74     202212   SA               False                  0.443690   \n",
       "75     202301   SA               False                  0.315053   \n",
       "\n",
       "    y_true_transformer  y_pred_xgboost  y_pred_proba_xgboost  y_true_xgboost  \\\n",
       "0                False            True              0.660580           False   \n",
       "1                False            True              0.579952           False   \n",
       "2                False            True              0.652542           False   \n",
       "3                False           False              0.480096           False   \n",
       "4                False            True              0.589674            True   \n",
       "..                 ...             ...                   ...             ...   \n",
       "71               False           False              0.205914           False   \n",
       "72               False           False              0.209022           False   \n",
       "73               False           False              0.495618            True   \n",
       "74               False           False              0.428008           False   \n",
       "75                True            True              0.618117           False   \n",
       "\n",
       "    y_pred_ffnn  y_pred_proba_ffnn  y_true_ffnn iso3  \n",
       "0         False           0.381938        False  UZB  \n",
       "1         False           0.364793        False  UZB  \n",
       "2         False           0.364343        False  UZB  \n",
       "3         False           0.398537        False  IDN  \n",
       "4         False           0.395459        False  IDN  \n",
       "..          ...                ...          ...  ...  \n",
       "71        False           0.273060        False  JPN  \n",
       "72        False           0.272838        False  JPN  \n",
       "73        False           0.365198        False  SAU  \n",
       "74        False           0.366745        False  SAU  \n",
       "75        False           0.367574         True  SAU  \n",
       "\n",
       "[76 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae406d38",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "### Create the Prediciton Probability \"Error\" results for the xgboost and ffnn models analagously to the transformer model produced above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a472b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_proba_transformer</th>\n",
       "      <th>transformer_probability_prediction_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.183897</td>\n",
       "      <td>0.183897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0.267831</td>\n",
       "      <td>0.267831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0.482585</td>\n",
       "      <td>0.482585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0.187792</td>\n",
       "      <td>0.187792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>0.539319</td>\n",
       "      <td>0.460681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>False</td>\n",
       "      <td>0.182196</td>\n",
       "      <td>0.182196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>False</td>\n",
       "      <td>0.203236</td>\n",
       "      <td>0.203236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>False</td>\n",
       "      <td>0.527107</td>\n",
       "      <td>0.527107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>False</td>\n",
       "      <td>0.555677</td>\n",
       "      <td>0.555677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>True</td>\n",
       "      <td>0.565700</td>\n",
       "      <td>0.434300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true_transformer  y_pred_proba_transformer  \\\n",
       "0                 False                  0.183897   \n",
       "1                 False                  0.267831   \n",
       "2                 False                  0.482585   \n",
       "3                 False                  0.187792   \n",
       "4                  True                  0.539319   \n",
       "..                  ...                       ...   \n",
       "359               False                  0.182196   \n",
       "360               False                  0.203236   \n",
       "361               False                  0.527107   \n",
       "362               False                  0.555677   \n",
       "363                True                  0.565700   \n",
       "\n",
       "     transformer_probability_prediction_error  \n",
       "0                                    0.183897  \n",
       "1                                    0.267831  \n",
       "2                                    0.482585  \n",
       "3                                    0.187792  \n",
       "4                                    0.460681  \n",
       "..                                        ...  \n",
       "359                                  0.182196  \n",
       "360                                  0.203236  \n",
       "361                                  0.527107  \n",
       "362                                  0.555677  \n",
       "363                                  0.434300  \n",
       "\n",
       "[364 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Probability \"Error\" for transformer\n",
    "df_preds['transformer_probability_prediction_error'] = np.abs(df_preds['y_true_transformer'].astype(float) - df_preds['y_pred_proba_transformer'])\n",
    "df_preds[['y_true_transformer','y_pred_proba_transformer','transformer_probability_prediction_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab94f32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_proba_xgboost</th>\n",
       "      <th>xgboost_probability_prediction_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.066500</td>\n",
       "      <td>0.066500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0.099643</td>\n",
       "      <td>0.099643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>0.704086</td>\n",
       "      <td>0.295914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>0.638444</td>\n",
       "      <td>0.361556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0.608380</td>\n",
       "      <td>0.608380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>False</td>\n",
       "      <td>0.079453</td>\n",
       "      <td>0.079453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>False</td>\n",
       "      <td>0.060189</td>\n",
       "      <td>0.060189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>True</td>\n",
       "      <td>0.697625</td>\n",
       "      <td>0.302375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>False</td>\n",
       "      <td>0.729246</td>\n",
       "      <td>0.729246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>False</td>\n",
       "      <td>0.591722</td>\n",
       "      <td>0.591722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true_xgboost  y_pred_proba_xgboost  \\\n",
       "0             False              0.066500   \n",
       "1             False              0.099643   \n",
       "2              True              0.704086   \n",
       "3              True              0.638444   \n",
       "4             False              0.608380   \n",
       "..              ...                   ...   \n",
       "359           False              0.079453   \n",
       "360           False              0.060189   \n",
       "361            True              0.697625   \n",
       "362           False              0.729246   \n",
       "363           False              0.591722   \n",
       "\n",
       "     xgboost_probability_prediction_error  \n",
       "0                                0.066500  \n",
       "1                                0.099643  \n",
       "2                                0.295914  \n",
       "3                                0.361556  \n",
       "4                                0.608380  \n",
       "..                                    ...  \n",
       "359                              0.079453  \n",
       "360                              0.060189  \n",
       "361                              0.302375  \n",
       "362                              0.729246  \n",
       "363                              0.591722  \n",
       "\n",
       "[364 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Probability \"Error\" for xgboost\n",
    "df_preds['xgboost_probability_prediction_error'] = np.abs(df_preds['y_true_xgboost'].astype(float) - df_preds['y_pred_proba_xgboost'])\n",
    "df_preds[['y_true_xgboost','y_pred_proba_xgboost','xgboost_probability_prediction_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a258a6d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_ffnn</th>\n",
       "      <th>y_pred_proba_ffnn</th>\n",
       "      <th>ffnn_probability_prediction_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.409958</td>\n",
       "      <td>0.409958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0.406696</td>\n",
       "      <td>0.406696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0.545236</td>\n",
       "      <td>0.545236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0.534560</td>\n",
       "      <td>0.534560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>0.538583</td>\n",
       "      <td>0.461417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>False</td>\n",
       "      <td>0.291874</td>\n",
       "      <td>0.291874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>False</td>\n",
       "      <td>0.300321</td>\n",
       "      <td>0.300321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>False</td>\n",
       "      <td>0.335496</td>\n",
       "      <td>0.335496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>False</td>\n",
       "      <td>0.324000</td>\n",
       "      <td>0.324000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>True</td>\n",
       "      <td>0.332455</td>\n",
       "      <td>0.667545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true_ffnn  y_pred_proba_ffnn  ffnn_probability_prediction_error\n",
       "0          False           0.409958                           0.409958\n",
       "1          False           0.406696                           0.406696\n",
       "2          False           0.545236                           0.545236\n",
       "3          False           0.534560                           0.534560\n",
       "4           True           0.538583                           0.461417\n",
       "..           ...                ...                                ...\n",
       "359        False           0.291874                           0.291874\n",
       "360        False           0.300321                           0.300321\n",
       "361        False           0.335496                           0.335496\n",
       "362        False           0.324000                           0.324000\n",
       "363         True           0.332455                           0.667545\n",
       "\n",
       "[364 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Probability \"Error\" for ffnn\n",
    "df_preds['ffnn_probability_prediction_error'] = np.abs(df_preds['y_true_ffnn'].astype(float) - df_preds['y_pred_proba_ffnn'])\n",
    "df_preds[['y_true_ffnn','y_pred_proba_ffnn','ffnn_probability_prediction_error']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d87a181",
   "metadata": {},
   "source": [
    "## Q2\n",
    "### 2. Create a bootsrap confidence interval for the average Prediction Probability \"Error\" for one of these models using all the data.\n",
    "\n",
    "\n",
    "> In this context \"using all the data\" means using all the predictions made for a given model under consideration; whereas, \"using a data subset\" would mean restricting the rows of the data on the basis of one (or more) of the columns from the \"Progress Indicators\" data so as to only consider the predictions made for the given model under consideration within a given subset of (the countries of) the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8de45c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39546702, 0.44078702])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I choose ffnn to do the bootsrap confidence interval for 90%\n",
    "rep, n = 1000,76\n",
    "my_bootstrapped_sample_means = np.zeros(rep)\n",
    "for i in range(rep):\n",
    "    my_bootstrap_sample_ffnn = np.random.choice(df_preds.ffnn_probability_prediction_error,replace=True, size=n)\n",
    "    my_bootstrapped_sample_means[i] = my_bootstrap_sample_ffnn.mean()\n",
    "np.quantile(my_bootstrapped_sample_means, [0.05,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0379dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042899999999999994"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4375-0.3946"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86b52756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27894504, 0.63068192])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep, n = 1000,76\n",
    "my_bootstrapped_sample_means = np.zeros(rep)\n",
    "for i in range(rep):\n",
    "    my_bootstrap_sample_xgboost = np.random.choice(df_preds.xgboost_probability_prediction_error,replace=True, size=n)\n",
    "    my_bootstrapped_sample_means[i] = my_bootstrap_sample_xgboost.mean()\n",
    "np.quantile(my_bootstrap_sample_ffnn, [0.05,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a562088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3315"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.6168-0.2853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aad095ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40866142, 0.47314292])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep, n = 1000,76\n",
    "my_bootstrapped_sample_means = np.zeros(rep)\n",
    "for i in range(rep):\n",
    "    my_bootstrap_sample_transformer = np.random.choice(df_preds.transformer_probability_prediction_error,replace=True, size=n)\n",
    "    my_bootstrapped_sample_means[i] = my_bootstrap_sample_transformer.mean()\n",
    "np.quantile(my_bootstrapped_sample_means, [0.05,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be787778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06359999999999999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4720-0.4084"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d6d3a7",
   "metadata": {},
   "source": [
    "# Q3\n",
    "### 3. Create the Prediction Classification \"Correctness\" results of \"correct\" and \"incorrect\" predictions for the `transformer`, `xgboost` and `ffnn` models; or, an alternative \"either/or\" breakdown of interest (such as \"wrongly predicted no escalation\" versus all the other categories combined)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d56bf6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>transformer_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true_transformer  y_pred_transformer  \\\n",
       "0                 False               False   \n",
       "1                 False               False   \n",
       "2                 False               False   \n",
       "3                 False               False   \n",
       "4                  True                True   \n",
       "..                  ...                 ...   \n",
       "359               False               False   \n",
       "360               False               False   \n",
       "361               False                True   \n",
       "362               False                True   \n",
       "363                True                True   \n",
       "\n",
       "    transformer_classifcation_performance_outcome  \n",
       "0               correctly predicted no escalation  \n",
       "1               correctly predicted no escalation  \n",
       "2               correctly predicted no escalation  \n",
       "3               correctly predicted no escalation  \n",
       "4                  correctly predicted escalation  \n",
       "..                                            ...  \n",
       "359             correctly predicted no escalation  \n",
       "360             correctly predicted no escalation  \n",
       "361                  wrongly predicted escalation  \n",
       "362                  wrongly predicted escalation  \n",
       "363                correctly predicted escalation  \n",
       "\n",
       "[364 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Classification \"Correctness\" for transformer\n",
    "threshold = 0.5 # using default classification threshold\n",
    "\n",
    "df_preds['transformer_classifcation_performance_outcome'] = None\n",
    "\n",
    "tmp = df_preds['transformer_classifcation_performance_outcome'].copy()\n",
    "TP_pos_pred_correct = df_preds.y_true_transformer & (df_preds.y_pred_proba_transformer>threshold)\n",
    "tmp[TP_pos_pred_correct] = \"correctly predicted escalation\"\n",
    "TN_neg_pred_correct = (~df_preds.y_true_transformer) & (df_preds.y_pred_proba_transformer<=threshold)\n",
    "tmp[TN_neg_pred_correct] = \"correctly predicted no escalation\"\n",
    "FP_pos_pred_wrong = (~df_preds.y_true_transformer) & (df_preds.y_pred_proba_transformer>threshold)\n",
    "tmp[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df_preds.y_true_transformer & (df_preds.y_pred_proba_transformer<=threshold)\n",
    "tmp[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df_preds['transformer_classifcation_performance_outcome'] = tmp\n",
    "df_preds[['y_true_transformer','y_pred_transformer','transformer_classifcation_performance_outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c27a10be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_xgboost</th>\n",
       "      <th>transformer_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true_xgboost  y_pred_xgboost  \\\n",
       "0             False           False   \n",
       "1             False           False   \n",
       "2              True            True   \n",
       "3              True            True   \n",
       "4             False            True   \n",
       "..              ...             ...   \n",
       "359           False           False   \n",
       "360           False           False   \n",
       "361            True            True   \n",
       "362           False            True   \n",
       "363           False            True   \n",
       "\n",
       "    transformer_classifcation_performance_outcome  \n",
       "0               correctly predicted no escalation  \n",
       "1               correctly predicted no escalation  \n",
       "2               correctly predicted no escalation  \n",
       "3               correctly predicted no escalation  \n",
       "4                  correctly predicted escalation  \n",
       "..                                            ...  \n",
       "359             correctly predicted no escalation  \n",
       "360             correctly predicted no escalation  \n",
       "361                  wrongly predicted escalation  \n",
       "362                  wrongly predicted escalation  \n",
       "363                correctly predicted escalation  \n",
       "\n",
       "[364 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Classification \"Correctness\" for xgboost\n",
    "threshold = 0.5 # using default classification threshold\n",
    "\n",
    "df_preds['xgboost_classifcation_performance_outcome'] = None\n",
    "\n",
    "tmp = df_preds['xgboost_classifcation_performance_outcome'].copy()\n",
    "TP_pos_pred_correct = df_preds.y_true_transformer & (df_preds.y_pred_proba_transformer>threshold)\n",
    "tmp[TP_pos_pred_correct] = \"correctly predicted escalation\"\n",
    "TN_neg_pred_correct = (~df_preds.y_true_transformer) & (df_preds.y_pred_proba_transformer<=threshold)\n",
    "tmp[TN_neg_pred_correct] = \"correctly predicted no escalation\"\n",
    "FP_pos_pred_wrong = (~df_preds.y_true_transformer) & (df_preds.y_pred_proba_transformer>threshold)\n",
    "tmp[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df_preds.y_true_transformer & (df_preds.y_pred_proba_transformer<=threshold)\n",
    "tmp[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df_preds['xgboost_classifcation_performance_outcome'] = tmp\n",
    "df_preds[['y_true_xgboost','y_pred_xgboost','transformer_classifcation_performance_outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6e29a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_ffnn</th>\n",
       "      <th>y_pred_ffnn</th>\n",
       "      <th>ffnn_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_true_ffnn  y_pred_ffnn ffnn_classifcation_performance_outcome\n",
       "0          False        False      correctly predicted no escalation\n",
       "1          False        False      correctly predicted no escalation\n",
       "2          False         True      correctly predicted no escalation\n",
       "3          False         True      correctly predicted no escalation\n",
       "4           True         True         correctly predicted escalation\n",
       "..           ...          ...                                    ...\n",
       "359        False        False      correctly predicted no escalation\n",
       "360        False        False      correctly predicted no escalation\n",
       "361        False        False           wrongly predicted escalation\n",
       "362        False        False           wrongly predicted escalation\n",
       "363         True        False         correctly predicted escalation\n",
       "\n",
       "[364 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Classification \"Correctness\" for ffnn\n",
    "threshold = 0.5 # using default classification threshold\n",
    "\n",
    "df_preds['ffnn_classifcation_performance_outcome'] = None\n",
    "\n",
    "tmp = df_preds['ffnn_classifcation_performance_outcome'].copy()\n",
    "TP_pos_pred_correct = df_preds.y_true_transformer & (df_preds.y_pred_proba_transformer>threshold)\n",
    "tmp[TP_pos_pred_correct] = \"correctly predicted escalation\"\n",
    "TN_neg_pred_correct = (~df_preds.y_true_transformer) & (df_preds.y_pred_proba_transformer<=threshold)\n",
    "tmp[TN_neg_pred_correct] = \"correctly predicted no escalation\"\n",
    "FP_pos_pred_wrong = (~df_preds.y_true_transformer) & (df_preds.y_pred_proba_transformer>threshold)\n",
    "tmp[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df_preds.y_true_transformer & (df_preds.y_pred_proba_transformer<=threshold)\n",
    "tmp[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df_preds['ffnn_classifcation_performance_outcome'] = tmp\n",
    "df_preds[['y_true_ffnn','y_pred_ffnn','ffnn_classifcation_performance_outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28849b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correctly predicted no escalation    193\n",
       "wrongly predicted escalation         117\n",
       "correctly predicted escalation        32\n",
       "wrongly predicted no escalation       22\n",
       "Name: ffnn_classifcation_performance_outcome, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds[['y_true_ffnn','y_pred_ffnn','ffnn_classifcation_performance_outcome']].\\\n",
    "ffnn_classifcation_performance_outcome.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa68cf6a",
   "metadata": {},
   "source": [
    "# Country data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c96a0201",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>transformer_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_true_transformer  y_pred_transformer  \\\n",
       "0                False                True   \n",
       "1                False                True   \n",
       "2                False               False   \n",
       "3                False               False   \n",
       "4                False               False   \n",
       "..                 ...                 ...   \n",
       "71               False               False   \n",
       "72               False               False   \n",
       "73               False               False   \n",
       "74               False               False   \n",
       "75                True               False   \n",
       "\n",
       "   transformer_classifcation_performance_outcome  \n",
       "0                   wrongly predicted escalation  \n",
       "1                   wrongly predicted escalation  \n",
       "2              correctly predicted no escalation  \n",
       "3              correctly predicted no escalation  \n",
       "4              correctly predicted no escalation  \n",
       "..                                           ...  \n",
       "71             correctly predicted no escalation  \n",
       "72             correctly predicted no escalation  \n",
       "73             correctly predicted no escalation  \n",
       "74             correctly predicted no escalation  \n",
       "75               wrongly predicted no escalation  \n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Classification \"Correctness\" for transformer\n",
    "threshold = 0.5 # using default classification threshold\n",
    "\n",
    "df_new['transformer_classifcation_performance_outcome'] = None\n",
    "\n",
    "tmp = df_new['transformer_classifcation_performance_outcome'].copy()\n",
    "TP_pos_pred_correct = df_new.y_true_transformer & (df_new.y_pred_proba_transformer>threshold)\n",
    "tmp[TP_pos_pred_correct] = \"correctly predicted escalation\"\n",
    "TN_neg_pred_correct = (~df_new.y_true_transformer) & (df_new.y_pred_proba_transformer<=threshold)\n",
    "tmp[TN_neg_pred_correct] = \"correctly predicted no escalation\"\n",
    "FP_pos_pred_wrong = (~df_new.y_true_transformer) & (df_new.y_pred_proba_transformer>threshold)\n",
    "tmp[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df_new.y_true_transformer & (df_new.y_pred_proba_transformer<=threshold)\n",
    "tmp[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df_new['transformer_classifcation_performance_outcome'] = tmp\n",
    "df_new[['y_true_transformer','y_pred_transformer','transformer_classifcation_performance_outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfc09a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correctly predicted no escalation    33\n",
       "wrongly predicted escalation         31\n",
       "correctly predicted escalation        9\n",
       "wrongly predicted no escalation       3\n",
       "Name: transformer_classifcation_performance_outcome, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[['y_true_transformer','y_pred_transformer','transformer_classifcation_performance_outcome']].\\\n",
    "transformer_classifcation_performance_outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8668ea7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_xgboost</th>\n",
       "      <th>xgboost_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_true_xgboost  y_pred_xgboost xgboost_classifcation_performance_outcome\n",
       "0            False            True              wrongly predicted escalation\n",
       "1            False            True              wrongly predicted escalation\n",
       "2            False            True         correctly predicted no escalation\n",
       "3            False           False         correctly predicted no escalation\n",
       "4             True            True         correctly predicted no escalation\n",
       "..             ...             ...                                       ...\n",
       "71           False           False         correctly predicted no escalation\n",
       "72           False           False         correctly predicted no escalation\n",
       "73            True           False         correctly predicted no escalation\n",
       "74           False           False         correctly predicted no escalation\n",
       "75           False            True           wrongly predicted no escalation\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Classification \"Correctness\" for xgboost\n",
    "threshold = 0.5 # using default classification threshold\n",
    "\n",
    "df_new['xgboost_classifcation_performance_outcome'] = None\n",
    "\n",
    "tmp = df_new['xgboost_classifcation_performance_outcome'].copy()\n",
    "TP_pos_pred_correct = df_new.y_true_transformer & (df_new.y_pred_proba_transformer>threshold)\n",
    "tmp[TP_pos_pred_correct] = \"correctly predicted escalation\"\n",
    "TN_neg_pred_correct = (~df_new.y_true_transformer) & (df_new.y_pred_proba_transformer<=threshold)\n",
    "tmp[TN_neg_pred_correct] = \"correctly predicted no escalation\"\n",
    "FP_pos_pred_wrong = (~df_new.y_true_transformer) & (df_new.y_pred_proba_transformer>threshold)\n",
    "tmp[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df_new.y_true_transformer & (df_new.y_pred_proba_transformer<=threshold)\n",
    "tmp[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df_new['xgboost_classifcation_performance_outcome'] = tmp\n",
    "df_new[['y_true_xgboost','y_pred_xgboost','xgboost_classifcation_performance_outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b943706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correctly predicted no escalation    33\n",
       "wrongly predicted escalation         31\n",
       "correctly predicted escalation        9\n",
       "wrongly predicted no escalation       3\n",
       "Name: transformer_classifcation_performance_outcome, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[['y_true_xgboost','y_pred_xgboost','transformer_classifcation_performance_outcome']].\\\n",
    "transformer_classifcation_performance_outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "115eab3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_ffnn</th>\n",
       "      <th>y_pred_ffnn</th>\n",
       "      <th>ffnn_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_true_ffnn  y_pred_ffnn ffnn_classifcation_performance_outcome\n",
       "0         False        False           wrongly predicted escalation\n",
       "1         False        False           wrongly predicted escalation\n",
       "2         False        False      correctly predicted no escalation\n",
       "3         False        False      correctly predicted no escalation\n",
       "4         False        False      correctly predicted no escalation\n",
       "..          ...          ...                                    ...\n",
       "71        False        False      correctly predicted no escalation\n",
       "72        False        False      correctly predicted no escalation\n",
       "73        False        False      correctly predicted no escalation\n",
       "74        False        False      correctly predicted no escalation\n",
       "75         True        False        wrongly predicted no escalation\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Classification \"Correctness\" for ffnn\n",
    "threshold = 0.5 # using default classification threshold\n",
    "\n",
    "df_new['ffnn_classifcation_performance_outcome'] = None\n",
    "\n",
    "tmp = df_new['ffnn_classifcation_performance_outcome'].copy()\n",
    "TP_pos_pred_correct = df_new.y_true_transformer & (df_new.y_pred_proba_transformer>threshold)\n",
    "tmp[TP_pos_pred_correct] = \"correctly predicted escalation\"\n",
    "TN_neg_pred_correct = (~df_new.y_true_transformer) & (df_new.y_pred_proba_transformer<=threshold)\n",
    "tmp[TN_neg_pred_correct] = \"correctly predicted no escalation\"\n",
    "FP_pos_pred_wrong = (~df_new.y_true_transformer) & (df_new.y_pred_proba_transformer>threshold)\n",
    "tmp[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df_new.y_true_transformer & (df_new.y_pred_proba_transformer<=threshold)\n",
    "tmp[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df_new['ffnn_classifcation_performance_outcome'] = tmp\n",
    "df_new[['y_true_ffnn','y_pred_ffnn','ffnn_classifcation_performance_outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "864496bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correctly predicted no escalation    33\n",
       "wrongly predicted escalation         31\n",
       "correctly predicted escalation        9\n",
       "wrongly predicted no escalation       3\n",
       "Name: ffnn_classifcation_performance_outcome, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[['y_true_ffnn','y_pred_ffnn','ffnn_classifcation_performance_outcome']].ffnn_classifcation_performance_outcome.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b0067e",
   "metadata": {},
   "source": [
    "# Q4\n",
    "### 4. Perform a one sample hypothesis test of the proportion of a specific Prediction Classification \"Correctness\" category for another of these models using all the data.\n",
    "\n",
    "When performing a hypothesis test you'll need to determine and specify the null hypothesis under consideration; obtain a p-value (either through simulation, or `scipy.stats.binom` or `scipy.stats.ttest_1samp`); and, finally, provide a statement of the degree of evidence against the null hypothesis in the usual manner (of https://www.jcpcarchives.org/userfiles/values-of-p-Inference.jpg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d16edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a2bb733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I choose xgboost to do the one sample hypothesis test, for correctly predicted escalation\n",
    "# Assume correctly predicted escalation's p value is 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a2d2b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yearmonth                                        32\n",
       "fips                                             32\n",
       "y_pred_transformer                               32\n",
       "y_pred_proba_transformer                         32\n",
       "y_true_transformer                               32\n",
       "y_pred_xgboost                                   32\n",
       "y_pred_proba_xgboost                             32\n",
       "y_true_xgboost                                   32\n",
       "y_pred_ffnn                                      32\n",
       "y_pred_proba_ffnn                                32\n",
       "y_true_ffnn                                      32\n",
       "iso3                                             32\n",
       "transformer_probability_prediction_error         32\n",
       "xgboost_probability_prediction_error             32\n",
       "ffnn_probability_prediction_error                32\n",
       "transformer_classifcation_performance_outcome    32\n",
       "xgboost_classifcation_performance_outcome        32\n",
       "ffnn_classifcation_performance_outcome           32\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds[df_preds.transformer_classifcation_performance_outcome == \"correctly predicted escalation\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60abf335",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.466"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep, n =1000,364\n",
    "p = 0.1\n",
    "correct_p = []\n",
    "np.random.seed()\n",
    "for i in range(rep):\n",
    "    sample = np.random.choice([\"correct\",\"incorrect\"], size = n, replace = True, p = [p, 1-p])\n",
    "    sample_prop = np.count_nonzero(sample == \"correct\")/n\n",
    "    correct_p.append(sample_prop)\n",
    "given = 32/364\n",
    "extreme_num = (abs(np.array(correct_p)-p) >= abs(given-p)).sum()\n",
    "p_value = np.round(extreme_num / rep, 3)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbe2f5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This show the No evidence against the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7130ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3dde2e04",
   "metadata": {},
   "source": [
    "## Q5\n",
    "### 5. Consider the \"Progress Indicators\" data and use \"boolean selection\" with one (or more) of the columns to restrict the data to a subset (of rows) of data and repeat either of the (confidence interval and hypothesis testing) analyses above but this time instead only using this specified subset of countries.\n",
    "\n",
    "*Potentially relevant subsets of data that might be of interest could be created on the basis of Human Development Index categories, Fragile States Index categories, World Bank economy categories, etc. (e.g., `'fsi_category', 'hdr_hdicode', 'hdr_region', 'wbi_income_group', 'wbi_lending_category', 'wbi_other_(emu_or_hipc)'`, etc.); or, perhaps by alternative boolean selections based on restricting the data to countries with specific continuous variable values that fall within specified thresholds or limits.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87ecec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_iso3 = ['CHN','SGP','PAK','PHL','IND','IRN','THA','JPN','PRK','KOR','VNM','SAU','ISR','MDV',\n",
    "                 'IDN','TWN','BGD','ARM','MYS','LKA','AFG','IRQ','ARE','QAT','MMR','LBN','SYR','KHM',\n",
    "                'YEM','UZB','NPL','KWT','OMN','MNG','MAC','BHR','JOR','KGZ','LAO']\n",
    "selected_rows = df_preds[df_preds['iso3'].isin(selected_iso3)]\n",
    "df_PI = selected_rows\n",
    "df_PI.to_csv('selected_for_PI.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0787f3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearmonth</th>\n",
       "      <th>fips</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>y_pred_proba_transformer</th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_xgboost</th>\n",
       "      <th>y_pred_proba_xgboost</th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_ffnn</th>\n",
       "      <th>y_pred_proba_ffnn</th>\n",
       "      <th>y_true_ffnn</th>\n",
       "      <th>iso3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202211</td>\n",
       "      <td>UZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.535385</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.660580</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.381938</td>\n",
       "      <td>False</td>\n",
       "      <td>UZB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202212</td>\n",
       "      <td>UZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.538211</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.579952</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.364793</td>\n",
       "      <td>False</td>\n",
       "      <td>UZB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202301</td>\n",
       "      <td>UZ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.204810</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.652542</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.364343</td>\n",
       "      <td>False</td>\n",
       "      <td>UZB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202211</td>\n",
       "      <td>ID</td>\n",
       "      <td>False</td>\n",
       "      <td>0.461546</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.480096</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.398537</td>\n",
       "      <td>False</td>\n",
       "      <td>IDN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202212</td>\n",
       "      <td>ID</td>\n",
       "      <td>False</td>\n",
       "      <td>0.346367</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.589674</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>False</td>\n",
       "      <td>IDN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>202211</td>\n",
       "      <td>JA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.163859</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.205914</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.273060</td>\n",
       "      <td>False</td>\n",
       "      <td>JPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>202212</td>\n",
       "      <td>JA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191392</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.209022</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.272838</td>\n",
       "      <td>False</td>\n",
       "      <td>JPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>202211</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.450048</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.495618</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.365198</td>\n",
       "      <td>False</td>\n",
       "      <td>SAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>202212</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.443690</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.428008</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.366745</td>\n",
       "      <td>False</td>\n",
       "      <td>SAU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>202301</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.315053</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.618117</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.367574</td>\n",
       "      <td>True</td>\n",
       "      <td>SAU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    yearmonth fips  y_pred_transformer  y_pred_proba_transformer  \\\n",
       "0      202211   UZ                True                  0.535385   \n",
       "1      202212   UZ                True                  0.538211   \n",
       "2      202301   UZ               False                  0.204810   \n",
       "3      202211   ID               False                  0.461546   \n",
       "4      202212   ID               False                  0.346367   \n",
       "..        ...  ...                 ...                       ...   \n",
       "71     202211   JA               False                  0.163859   \n",
       "72     202212   JA               False                  0.191392   \n",
       "73     202211   SA               False                  0.450048   \n",
       "74     202212   SA               False                  0.443690   \n",
       "75     202301   SA               False                  0.315053   \n",
       "\n",
       "    y_true_transformer  y_pred_xgboost  y_pred_proba_xgboost  y_true_xgboost  \\\n",
       "0                False            True              0.660580           False   \n",
       "1                False            True              0.579952           False   \n",
       "2                False            True              0.652542           False   \n",
       "3                False           False              0.480096           False   \n",
       "4                False            True              0.589674            True   \n",
       "..                 ...             ...                   ...             ...   \n",
       "71               False           False              0.205914           False   \n",
       "72               False           False              0.209022           False   \n",
       "73               False           False              0.495618            True   \n",
       "74               False           False              0.428008           False   \n",
       "75                True            True              0.618117           False   \n",
       "\n",
       "    y_pred_ffnn  y_pred_proba_ffnn  y_true_ffnn iso3  \n",
       "0         False           0.381938        False  UZB  \n",
       "1         False           0.364793        False  UZB  \n",
       "2         False           0.364343        False  UZB  \n",
       "3         False           0.398537        False  IDN  \n",
       "4         False           0.395459        False  IDN  \n",
       "..          ...                ...          ...  ...  \n",
       "71        False           0.273060        False  JPN  \n",
       "72        False           0.272838        False  JPN  \n",
       "73        False           0.365198        False  SAU  \n",
       "74        False           0.366745        False  SAU  \n",
       "75        False           0.367574         True  SAU  \n",
       "\n",
       "[76 rows x 12 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_PI = pd.read_csv('selected_rows.csv')\n",
    "df_PI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29aba6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearmonth</th>\n",
       "      <th>fips</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>y_pred_proba_transformer</th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_xgboost</th>\n",
       "      <th>y_pred_proba_xgboost</th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_ffnn</th>\n",
       "      <th>y_pred_proba_ffnn</th>\n",
       "      <th>...</th>\n",
       "      <th>fsi_e3:_human_flight_and_brain_drain</th>\n",
       "      <th>fsi_e2:_economic_inequality</th>\n",
       "      <th>fsi_e1:_economy</th>\n",
       "      <th>fsi_p1:_state_legitimacy</th>\n",
       "      <th>fsi_p2:_public_services</th>\n",
       "      <th>fsi_p3:_human_rights</th>\n",
       "      <th>fsi_c1:_security_apparatus</th>\n",
       "      <th>fsi_c2:_factionalized_elites</th>\n",
       "      <th>fsi_x1:_external_intervention</th>\n",
       "      <th>fsi_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202211</td>\n",
       "      <td>UZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.535385</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.660580</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.381938</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202212</td>\n",
       "      <td>UZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.538211</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.579952</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.364793</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202301</td>\n",
       "      <td>UZ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.204810</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.652542</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.364343</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202211</td>\n",
       "      <td>ID</td>\n",
       "      <td>False</td>\n",
       "      <td>0.461546</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.480096</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.398537</td>\n",
       "      <td>...</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202212</td>\n",
       "      <td>ID</td>\n",
       "      <td>False</td>\n",
       "      <td>0.346367</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.589674</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>...</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>202211</td>\n",
       "      <td>JA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.163859</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.205914</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.273060</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>202212</td>\n",
       "      <td>JA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191392</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.209022</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.272838</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>202211</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.450048</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.495618</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.365198</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>202212</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.443690</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.428008</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.366745</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>202301</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.315053</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.618117</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.367574</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Warning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 1343 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    yearmonth fips  y_pred_transformer  y_pred_proba_transformer  \\\n",
       "0      202211   UZ                True                  0.535385   \n",
       "1      202212   UZ                True                  0.538211   \n",
       "2      202301   UZ               False                  0.204810   \n",
       "3      202211   ID               False                  0.461546   \n",
       "4      202212   ID               False                  0.346367   \n",
       "..        ...  ...                 ...                       ...   \n",
       "71     202211   JA               False                  0.163859   \n",
       "72     202212   JA               False                  0.191392   \n",
       "73     202211   SA               False                  0.450048   \n",
       "74     202212   SA               False                  0.443690   \n",
       "75     202301   SA               False                  0.315053   \n",
       "\n",
       "    y_true_transformer  y_pred_xgboost  y_pred_proba_xgboost  y_true_xgboost  \\\n",
       "0                False            True              0.660580           False   \n",
       "1                False            True              0.579952           False   \n",
       "2                False            True              0.652542           False   \n",
       "3                False           False              0.480096           False   \n",
       "4                False            True              0.589674            True   \n",
       "..                 ...             ...                   ...             ...   \n",
       "71               False           False              0.205914           False   \n",
       "72               False           False              0.209022           False   \n",
       "73               False           False              0.495618            True   \n",
       "74               False           False              0.428008           False   \n",
       "75                True            True              0.618117           False   \n",
       "\n",
       "    y_pred_ffnn  y_pred_proba_ffnn  ...  fsi_e3:_human_flight_and_brain_drain  \\\n",
       "0         False           0.381938  ...                                   4.8   \n",
       "1         False           0.364793  ...                                   4.8   \n",
       "2         False           0.364343  ...                                   4.8   \n",
       "3         False           0.398537  ...                                   5.7   \n",
       "4         False           0.395459  ...                                   5.7   \n",
       "..          ...                ...  ...                                   ...   \n",
       "71        False           0.273060  ...                                   2.7   \n",
       "72        False           0.272838  ...                                   2.7   \n",
       "73        False           0.365198  ...                                   2.7   \n",
       "74        False           0.366745  ...                                   2.7   \n",
       "75        False           0.367574  ...                                   2.7   \n",
       "\n",
       "   fsi_e2:_economic_inequality  fsi_e1:_economy  fsi_p1:_state_legitimacy  \\\n",
       "0                          5.3              5.1                       9.0   \n",
       "1                          5.3              5.1                       9.0   \n",
       "2                          5.3              5.1                       9.0   \n",
       "3                          4.4              4.1                       4.7   \n",
       "4                          4.4              4.1                       4.7   \n",
       "..                         ...              ...                       ...   \n",
       "71                         2.9              3.5                       0.3   \n",
       "72                         2.9              3.5                       0.3   \n",
       "73                         4.8              3.6                       7.6   \n",
       "74                         4.8              3.6                       7.6   \n",
       "75                         4.8              3.6                       7.6   \n",
       "\n",
       "    fsi_p2:_public_services  fsi_p3:_human_rights  fsi_c1:_security_apparatus  \\\n",
       "0                       4.0                   7.3                         5.6   \n",
       "1                       4.0                   7.3                         5.6   \n",
       "2                       4.0                   7.3                         5.6   \n",
       "3                       5.9                   6.5                         5.2   \n",
       "4                       5.9                   6.5                         5.2   \n",
       "..                      ...                   ...                         ...   \n",
       "71                      1.8                   2.8                         1.5   \n",
       "72                      1.8                   2.8                         1.5   \n",
       "73                      3.8                   8.1                         5.1   \n",
       "74                      3.8                   8.1                         5.1   \n",
       "75                      3.8                   8.1                         5.1   \n",
       "\n",
       "    fsi_c2:_factionalized_elites  fsi_x1:_external_intervention  fsi_category  \n",
       "0                            8.8                            3.4       Warning  \n",
       "1                            8.8                            3.4       Warning  \n",
       "2                            8.8                            3.4       Warning  \n",
       "3                            7.1                            3.7       Warning  \n",
       "4                            7.1                            3.7       Warning  \n",
       "..                           ...                            ...           ...  \n",
       "71                           2.6                            2.0        Stable  \n",
       "72                           2.6                            2.0        Stable  \n",
       "73                           8.5                            4.1       Warning  \n",
       "74                           8.5                            4.1       Warning  \n",
       "75                           8.5                            4.1       Warning  \n",
       "\n",
       "[76 rows x 1343 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_PI.merge(df_indicators, left_on='iso3', right_on='iso3', how='inner')\n",
    "df #the DataFrame of asian countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a37df67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Warning    41\n",
       "Alert      18\n",
       "Stable     17\n",
       "Name: fsi_category, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fsi_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d2a6330b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5394736842105263"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "41/76\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9ff1927",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here I want to use the fsi_category as the item to Hypothesis testing\n",
    "## Null hypothesis: assume the p_value of Warning condition in Asian country is 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b64c201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.592"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep, n = 1000, 76\n",
    "p = 0.5\n",
    "warn_list = []\n",
    "np.random.seed()\n",
    "for i in range(rep):\n",
    "    sample = np.random.choice(['Warning','unWarning'],size = n, replace = True, p = [p,1-p])\n",
    "    sample_prop = np.count_nonzero(sample == 'Warning')/n\n",
    "    warn_list.append(sample_prop)\n",
    "given = 41/76\n",
    "extreme = (abs(np.array(warn_list) - p) >= abs (given - p)).sum()\n",
    "p_value = np.round(extreme/rep,3)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "213a9af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40723684, 0.60526316])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(warn_list,[0.05,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaf19ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8fbc0fe",
   "metadata": {},
   "source": [
    "## Q6\n",
    "### 6. (and 7.) Create a two-sample bootstrap confidence interval and perform a hypothesis test comparing the performance of a single model for the data subset created above versus the remaining data not included in that data subset.\n",
    "\n",
    "  - A two-sample bootstrap confidence interval is created by repeatedly creating a \"'pair\" of bootrapped samples\" by making a single bootstrap sample for one of the two data subsets individually, and then the other, and then those two \"single sample\" bootstrapped stamples together make up the \"'pair\" of bootrapped samples\".\n",
    "  <br><br>\n",
    "    \n",
    "  - A hypothesis test for two (\"unpaired\") samples can be carried out on the basis of permutating shuffling group membership (while ensuring that the original subset sample sizes remain unchanged) in order to create a sampling distribution under a null hypothesis assumption of \"no difference between groups\", or based on `scipy.stats.median_test` which assumes the *medians* of the two groups are identical (or the more powerful `scipy.stats.mannwhitneyu` which again assumes \"no difference between groups\"), or `scipy.stats.ttest_ind` which assumes the *means* of the two groups are identical (and that the samples come from normally distributed populations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d8e8b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00075514 0.03995951]\n"
     ]
    }
   ],
   "source": [
    "rep = 1000\n",
    "bootstrap_differences = np.zeros(rep)\n",
    "group1 = df['y_pred_proba_ffnn'][df['fsi_category'] == 'Warning']\n",
    "group2 = df['y_pred_proba_ffnn'][df['fsi_category'] != 'Warning']\n",
    "for i in range(rep):\n",
    "    sample1 = group1.sample(frac=1, replace=True)\n",
    "    sample2 = group2.sample(frac=1, replace=True)\n",
    "    difference = sample1.mean() - sample2.mean()\n",
    "    bootstrap_differences[i] = abs(difference)\n",
    "confidence_interval = np.percentile(bootstrap_differences, [2.5, 97.5])\n",
    "print(confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ff52502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.856\n"
     ]
    }
   ],
   "source": [
    "observed_difference = group1.mean() - group2.mean()\n",
    "differences = np.zeros(rep)\n",
    "for i in range(rep):\n",
    "    combined_sample = df['y_pred_proba_ffnn'].sample(frac=1, replace=True)\n",
    "    new_group1 = combined_sample[df['fsi_category'] == 'Warning']\n",
    "    new_group2 = combined_sample[df['fsi_category'] != 'Warning']\n",
    "    difference = new_group1.mean() - new_group2.mean()\n",
    "    differences[i] = abs(difference)\n",
    "\n",
    "p_value = (differences >= observed_difference).mean()\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b153beaa",
   "metadata": {},
   "source": [
    "## Q8 and Q9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f77df4",
   "metadata": {},
   "source": [
    "> 8. (and 9.) Create a bootstrap confidence interval and a hypothesis test comparing the performance of two the models across all the data on the basis of a \"paired\" sample analysis (by transforming the paired sample into a single $z_i=x_i-y_i$ difference sample).\n",
    "    - A bootstrap confidence interval is created by bootrapping from the sample of \"paired differences\"; whereas, the sampling distribution of the null hypothesis of \"the group an observation belongs to doesn't matter\" can be constructed using a permutation shuffling approach which randomly reassigns the sample membership within each of the paired samples. Functions performing theoretical nonparametric and parametric \"paired\" sample analyses are `scipy.stats.wilcoxon` and `scipy.stats.ttest_rel`, where the null hypothesis of the former assumes the slightly different \"no tendency for one of the samples in the pair to be larger than the other\", while the null hypothesis of the latter assumes \"no difference on average\" between the pairs (and that the samples come from normally distributed populations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f2890959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.200968    0.10393999]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# arbitrary simulation parameters\n",
    "n,R = 5,100\n",
    "results=[]\n",
    "# a first \"sample\"\n",
    "sample_1 = df_new['y_pred_proba_transformer']\n",
    "# a second \"sample\"\n",
    "sample_2 = df_new['y_pred_proba_xgboost']\n",
    "\n",
    "# \"paired\" samples analysis\n",
    "sample_difference = sample_1 - sample_2\n",
    "\n",
    "# bootstrapping a \"paired\" sample\n",
    "for rep in range(R):\n",
    "    bootstrap_sample = np.random.choice(sample_difference, size=n)\n",
    "    aver = bootstrap_sample.mean()\n",
    "    results.append(aver)\n",
    "\n",
    "ci = np.percentile(results, [2.5, 97.5])\n",
    "print(ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f57fc09",
   "metadata": {},
   "source": [
    "## Q10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cfe02e",
   "metadata": {},
   "source": [
    "XGBoost is a model based on gradient boosting trees, mainly used to solve classification and regression problems, especially suitable for structured data. This modal is simpler and easier to understand compared to other two modals.\n",
    "FFNN is a feedforward neural network-based model that is commonly used on various types of data, including structured and unstructured data such as images, text, and time series data.\n",
    "Transformer is a deep learning model for processing sequence data, especially suitable for natural language processing (NLP) and machine translation tasks. This is more complicated and difficult to understand.\n",
    "\n",
    "Specifically, they calculated the error between each model’s classification probability prediction and the true label, and classified the predictions into the following four categories:\n",
    "\n",
    "> Correctly predicting upgrades: The model correctly predicted positive classes (upgrades).\n",
    "Correct prediction without upgrading: The model correctly predicted the negative class (without upgrading).\n",
    "Wrong prediction upgrade: The model incorrectly predicts the sample as a positive category.\n",
    "Wrong predictions are not upgraded: The model incorrectly predicts samples as negative categories.\n",
    "\n",
    "Specifically, each model's performance in four categories can be observed to understand its classification performance. Generally, better-performing models have higher proportions in the Correctly Predicted Upgrades and Correctly Predicted No Upgrades categories, and lower proportions in the \"Incorrectly Predicted Upgrades\" and \"Incorrectly Predicted No Upgrades\" categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a972f3",
   "metadata": {},
   "source": [
    "### how to find the difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bba3ff",
   "metadata": {},
   "source": [
    "Classification accuracy:\n",
    "\n",
    ">Assume that in this binary classification task, XGBoost has an accuracy of 90%, FFNN has an accuracy of 85%, and Transformer has an accuracy of 80%. In this case, XGBoost performs best, followed by FFNN and finally Transformer. \n",
    "This shows that XGBoost achieves better classification performance on this task.\n",
    "\n",
    "Error in predicted probability:\n",
    "\n",
    ">Assume that in this certain regression task, the mean absolute error (MAE) of XGBoost is 5, the MAE of FFNN is 7, and the MAE of Transformer is 8. A lower MAE value means that XGBoost's probability prediction is closer to the actual value, so XGBoost performs better in terms of probability prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3903d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a79d4a1",
   "metadata": {},
   "source": [
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40df5065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearmonth</th>\n",
       "      <th>fips</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>y_pred_proba_transformer</th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_xgboost</th>\n",
       "      <th>y_pred_proba_xgboost</th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_ffnn</th>\n",
       "      <th>y_pred_proba_ffnn</th>\n",
       "      <th>...</th>\n",
       "      <th>fsi_e3:_human_flight_and_brain_drain</th>\n",
       "      <th>fsi_e2:_economic_inequality</th>\n",
       "      <th>fsi_e1:_economy</th>\n",
       "      <th>fsi_p1:_state_legitimacy</th>\n",
       "      <th>fsi_p2:_public_services</th>\n",
       "      <th>fsi_p3:_human_rights</th>\n",
       "      <th>fsi_c1:_security_apparatus</th>\n",
       "      <th>fsi_c2:_factionalized_elites</th>\n",
       "      <th>fsi_x1:_external_intervention</th>\n",
       "      <th>fsi_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202211</td>\n",
       "      <td>UZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.535385</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.660580</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.381938</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202212</td>\n",
       "      <td>UZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.538211</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.579952</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.364793</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202301</td>\n",
       "      <td>UZ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.204810</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.652542</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.364343</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202211</td>\n",
       "      <td>ID</td>\n",
       "      <td>False</td>\n",
       "      <td>0.461546</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.480096</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.398537</td>\n",
       "      <td>...</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202212</td>\n",
       "      <td>ID</td>\n",
       "      <td>False</td>\n",
       "      <td>0.346367</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.589674</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>...</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>202211</td>\n",
       "      <td>JA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.163859</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.205914</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.273060</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>202212</td>\n",
       "      <td>JA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191392</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.209022</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.272838</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Stable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>202211</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.450048</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.495618</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.365198</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>202212</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.443690</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.428008</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.366745</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Warning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>202301</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.315053</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.618117</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.367574</td>\n",
       "      <td>...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Warning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 1343 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    yearmonth fips  y_pred_transformer  y_pred_proba_transformer  \\\n",
       "0      202211   UZ                True                  0.535385   \n",
       "1      202212   UZ                True                  0.538211   \n",
       "2      202301   UZ               False                  0.204810   \n",
       "3      202211   ID               False                  0.461546   \n",
       "4      202212   ID               False                  0.346367   \n",
       "..        ...  ...                 ...                       ...   \n",
       "71     202211   JA               False                  0.163859   \n",
       "72     202212   JA               False                  0.191392   \n",
       "73     202211   SA               False                  0.450048   \n",
       "74     202212   SA               False                  0.443690   \n",
       "75     202301   SA               False                  0.315053   \n",
       "\n",
       "    y_true_transformer  y_pred_xgboost  y_pred_proba_xgboost  y_true_xgboost  \\\n",
       "0                False            True              0.660580           False   \n",
       "1                False            True              0.579952           False   \n",
       "2                False            True              0.652542           False   \n",
       "3                False           False              0.480096           False   \n",
       "4                False            True              0.589674            True   \n",
       "..                 ...             ...                   ...             ...   \n",
       "71               False           False              0.205914           False   \n",
       "72               False           False              0.209022           False   \n",
       "73               False           False              0.495618            True   \n",
       "74               False           False              0.428008           False   \n",
       "75                True            True              0.618117           False   \n",
       "\n",
       "    y_pred_ffnn  y_pred_proba_ffnn  ...  fsi_e3:_human_flight_and_brain_drain  \\\n",
       "0         False           0.381938  ...                                   4.8   \n",
       "1         False           0.364793  ...                                   4.8   \n",
       "2         False           0.364343  ...                                   4.8   \n",
       "3         False           0.398537  ...                                   5.7   \n",
       "4         False           0.395459  ...                                   5.7   \n",
       "..          ...                ...  ...                                   ...   \n",
       "71        False           0.273060  ...                                   2.7   \n",
       "72        False           0.272838  ...                                   2.7   \n",
       "73        False           0.365198  ...                                   2.7   \n",
       "74        False           0.366745  ...                                   2.7   \n",
       "75        False           0.367574  ...                                   2.7   \n",
       "\n",
       "   fsi_e2:_economic_inequality  fsi_e1:_economy  fsi_p1:_state_legitimacy  \\\n",
       "0                          5.3              5.1                       9.0   \n",
       "1                          5.3              5.1                       9.0   \n",
       "2                          5.3              5.1                       9.0   \n",
       "3                          4.4              4.1                       4.7   \n",
       "4                          4.4              4.1                       4.7   \n",
       "..                         ...              ...                       ...   \n",
       "71                         2.9              3.5                       0.3   \n",
       "72                         2.9              3.5                       0.3   \n",
       "73                         4.8              3.6                       7.6   \n",
       "74                         4.8              3.6                       7.6   \n",
       "75                         4.8              3.6                       7.6   \n",
       "\n",
       "    fsi_p2:_public_services  fsi_p3:_human_rights  fsi_c1:_security_apparatus  \\\n",
       "0                       4.0                   7.3                         5.6   \n",
       "1                       4.0                   7.3                         5.6   \n",
       "2                       4.0                   7.3                         5.6   \n",
       "3                       5.9                   6.5                         5.2   \n",
       "4                       5.9                   6.5                         5.2   \n",
       "..                      ...                   ...                         ...   \n",
       "71                      1.8                   2.8                         1.5   \n",
       "72                      1.8                   2.8                         1.5   \n",
       "73                      3.8                   8.1                         5.1   \n",
       "74                      3.8                   8.1                         5.1   \n",
       "75                      3.8                   8.1                         5.1   \n",
       "\n",
       "    fsi_c2:_factionalized_elites  fsi_x1:_external_intervention  fsi_category  \n",
       "0                            8.8                            3.4       Warning  \n",
       "1                            8.8                            3.4       Warning  \n",
       "2                            8.8                            3.4       Warning  \n",
       "3                            7.1                            3.7       Warning  \n",
       "4                            7.1                            3.7       Warning  \n",
       "..                           ...                            ...           ...  \n",
       "71                           2.6                            2.0        Stable  \n",
       "72                           2.6                            2.0        Stable  \n",
       "73                           8.5                            4.1       Warning  \n",
       "74                           8.5                            4.1       Warning  \n",
       "75                           8.5                            4.1       Warning  \n",
       "\n",
       "[76 rows x 1343 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_PI.merge(df_indicators, left_on='iso3', right_on='iso3', how='inner')\n",
    "df #the DataFrame of asian countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b87fae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_proba_transformer</th>\n",
       "      <th>transformer_probability_prediction_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.535385</td>\n",
       "      <td>0.535385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0.538211</td>\n",
       "      <td>0.538211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0.204810</td>\n",
       "      <td>0.204810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0.461546</td>\n",
       "      <td>0.461546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0.346367</td>\n",
       "      <td>0.346367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>False</td>\n",
       "      <td>0.163859</td>\n",
       "      <td>0.163859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>False</td>\n",
       "      <td>0.191392</td>\n",
       "      <td>0.191392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>False</td>\n",
       "      <td>0.450048</td>\n",
       "      <td>0.450048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>False</td>\n",
       "      <td>0.443690</td>\n",
       "      <td>0.443690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>True</td>\n",
       "      <td>0.315053</td>\n",
       "      <td>0.684947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_true_transformer  y_pred_proba_transformer  \\\n",
       "0                False                  0.535385   \n",
       "1                False                  0.538211   \n",
       "2                False                  0.204810   \n",
       "3                False                  0.461546   \n",
       "4                False                  0.346367   \n",
       "..                 ...                       ...   \n",
       "71               False                  0.163859   \n",
       "72               False                  0.191392   \n",
       "73               False                  0.450048   \n",
       "74               False                  0.443690   \n",
       "75                True                  0.315053   \n",
       "\n",
       "    transformer_probability_prediction_error  \n",
       "0                                   0.535385  \n",
       "1                                   0.538211  \n",
       "2                                   0.204810  \n",
       "3                                   0.461546  \n",
       "4                                   0.346367  \n",
       "..                                       ...  \n",
       "71                                  0.163859  \n",
       "72                                  0.191392  \n",
       "73                                  0.450048  \n",
       "74                                  0.443690  \n",
       "75                                  0.684947  \n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Probability \"Error\" for transformer\n",
    "df['transformer_probability_prediction_error'] = np.abs(df['y_true_transformer'].astype(float) - df['y_pred_proba_transformer'])\n",
    "df[['y_true_transformer','y_pred_proba_transformer','transformer_probability_prediction_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c1883bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_proba_xgboost</th>\n",
       "      <th>xgboost_probability_prediction_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.660580</td>\n",
       "      <td>0.660580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0.579952</td>\n",
       "      <td>0.579952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0.652542</td>\n",
       "      <td>0.652542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0.480096</td>\n",
       "      <td>0.480096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>0.589674</td>\n",
       "      <td>0.410326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>False</td>\n",
       "      <td>0.205914</td>\n",
       "      <td>0.205914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>False</td>\n",
       "      <td>0.209022</td>\n",
       "      <td>0.209022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>True</td>\n",
       "      <td>0.495618</td>\n",
       "      <td>0.504382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>False</td>\n",
       "      <td>0.428008</td>\n",
       "      <td>0.428008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>False</td>\n",
       "      <td>0.618117</td>\n",
       "      <td>0.618117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_true_xgboost  y_pred_proba_xgboost  xgboost_probability_prediction_error\n",
       "0            False              0.660580                              0.660580\n",
       "1            False              0.579952                              0.579952\n",
       "2            False              0.652542                              0.652542\n",
       "3            False              0.480096                              0.480096\n",
       "4             True              0.589674                              0.410326\n",
       "..             ...                   ...                                   ...\n",
       "71           False              0.205914                              0.205914\n",
       "72           False              0.209022                              0.209022\n",
       "73            True              0.495618                              0.504382\n",
       "74           False              0.428008                              0.428008\n",
       "75           False              0.618117                              0.618117\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Probability \"Error\" for xgboost\n",
    "df['xgboost_probability_prediction_error'] = np.abs(df['y_true_xgboost'].astype(float) - df['y_pred_proba_xgboost'])\n",
    "df[['y_true_xgboost','y_pred_proba_xgboost','xgboost_probability_prediction_error']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72d51229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_ffnn</th>\n",
       "      <th>y_pred_proba_ffnn</th>\n",
       "      <th>ffnn_probability_prediction_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>0.381938</td>\n",
       "      <td>0.381938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>0.364793</td>\n",
       "      <td>0.364793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>0.364343</td>\n",
       "      <td>0.364343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0.398537</td>\n",
       "      <td>0.398537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>0.395459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>False</td>\n",
       "      <td>0.273060</td>\n",
       "      <td>0.273060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>False</td>\n",
       "      <td>0.272838</td>\n",
       "      <td>0.272838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>False</td>\n",
       "      <td>0.365198</td>\n",
       "      <td>0.365198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>False</td>\n",
       "      <td>0.366745</td>\n",
       "      <td>0.366745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>True</td>\n",
       "      <td>0.367574</td>\n",
       "      <td>0.632426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_true_ffnn  y_pred_proba_ffnn  ffnn_probability_prediction_error\n",
       "0         False           0.381938                           0.381938\n",
       "1         False           0.364793                           0.364793\n",
       "2         False           0.364343                           0.364343\n",
       "3         False           0.398537                           0.398537\n",
       "4         False           0.395459                           0.395459\n",
       "..          ...                ...                                ...\n",
       "71        False           0.273060                           0.273060\n",
       "72        False           0.272838                           0.272838\n",
       "73        False           0.365198                           0.365198\n",
       "74        False           0.366745                           0.366745\n",
       "75         True           0.367574                           0.632426\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Probability \"Error\" for ffnn\n",
    "df['ffnn_probability_prediction_error'] = np.abs(df['y_true_ffnn'].astype(float) - df['y_pred_proba_ffnn'])\n",
    "df[['y_true_ffnn','y_pred_proba_ffnn','ffnn_probability_prediction_error']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1785b19",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4de28a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39869129, 0.43625163])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I choose ffnn to do the bootsrap confidence interval for 90%\n",
    "np.random.seed(100)\n",
    "rep, n = 1000,76\n",
    "my_bootstrapped_sample_means = np.zeros(rep)\n",
    "for i in range(rep):\n",
    "    my_bootstrap_sample_ffnn = np.random.choice(df.ffnn_probability_prediction_error,replace=True, size=n)\n",
    "    my_bootstrapped_sample_means[i] = my_bootstrap_sample_ffnn.mean()\n",
    "np.quantile(my_bootstrapped_sample_means, [0.05,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4d071491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0373"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.436-0.3987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "111b8510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29890241, 0.63893247])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I choose xgboost to do the bootsrap confidence interval for 90%\n",
    "np.random.seed(100)\n",
    "rep, n = 1000,76\n",
    "my_bootstrapped_sample_means = np.zeros(rep)\n",
    "for i in range(rep):\n",
    "    my_bootstrap_sample_xgboost = np.random.choice(df.xgboost_probability_prediction_error,replace=True, size=n)\n",
    "    my_bootstrapped_sample_means[i] = my_bootstrap_sample_xgboost.mean()\n",
    "np.quantile(my_bootstrap_sample_ffnn, [0.05,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c8194a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.6389-0.2989"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2b9f1e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.43941822, 0.51012663])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I choose transformer to do the bootsrap confidence interval for 90%\n",
    "np.random.seed(100)\n",
    "rep, n = 1000,76\n",
    "my_bootstrapped_sample_means = np.zeros(rep)\n",
    "for i in range(rep):\n",
    "    my_bootstrap_sample_transformer = np.random.choice(df.transformer_probability_prediction_error,replace=True, size=n)\n",
    "    my_bootstrapped_sample_means[i] = my_bootstrap_sample_transformer.mean()\n",
    "np.quantile(my_bootstrapped_sample_means, [0.05,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7accf0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07069999999999999"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5101-0.4394"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01534f9",
   "metadata": {},
   "source": [
    "# Step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3da5c984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>transformer_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_true_transformer  y_pred_transformer  \\\n",
       "0                False                True   \n",
       "1                False                True   \n",
       "2                False               False   \n",
       "3                False               False   \n",
       "4                False               False   \n",
       "..                 ...                 ...   \n",
       "71               False               False   \n",
       "72               False               False   \n",
       "73               False               False   \n",
       "74               False               False   \n",
       "75                True               False   \n",
       "\n",
       "   transformer_classifcation_performance_outcome  \n",
       "0                   wrongly predicted escalation  \n",
       "1                   wrongly predicted escalation  \n",
       "2              correctly predicted no escalation  \n",
       "3              correctly predicted no escalation  \n",
       "4              correctly predicted no escalation  \n",
       "..                                           ...  \n",
       "71             correctly predicted no escalation  \n",
       "72             correctly predicted no escalation  \n",
       "73             correctly predicted no escalation  \n",
       "74             correctly predicted no escalation  \n",
       "75               wrongly predicted no escalation  \n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Classification \"Correctness\" for transformer\n",
    "threshold = 0.5 # using default classification threshold\n",
    "\n",
    "df['transformer_classifcation_performance_outcome'] = None\n",
    "\n",
    "tmp = df_new['transformer_classifcation_performance_outcome'].copy()\n",
    "TP_pos_pred_correct = df.y_true_transformer & (df.y_pred_proba_transformer>threshold)\n",
    "tmp[TP_pos_pred_correct] = \"correctly predicted escalation\"\n",
    "TN_neg_pred_correct = (~df.y_true_transformer) & (df.y_pred_proba_transformer<=threshold)\n",
    "tmp[TN_neg_pred_correct] = \"correctly predicted no escalation\"\n",
    "FP_pos_pred_wrong = (~df.y_true_transformer) & (df.y_pred_proba_transformer>threshold)\n",
    "tmp[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df.y_true_transformer & (df.y_pred_proba_transformer<=threshold)\n",
    "tmp[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df['transformer_classifcation_performance_outcome'] = tmp\n",
    "df[['y_true_transformer','y_pred_transformer','transformer_classifcation_performance_outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c10fba0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = ConfusionMatrixDisplay.from_predictions(df.y_true_transformer, df.y_pred_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2af6f35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_xgboost</th>\n",
       "      <th>xgboost_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_true_xgboost  y_pred_xgboost xgboost_classifcation_performance_outcome\n",
       "0            False            True              wrongly predicted escalation\n",
       "1            False            True              wrongly predicted escalation\n",
       "2            False            True         correctly predicted no escalation\n",
       "3            False           False         correctly predicted no escalation\n",
       "4             True            True         correctly predicted no escalation\n",
       "..             ...             ...                                       ...\n",
       "71           False           False         correctly predicted no escalation\n",
       "72           False           False         correctly predicted no escalation\n",
       "73            True           False         correctly predicted no escalation\n",
       "74           False           False         correctly predicted no escalation\n",
       "75           False            True           wrongly predicted no escalation\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Classification \"Correctness\" for xgboost\n",
    "threshold = 0.5 # using default classification threshold\n",
    "\n",
    "df['xgboost_classifcation_performance_outcome'] = None\n",
    "\n",
    "tmp = df['xgboost_classifcation_performance_outcome'].copy()\n",
    "TP_pos_pred_correct = df.y_true_transformer & (df.y_pred_proba_transformer>threshold)\n",
    "tmp[TP_pos_pred_correct] = \"correctly predicted escalation\"\n",
    "TN_neg_pred_correct = (~df.y_true_transformer) & (df.y_pred_proba_transformer<=threshold)\n",
    "tmp[TN_neg_pred_correct] = \"correctly predicted no escalation\"\n",
    "FP_pos_pred_wrong = (~df.y_true_transformer) & (df.y_pred_proba_transformer>threshold)\n",
    "tmp[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df.y_true_transformer & (df.y_pred_proba_transformer<=threshold)\n",
    "tmp[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df['xgboost_classifcation_performance_outcome'] = tmp\n",
    "df[['y_true_xgboost','y_pred_xgboost','xgboost_classifcation_performance_outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dda2eb86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = ConfusionMatrixDisplay.from_predictions(df.y_true_xgboost, df.y_pred_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "78eb6ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true_ffnn</th>\n",
       "      <th>y_pred_ffnn</th>\n",
       "      <th>ffnn_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_true_ffnn  y_pred_ffnn ffnn_classifcation_performance_outcome\n",
       "0         False        False           wrongly predicted escalation\n",
       "1         False        False           wrongly predicted escalation\n",
       "2         False        False      correctly predicted no escalation\n",
       "3         False        False      correctly predicted no escalation\n",
       "4         False        False      correctly predicted no escalation\n",
       "..          ...          ...                                    ...\n",
       "71        False        False      correctly predicted no escalation\n",
       "72        False        False      correctly predicted no escalation\n",
       "73        False        False      correctly predicted no escalation\n",
       "74        False        False      correctly predicted no escalation\n",
       "75         True        False        wrongly predicted no escalation\n",
       "\n",
       "[76 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Classification \"Correctness\" for ffnn\n",
    "threshold = 0.5 # using default classification threshold\n",
    "\n",
    "df['ffnn_classifcation_performance_outcome'] = None\n",
    "\n",
    "tmp = df['ffnn_classifcation_performance_outcome'].copy()\n",
    "TP_pos_pred_correct = df.y_true_transformer & (df.y_pred_proba_transformer>threshold)\n",
    "tmp[TP_pos_pred_correct] = \"correctly predicted escalation\"\n",
    "TN_neg_pred_correct = (~df.y_true_transformer) & (df.y_pred_proba_transformer<=threshold)\n",
    "tmp[TN_neg_pred_correct] = \"correctly predicted no escalation\"\n",
    "FP_pos_pred_wrong = (~df.y_true_transformer) & (df.y_pred_proba_transformer>threshold)\n",
    "tmp[FP_pos_pred_wrong] = \"wrongly predicted escalation\"\n",
    "FN_neg_pred_wrong = df.y_true_transformer & (df.y_pred_proba_transformer<=threshold)\n",
    "tmp[FN_neg_pred_wrong] = \"wrongly predicted no escalation\"\n",
    "\n",
    "df['ffnn_classifcation_performance_outcome'] = tmp\n",
    "df[['y_true_ffnn','y_pred_ffnn','ffnn_classifcation_performance_outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "eaa4ae76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = ConfusionMatrixDisplay.from_predictions(df.y_true_ffnn, df.y_pred_ffnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eda404",
   "metadata": {},
   "source": [
    "# Step3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f7d9ea",
   "metadata": {},
   "source": [
    "H0: p = 0.5\\\n",
    "Ha: p not 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f767db5f",
   "metadata": {},
   "source": [
    "ffnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "18edebe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearmonth</th>\n",
       "      <th>fips</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>y_pred_proba_transformer</th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_xgboost</th>\n",
       "      <th>y_pred_proba_xgboost</th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_ffnn</th>\n",
       "      <th>y_pred_proba_ffnn</th>\n",
       "      <th>...</th>\n",
       "      <th>fsi_c1:_security_apparatus</th>\n",
       "      <th>fsi_c2:_factionalized_elites</th>\n",
       "      <th>fsi_x1:_external_intervention</th>\n",
       "      <th>fsi_category</th>\n",
       "      <th>transformer_probability_prediction_error</th>\n",
       "      <th>xgboost_probability_prediction_error</th>\n",
       "      <th>ffnn_probability_prediction_error</th>\n",
       "      <th>transformer_classifcation_performance_outcome</th>\n",
       "      <th>xgboost_classifcation_performance_outcome</th>\n",
       "      <th>ffnn_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202211</td>\n",
       "      <td>UZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.535385</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.660580</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.381938</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.535385</td>\n",
       "      <td>0.660580</td>\n",
       "      <td>0.381938</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202212</td>\n",
       "      <td>UZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.538211</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.579952</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.364793</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.538211</td>\n",
       "      <td>0.579952</td>\n",
       "      <td>0.364793</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202301</td>\n",
       "      <td>UZ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.204810</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.652542</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.364343</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.204810</td>\n",
       "      <td>0.652542</td>\n",
       "      <td>0.364343</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202211</td>\n",
       "      <td>ID</td>\n",
       "      <td>False</td>\n",
       "      <td>0.461546</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.480096</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.398537</td>\n",
       "      <td>...</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.461546</td>\n",
       "      <td>0.480096</td>\n",
       "      <td>0.398537</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202212</td>\n",
       "      <td>ID</td>\n",
       "      <td>False</td>\n",
       "      <td>0.346367</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.589674</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>...</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.346367</td>\n",
       "      <td>0.410326</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202301</td>\n",
       "      <td>ID</td>\n",
       "      <td>False</td>\n",
       "      <td>0.398960</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.488815</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.401349</td>\n",
       "      <td>...</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.398960</td>\n",
       "      <td>0.488815</td>\n",
       "      <td>0.401349</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>202211</td>\n",
       "      <td>JO</td>\n",
       "      <td>False</td>\n",
       "      <td>0.224120</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.414194</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.458932</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.224120</td>\n",
       "      <td>0.414194</td>\n",
       "      <td>0.458932</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>202212</td>\n",
       "      <td>JO</td>\n",
       "      <td>False</td>\n",
       "      <td>0.222957</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.414615</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.455622</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.777043</td>\n",
       "      <td>0.414615</td>\n",
       "      <td>0.544378</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>202301</td>\n",
       "      <td>JO</td>\n",
       "      <td>False</td>\n",
       "      <td>0.231262</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.577142</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.451574</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.231262</td>\n",
       "      <td>0.422858</td>\n",
       "      <td>0.451574</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>202211</td>\n",
       "      <td>CB</td>\n",
       "      <td>True</td>\n",
       "      <td>0.622624</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.441517</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.394288</td>\n",
       "      <td>...</td>\n",
       "      <td>6.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.622624</td>\n",
       "      <td>0.441517</td>\n",
       "      <td>0.394288</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>202212</td>\n",
       "      <td>CB</td>\n",
       "      <td>False</td>\n",
       "      <td>0.430438</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.495520</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.398258</td>\n",
       "      <td>...</td>\n",
       "      <td>6.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.430438</td>\n",
       "      <td>0.495520</td>\n",
       "      <td>0.398258</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>202211</td>\n",
       "      <td>TH</td>\n",
       "      <td>True</td>\n",
       "      <td>0.603183</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.645155</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.295604</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.396817</td>\n",
       "      <td>0.645155</td>\n",
       "      <td>0.704396</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>202212</td>\n",
       "      <td>TH</td>\n",
       "      <td>True</td>\n",
       "      <td>0.657782</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.642789</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.291629</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.657782</td>\n",
       "      <td>0.642789</td>\n",
       "      <td>0.291629</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>202301</td>\n",
       "      <td>TH</td>\n",
       "      <td>False</td>\n",
       "      <td>0.415332</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.507814</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.297613</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.415332</td>\n",
       "      <td>0.507814</td>\n",
       "      <td>0.297613</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>202211</td>\n",
       "      <td>IN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.542866</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.527862</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.386045</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.542866</td>\n",
       "      <td>0.527862</td>\n",
       "      <td>0.386045</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>202212</td>\n",
       "      <td>IN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.707988</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.550853</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.387514</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.707988</td>\n",
       "      <td>0.449147</td>\n",
       "      <td>0.387514</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>202301</td>\n",
       "      <td>IN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.793501</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.545930</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.384485</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.793501</td>\n",
       "      <td>0.545930</td>\n",
       "      <td>0.384485</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>202211</td>\n",
       "      <td>BG</td>\n",
       "      <td>True</td>\n",
       "      <td>0.619812</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.564092</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.417691</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.619812</td>\n",
       "      <td>0.564092</td>\n",
       "      <td>0.417691</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>202212</td>\n",
       "      <td>BG</td>\n",
       "      <td>True</td>\n",
       "      <td>0.625523</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.552029</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.416145</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.625523</td>\n",
       "      <td>0.552029</td>\n",
       "      <td>0.416145</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>202301</td>\n",
       "      <td>BG</td>\n",
       "      <td>True</td>\n",
       "      <td>0.624302</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.576891</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.428320</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.624302</td>\n",
       "      <td>0.576891</td>\n",
       "      <td>0.428320</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>202211</td>\n",
       "      <td>NP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.541297</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.691555</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.464957</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.458703</td>\n",
       "      <td>0.691555</td>\n",
       "      <td>0.535043</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>202212</td>\n",
       "      <td>NP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.686276</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.668246</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.443688</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.686276</td>\n",
       "      <td>0.668246</td>\n",
       "      <td>0.443688</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>202301</td>\n",
       "      <td>NP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.630345</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.641119</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.521024</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.630345</td>\n",
       "      <td>0.641119</td>\n",
       "      <td>0.521024</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>202211</td>\n",
       "      <td>PK</td>\n",
       "      <td>True</td>\n",
       "      <td>0.792848</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.741170</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.506878</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.792848</td>\n",
       "      <td>0.258830</td>\n",
       "      <td>0.506878</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>202212</td>\n",
       "      <td>PK</td>\n",
       "      <td>True</td>\n",
       "      <td>0.732578</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.704396</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.512946</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.732578</td>\n",
       "      <td>0.704396</td>\n",
       "      <td>0.512946</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>202301</td>\n",
       "      <td>PK</td>\n",
       "      <td>True</td>\n",
       "      <td>0.756767</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.686989</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.509882</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.243233</td>\n",
       "      <td>0.686989</td>\n",
       "      <td>0.490118</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>202211</td>\n",
       "      <td>KG</td>\n",
       "      <td>False</td>\n",
       "      <td>0.448226</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.528620</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.387699</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.448226</td>\n",
       "      <td>0.528620</td>\n",
       "      <td>0.387699</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>202212</td>\n",
       "      <td>KG</td>\n",
       "      <td>False</td>\n",
       "      <td>0.203963</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.457680</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.203963</td>\n",
       "      <td>0.457680</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>202301</td>\n",
       "      <td>KG</td>\n",
       "      <td>False</td>\n",
       "      <td>0.455062</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.450184</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.388959</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.455062</td>\n",
       "      <td>0.450184</td>\n",
       "      <td>0.388959</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>202211</td>\n",
       "      <td>AM</td>\n",
       "      <td>True</td>\n",
       "      <td>0.542433</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.717793</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.301739</td>\n",
       "      <td>...</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.542433</td>\n",
       "      <td>0.717793</td>\n",
       "      <td>0.301739</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>202212</td>\n",
       "      <td>AM</td>\n",
       "      <td>True</td>\n",
       "      <td>0.533778</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.679612</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.299332</td>\n",
       "      <td>...</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.533778</td>\n",
       "      <td>0.679612</td>\n",
       "      <td>0.299332</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>202301</td>\n",
       "      <td>AM</td>\n",
       "      <td>True</td>\n",
       "      <td>0.637691</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.722840</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.296740</td>\n",
       "      <td>...</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.637691</td>\n",
       "      <td>0.722840</td>\n",
       "      <td>0.296740</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>202211</td>\n",
       "      <td>CH</td>\n",
       "      <td>True</td>\n",
       "      <td>0.742436</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.642813</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.307512</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.742436</td>\n",
       "      <td>0.357187</td>\n",
       "      <td>0.307512</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>202212</td>\n",
       "      <td>CH</td>\n",
       "      <td>True</td>\n",
       "      <td>0.771561</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.679547</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.305287</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.771561</td>\n",
       "      <td>0.679547</td>\n",
       "      <td>0.305287</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>202301</td>\n",
       "      <td>CH</td>\n",
       "      <td>True</td>\n",
       "      <td>0.741744</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.596304</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.306314</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.258256</td>\n",
       "      <td>0.596304</td>\n",
       "      <td>0.693686</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>202211</td>\n",
       "      <td>RP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.679475</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.695254</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.414133</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.320525</td>\n",
       "      <td>0.695254</td>\n",
       "      <td>0.585867</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>202212</td>\n",
       "      <td>RP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.620710</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.677803</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.414881</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.620710</td>\n",
       "      <td>0.322197</td>\n",
       "      <td>0.414881</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>202301</td>\n",
       "      <td>RP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.729239</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.641753</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.416434</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.729239</td>\n",
       "      <td>0.641753</td>\n",
       "      <td>0.416434</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>202211</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.450048</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.495618</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.365198</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.450048</td>\n",
       "      <td>0.504382</td>\n",
       "      <td>0.365198</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>202212</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.443690</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.428008</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.366745</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.443690</td>\n",
       "      <td>0.428008</td>\n",
       "      <td>0.366745</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>202301</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.315053</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.618117</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.367574</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.684947</td>\n",
       "      <td>0.618117</td>\n",
       "      <td>0.632426</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41 rows × 1349 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    yearmonth fips  y_pred_transformer  y_pred_proba_transformer  \\\n",
       "0      202211   UZ                True                  0.535385   \n",
       "1      202212   UZ                True                  0.538211   \n",
       "2      202301   UZ               False                  0.204810   \n",
       "3      202211   ID               False                  0.461546   \n",
       "4      202212   ID               False                  0.346367   \n",
       "5      202301   ID               False                  0.398960   \n",
       "12     202211   JO               False                  0.224120   \n",
       "13     202212   JO               False                  0.222957   \n",
       "14     202301   JO               False                  0.231262   \n",
       "24     202211   CB                True                  0.622624   \n",
       "25     202212   CB               False                  0.430438   \n",
       "26     202211   TH                True                  0.603183   \n",
       "27     202212   TH                True                  0.657782   \n",
       "28     202301   TH               False                  0.415332   \n",
       "36     202211   IN                True                  0.542866   \n",
       "37     202212   IN                True                  0.707988   \n",
       "38     202301   IN                True                  0.793501   \n",
       "39     202211   BG                True                  0.619812   \n",
       "40     202212   BG                True                  0.625523   \n",
       "41     202301   BG                True                  0.624302   \n",
       "42     202211   NP                True                  0.541297   \n",
       "43     202212   NP                True                  0.686276   \n",
       "44     202301   NP                True                  0.630345   \n",
       "45     202211   PK                True                  0.792848   \n",
       "46     202212   PK                True                  0.732578   \n",
       "47     202301   PK                True                  0.756767   \n",
       "51     202211   KG               False                  0.448226   \n",
       "52     202212   KG               False                  0.203963   \n",
       "53     202301   KG               False                  0.455062   \n",
       "57     202211   AM                True                  0.542433   \n",
       "58     202212   AM                True                  0.533778   \n",
       "59     202301   AM                True                  0.637691   \n",
       "63     202211   CH                True                  0.742436   \n",
       "64     202212   CH                True                  0.771561   \n",
       "65     202301   CH                True                  0.741744   \n",
       "66     202211   RP                True                  0.679475   \n",
       "67     202212   RP                True                  0.620710   \n",
       "68     202301   RP                True                  0.729239   \n",
       "73     202211   SA               False                  0.450048   \n",
       "74     202212   SA               False                  0.443690   \n",
       "75     202301   SA               False                  0.315053   \n",
       "\n",
       "    y_true_transformer  y_pred_xgboost  y_pred_proba_xgboost  y_true_xgboost  \\\n",
       "0                False            True              0.660580           False   \n",
       "1                False            True              0.579952           False   \n",
       "2                False            True              0.652542           False   \n",
       "3                False           False              0.480096           False   \n",
       "4                False            True              0.589674            True   \n",
       "5                False           False              0.488815           False   \n",
       "12               False           False              0.414194           False   \n",
       "13                True           False              0.414615           False   \n",
       "14               False            True              0.577142            True   \n",
       "24               False           False              0.441517           False   \n",
       "25               False           False              0.495520           False   \n",
       "26                True            True              0.645155           False   \n",
       "27               False            True              0.642789           False   \n",
       "28               False            True              0.507814           False   \n",
       "36               False            True              0.527862           False   \n",
       "37               False            True              0.550853            True   \n",
       "38               False            True              0.545930           False   \n",
       "39               False            True              0.564092           False   \n",
       "40               False            True              0.552029           False   \n",
       "41               False            True              0.576891           False   \n",
       "42                True            True              0.691555           False   \n",
       "43               False            True              0.668246           False   \n",
       "44               False            True              0.641119           False   \n",
       "45               False            True              0.741170            True   \n",
       "46               False            True              0.704396           False   \n",
       "47                True            True              0.686989           False   \n",
       "51               False            True              0.528620           False   \n",
       "52               False           False              0.457680           False   \n",
       "53               False           False              0.450184           False   \n",
       "57               False            True              0.717793           False   \n",
       "58               False            True              0.679612           False   \n",
       "59               False            True              0.722840           False   \n",
       "63               False            True              0.642813            True   \n",
       "64               False            True              0.679547           False   \n",
       "65                True            True              0.596304           False   \n",
       "66                True            True              0.695254           False   \n",
       "67               False            True              0.677803            True   \n",
       "68               False            True              0.641753           False   \n",
       "73               False           False              0.495618            True   \n",
       "74               False           False              0.428008           False   \n",
       "75                True            True              0.618117           False   \n",
       "\n",
       "    y_pred_ffnn  y_pred_proba_ffnn  ...  fsi_c1:_security_apparatus  \\\n",
       "0         False           0.381938  ...                         5.6   \n",
       "1         False           0.364793  ...                         5.6   \n",
       "2         False           0.364343  ...                         5.6   \n",
       "3         False           0.398537  ...                         5.2   \n",
       "4         False           0.395459  ...                         5.2   \n",
       "5         False           0.401349  ...                         5.2   \n",
       "12        False           0.458932  ...                         4.6   \n",
       "13        False           0.455622  ...                         4.6   \n",
       "14        False           0.451574  ...                         4.6   \n",
       "24        False           0.394288  ...                         6.4   \n",
       "25        False           0.398258  ...                         6.4   \n",
       "26        False           0.295604  ...                         8.0   \n",
       "27        False           0.291629  ...                         8.0   \n",
       "28        False           0.297613  ...                         8.0   \n",
       "36        False           0.386045  ...                         6.0   \n",
       "37        False           0.387514  ...                         6.0   \n",
       "38        False           0.384485  ...                         6.0   \n",
       "39        False           0.417691  ...                         6.8   \n",
       "40        False           0.416145  ...                         6.8   \n",
       "41        False           0.428320  ...                         6.8   \n",
       "42        False           0.464957  ...                         5.5   \n",
       "43        False           0.443688  ...                         5.5   \n",
       "44         True           0.521024  ...                         5.5   \n",
       "45         True           0.506878  ...                         7.6   \n",
       "46         True           0.512946  ...                         7.6   \n",
       "47         True           0.509882  ...                         7.6   \n",
       "51        False           0.387699  ...                         5.6   \n",
       "52        False           0.383262  ...                         5.6   \n",
       "53        False           0.388959  ...                         5.6   \n",
       "57        False           0.301739  ...                         5.7   \n",
       "58        False           0.299332  ...                         5.7   \n",
       "59        False           0.296740  ...                         5.7   \n",
       "63        False           0.307512  ...                         4.9   \n",
       "64        False           0.305287  ...                         4.9   \n",
       "65        False           0.306314  ...                         4.9   \n",
       "66        False           0.414133  ...                         9.1   \n",
       "67        False           0.414881  ...                         9.1   \n",
       "68        False           0.416434  ...                         9.1   \n",
       "73        False           0.365198  ...                         5.1   \n",
       "74        False           0.366745  ...                         5.1   \n",
       "75        False           0.367574  ...                         5.1   \n",
       "\n",
       "   fsi_c2:_factionalized_elites  fsi_x1:_external_intervention  fsi_category  \\\n",
       "0                           8.8                            3.4       Warning   \n",
       "1                           8.8                            3.4       Warning   \n",
       "2                           8.8                            3.4       Warning   \n",
       "3                           7.1                            3.7       Warning   \n",
       "4                           7.1                            3.7       Warning   \n",
       "5                           7.1                            3.7       Warning   \n",
       "12                          6.9                            5.9       Warning   \n",
       "13                          6.9                            5.9       Warning   \n",
       "14                          6.9                            5.9       Warning   \n",
       "24                          8.7                            7.0       Warning   \n",
       "25                          8.7                            7.0       Warning   \n",
       "26                          9.7                            2.0       Warning   \n",
       "27                          9.7                            2.0       Warning   \n",
       "28                          9.7                            2.0       Warning   \n",
       "36                          7.3                            3.9       Warning   \n",
       "37                          7.3                            3.9       Warning   \n",
       "38                          7.3                            3.9       Warning   \n",
       "39                          9.3                            4.6       Warning   \n",
       "40                          9.3                            4.6       Warning   \n",
       "41                          9.3                            4.6       Warning   \n",
       "42                          8.8                            5.9       Warning   \n",
       "43                          8.8                            5.9       Warning   \n",
       "44                          8.8                            5.9       Warning   \n",
       "45                          9.3                            8.3       Warning   \n",
       "46                          9.3                            8.3       Warning   \n",
       "47                          9.3                            8.3       Warning   \n",
       "51                          8.2                            6.3       Warning   \n",
       "52                          8.2                            6.3       Warning   \n",
       "53                          8.2                            6.3       Warning   \n",
       "57                          6.4                            7.0       Warning   \n",
       "58                          6.4                            7.0       Warning   \n",
       "59                          6.4                            7.0       Warning   \n",
       "63                          7.2                            2.1       Warning   \n",
       "64                          7.2                            2.1       Warning   \n",
       "65                          7.2                            2.1       Warning   \n",
       "66                          8.0                            5.4       Warning   \n",
       "67                          8.0                            5.4       Warning   \n",
       "68                          8.0                            5.4       Warning   \n",
       "73                          8.5                            4.1       Warning   \n",
       "74                          8.5                            4.1       Warning   \n",
       "75                          8.5                            4.1       Warning   \n",
       "\n",
       "    transformer_probability_prediction_error  \\\n",
       "0                                   0.535385   \n",
       "1                                   0.538211   \n",
       "2                                   0.204810   \n",
       "3                                   0.461546   \n",
       "4                                   0.346367   \n",
       "5                                   0.398960   \n",
       "12                                  0.224120   \n",
       "13                                  0.777043   \n",
       "14                                  0.231262   \n",
       "24                                  0.622624   \n",
       "25                                  0.430438   \n",
       "26                                  0.396817   \n",
       "27                                  0.657782   \n",
       "28                                  0.415332   \n",
       "36                                  0.542866   \n",
       "37                                  0.707988   \n",
       "38                                  0.793501   \n",
       "39                                  0.619812   \n",
       "40                                  0.625523   \n",
       "41                                  0.624302   \n",
       "42                                  0.458703   \n",
       "43                                  0.686276   \n",
       "44                                  0.630345   \n",
       "45                                  0.792848   \n",
       "46                                  0.732578   \n",
       "47                                  0.243233   \n",
       "51                                  0.448226   \n",
       "52                                  0.203963   \n",
       "53                                  0.455062   \n",
       "57                                  0.542433   \n",
       "58                                  0.533778   \n",
       "59                                  0.637691   \n",
       "63                                  0.742436   \n",
       "64                                  0.771561   \n",
       "65                                  0.258256   \n",
       "66                                  0.320525   \n",
       "67                                  0.620710   \n",
       "68                                  0.729239   \n",
       "73                                  0.450048   \n",
       "74                                  0.443690   \n",
       "75                                  0.684947   \n",
       "\n",
       "    xgboost_probability_prediction_error  ffnn_probability_prediction_error  \\\n",
       "0                               0.660580                           0.381938   \n",
       "1                               0.579952                           0.364793   \n",
       "2                               0.652542                           0.364343   \n",
       "3                               0.480096                           0.398537   \n",
       "4                               0.410326                           0.395459   \n",
       "5                               0.488815                           0.401349   \n",
       "12                              0.414194                           0.458932   \n",
       "13                              0.414615                           0.544378   \n",
       "14                              0.422858                           0.451574   \n",
       "24                              0.441517                           0.394288   \n",
       "25                              0.495520                           0.398258   \n",
       "26                              0.645155                           0.704396   \n",
       "27                              0.642789                           0.291629   \n",
       "28                              0.507814                           0.297613   \n",
       "36                              0.527862                           0.386045   \n",
       "37                              0.449147                           0.387514   \n",
       "38                              0.545930                           0.384485   \n",
       "39                              0.564092                           0.417691   \n",
       "40                              0.552029                           0.416145   \n",
       "41                              0.576891                           0.428320   \n",
       "42                              0.691555                           0.535043   \n",
       "43                              0.668246                           0.443688   \n",
       "44                              0.641119                           0.521024   \n",
       "45                              0.258830                           0.506878   \n",
       "46                              0.704396                           0.512946   \n",
       "47                              0.686989                           0.490118   \n",
       "51                              0.528620                           0.387699   \n",
       "52                              0.457680                           0.383262   \n",
       "53                              0.450184                           0.388959   \n",
       "57                              0.717793                           0.301739   \n",
       "58                              0.679612                           0.299332   \n",
       "59                              0.722840                           0.296740   \n",
       "63                              0.357187                           0.307512   \n",
       "64                              0.679547                           0.305287   \n",
       "65                              0.596304                           0.693686   \n",
       "66                              0.695254                           0.585867   \n",
       "67                              0.322197                           0.414881   \n",
       "68                              0.641753                           0.416434   \n",
       "73                              0.504382                           0.365198   \n",
       "74                              0.428008                           0.366745   \n",
       "75                              0.618117                           0.632426   \n",
       "\n",
       "    transformer_classifcation_performance_outcome  \\\n",
       "0                    wrongly predicted escalation   \n",
       "1                    wrongly predicted escalation   \n",
       "2               correctly predicted no escalation   \n",
       "3               correctly predicted no escalation   \n",
       "4               correctly predicted no escalation   \n",
       "5               correctly predicted no escalation   \n",
       "12              correctly predicted no escalation   \n",
       "13                wrongly predicted no escalation   \n",
       "14              correctly predicted no escalation   \n",
       "24                   wrongly predicted escalation   \n",
       "25              correctly predicted no escalation   \n",
       "26                 correctly predicted escalation   \n",
       "27                   wrongly predicted escalation   \n",
       "28              correctly predicted no escalation   \n",
       "36                   wrongly predicted escalation   \n",
       "37                   wrongly predicted escalation   \n",
       "38                   wrongly predicted escalation   \n",
       "39                   wrongly predicted escalation   \n",
       "40                   wrongly predicted escalation   \n",
       "41                   wrongly predicted escalation   \n",
       "42                 correctly predicted escalation   \n",
       "43                   wrongly predicted escalation   \n",
       "44                   wrongly predicted escalation   \n",
       "45                   wrongly predicted escalation   \n",
       "46                   wrongly predicted escalation   \n",
       "47                 correctly predicted escalation   \n",
       "51              correctly predicted no escalation   \n",
       "52              correctly predicted no escalation   \n",
       "53              correctly predicted no escalation   \n",
       "57                   wrongly predicted escalation   \n",
       "58                   wrongly predicted escalation   \n",
       "59                   wrongly predicted escalation   \n",
       "63                   wrongly predicted escalation   \n",
       "64                   wrongly predicted escalation   \n",
       "65                 correctly predicted escalation   \n",
       "66                 correctly predicted escalation   \n",
       "67                   wrongly predicted escalation   \n",
       "68                   wrongly predicted escalation   \n",
       "73              correctly predicted no escalation   \n",
       "74              correctly predicted no escalation   \n",
       "75                wrongly predicted no escalation   \n",
       "\n",
       "    xgboost_classifcation_performance_outcome  \\\n",
       "0                wrongly predicted escalation   \n",
       "1                wrongly predicted escalation   \n",
       "2           correctly predicted no escalation   \n",
       "3           correctly predicted no escalation   \n",
       "4           correctly predicted no escalation   \n",
       "5           correctly predicted no escalation   \n",
       "12          correctly predicted no escalation   \n",
       "13            wrongly predicted no escalation   \n",
       "14          correctly predicted no escalation   \n",
       "24               wrongly predicted escalation   \n",
       "25          correctly predicted no escalation   \n",
       "26             correctly predicted escalation   \n",
       "27               wrongly predicted escalation   \n",
       "28          correctly predicted no escalation   \n",
       "36               wrongly predicted escalation   \n",
       "37               wrongly predicted escalation   \n",
       "38               wrongly predicted escalation   \n",
       "39               wrongly predicted escalation   \n",
       "40               wrongly predicted escalation   \n",
       "41               wrongly predicted escalation   \n",
       "42             correctly predicted escalation   \n",
       "43               wrongly predicted escalation   \n",
       "44               wrongly predicted escalation   \n",
       "45               wrongly predicted escalation   \n",
       "46               wrongly predicted escalation   \n",
       "47             correctly predicted escalation   \n",
       "51          correctly predicted no escalation   \n",
       "52          correctly predicted no escalation   \n",
       "53          correctly predicted no escalation   \n",
       "57               wrongly predicted escalation   \n",
       "58               wrongly predicted escalation   \n",
       "59               wrongly predicted escalation   \n",
       "63               wrongly predicted escalation   \n",
       "64               wrongly predicted escalation   \n",
       "65             correctly predicted escalation   \n",
       "66             correctly predicted escalation   \n",
       "67               wrongly predicted escalation   \n",
       "68               wrongly predicted escalation   \n",
       "73          correctly predicted no escalation   \n",
       "74          correctly predicted no escalation   \n",
       "75            wrongly predicted no escalation   \n",
       "\n",
       "    ffnn_classifcation_performance_outcome  \n",
       "0             wrongly predicted escalation  \n",
       "1             wrongly predicted escalation  \n",
       "2        correctly predicted no escalation  \n",
       "3        correctly predicted no escalation  \n",
       "4        correctly predicted no escalation  \n",
       "5        correctly predicted no escalation  \n",
       "12       correctly predicted no escalation  \n",
       "13         wrongly predicted no escalation  \n",
       "14       correctly predicted no escalation  \n",
       "24            wrongly predicted escalation  \n",
       "25       correctly predicted no escalation  \n",
       "26          correctly predicted escalation  \n",
       "27            wrongly predicted escalation  \n",
       "28       correctly predicted no escalation  \n",
       "36            wrongly predicted escalation  \n",
       "37            wrongly predicted escalation  \n",
       "38            wrongly predicted escalation  \n",
       "39            wrongly predicted escalation  \n",
       "40            wrongly predicted escalation  \n",
       "41            wrongly predicted escalation  \n",
       "42          correctly predicted escalation  \n",
       "43            wrongly predicted escalation  \n",
       "44            wrongly predicted escalation  \n",
       "45            wrongly predicted escalation  \n",
       "46            wrongly predicted escalation  \n",
       "47          correctly predicted escalation  \n",
       "51       correctly predicted no escalation  \n",
       "52       correctly predicted no escalation  \n",
       "53       correctly predicted no escalation  \n",
       "57            wrongly predicted escalation  \n",
       "58            wrongly predicted escalation  \n",
       "59            wrongly predicted escalation  \n",
       "63            wrongly predicted escalation  \n",
       "64            wrongly predicted escalation  \n",
       "65          correctly predicted escalation  \n",
       "66          correctly predicted escalation  \n",
       "67            wrongly predicted escalation  \n",
       "68            wrongly predicted escalation  \n",
       "73       correctly predicted no escalation  \n",
       "74       correctly predicted no escalation  \n",
       "75         wrongly predicted no escalation  \n",
       "\n",
       "[41 rows x 1349 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ffnn\n",
    "data_1 = df[df['fsi_category'] == 'Warning']\n",
    "dataerror_1 = data_1['ffnn_probability_prediction_error']\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d39fce0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3170731707317073"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_1.ffnn_classifcation_performance_outcome == 'correctly predicted no escalation').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "20bdb3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12195121951219512"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_1.ffnn_classifcation_performance_outcome == 'correctly predicted escalation').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2ff226ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.439"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.317+0.122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa85812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4e6adb66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearmonth</th>\n",
       "      <th>fips</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>y_pred_proba_transformer</th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_xgboost</th>\n",
       "      <th>y_pred_proba_xgboost</th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_ffnn</th>\n",
       "      <th>y_pred_proba_ffnn</th>\n",
       "      <th>...</th>\n",
       "      <th>fsi_c1:_security_apparatus</th>\n",
       "      <th>fsi_c2:_factionalized_elites</th>\n",
       "      <th>fsi_x1:_external_intervention</th>\n",
       "      <th>fsi_category</th>\n",
       "      <th>transformer_probability_prediction_error</th>\n",
       "      <th>xgboost_probability_prediction_error</th>\n",
       "      <th>ffnn_probability_prediction_error</th>\n",
       "      <th>transformer_classifcation_performance_outcome</th>\n",
       "      <th>xgboost_classifcation_performance_outcome</th>\n",
       "      <th>ffnn_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202211</td>\n",
       "      <td>IS</td>\n",
       "      <td>True</td>\n",
       "      <td>0.634716</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.738002</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.343657</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.634716</td>\n",
       "      <td>0.738002</td>\n",
       "      <td>0.343657</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202212</td>\n",
       "      <td>IS</td>\n",
       "      <td>True</td>\n",
       "      <td>0.692216</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.711610</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.341547</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.307784</td>\n",
       "      <td>0.711610</td>\n",
       "      <td>0.658453</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202301</td>\n",
       "      <td>IS</td>\n",
       "      <td>True</td>\n",
       "      <td>0.687682</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.608835</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.344979</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.687682</td>\n",
       "      <td>0.391165</td>\n",
       "      <td>0.344979</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202211</td>\n",
       "      <td>LE</td>\n",
       "      <td>True</td>\n",
       "      <td>0.587201</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.669344</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.398378</td>\n",
       "      <td>...</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.587201</td>\n",
       "      <td>0.330656</td>\n",
       "      <td>0.398378</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>202212</td>\n",
       "      <td>LE</td>\n",
       "      <td>True</td>\n",
       "      <td>0.578990</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.536716</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.400631</td>\n",
       "      <td>...</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.578990</td>\n",
       "      <td>0.536716</td>\n",
       "      <td>0.400631</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>202301</td>\n",
       "      <td>LE</td>\n",
       "      <td>True</td>\n",
       "      <td>0.534593</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.690374</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.398455</td>\n",
       "      <td>...</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.465407</td>\n",
       "      <td>0.690374</td>\n",
       "      <td>0.601545</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>202211</td>\n",
       "      <td>QA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.176723</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.070106</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.274388</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.176723</td>\n",
       "      <td>0.070106</td>\n",
       "      <td>0.274388</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>202212</td>\n",
       "      <td>QA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.177739</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.064143</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.271447</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.177739</td>\n",
       "      <td>0.064143</td>\n",
       "      <td>0.271447</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>202211</td>\n",
       "      <td>KU</td>\n",
       "      <td>False</td>\n",
       "      <td>0.174353</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.075832</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.322281</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.174353</td>\n",
       "      <td>0.075832</td>\n",
       "      <td>0.322281</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>202212</td>\n",
       "      <td>KU</td>\n",
       "      <td>False</td>\n",
       "      <td>0.189701</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.074495</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.323783</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.189701</td>\n",
       "      <td>0.074495</td>\n",
       "      <td>0.323783</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>202211</td>\n",
       "      <td>IZ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.266301</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.637357</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.456745</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.266301</td>\n",
       "      <td>0.637357</td>\n",
       "      <td>0.456745</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>202212</td>\n",
       "      <td>IZ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.336891</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.663939</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.460606</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.336891</td>\n",
       "      <td>0.663939</td>\n",
       "      <td>0.460606</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>202301</td>\n",
       "      <td>IZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.572735</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.663939</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.452974</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.572735</td>\n",
       "      <td>0.663939</td>\n",
       "      <td>0.452974</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>202211</td>\n",
       "      <td>MU</td>\n",
       "      <td>False</td>\n",
       "      <td>0.243252</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100111</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.318327</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.243252</td>\n",
       "      <td>0.100111</td>\n",
       "      <td>0.318327</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>202212</td>\n",
       "      <td>MU</td>\n",
       "      <td>False</td>\n",
       "      <td>0.273943</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.129337</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.321544</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.273943</td>\n",
       "      <td>0.129337</td>\n",
       "      <td>0.321544</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>202211</td>\n",
       "      <td>BM</td>\n",
       "      <td>False</td>\n",
       "      <td>0.444116</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.763934</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.395985</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.444116</td>\n",
       "      <td>0.763934</td>\n",
       "      <td>0.395985</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>202212</td>\n",
       "      <td>BM</td>\n",
       "      <td>False</td>\n",
       "      <td>0.449590</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.758278</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.384911</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.449590</td>\n",
       "      <td>0.758278</td>\n",
       "      <td>0.384911</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>202301</td>\n",
       "      <td>BM</td>\n",
       "      <td>True</td>\n",
       "      <td>0.520781</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.764942</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.380714</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.520781</td>\n",
       "      <td>0.764942</td>\n",
       "      <td>0.380714</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>202211</td>\n",
       "      <td>VM</td>\n",
       "      <td>False</td>\n",
       "      <td>0.478212</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.065058</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.345246</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.478212</td>\n",
       "      <td>0.065058</td>\n",
       "      <td>0.345246</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>202212</td>\n",
       "      <td>VM</td>\n",
       "      <td>False</td>\n",
       "      <td>0.237275</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.067476</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.345988</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.237275</td>\n",
       "      <td>0.067476</td>\n",
       "      <td>0.345988</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>202211</td>\n",
       "      <td>MG</td>\n",
       "      <td>False</td>\n",
       "      <td>0.450012</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.405012</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.368454</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.450012</td>\n",
       "      <td>0.405012</td>\n",
       "      <td>0.368454</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>202212</td>\n",
       "      <td>MG</td>\n",
       "      <td>False</td>\n",
       "      <td>0.339055</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.093121</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.366858</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.339055</td>\n",
       "      <td>0.093121</td>\n",
       "      <td>0.366858</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>202211</td>\n",
       "      <td>AF</td>\n",
       "      <td>False</td>\n",
       "      <td>0.357150</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.386776</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.546216</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.357150</td>\n",
       "      <td>0.386776</td>\n",
       "      <td>0.546216</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>202212</td>\n",
       "      <td>AF</td>\n",
       "      <td>True</td>\n",
       "      <td>0.644641</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.533442</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.552699</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.644641</td>\n",
       "      <td>0.533442</td>\n",
       "      <td>0.552699</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>202301</td>\n",
       "      <td>AF</td>\n",
       "      <td>False</td>\n",
       "      <td>0.423742</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.430771</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.551422</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.423742</td>\n",
       "      <td>0.430771</td>\n",
       "      <td>0.551422</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>202211</td>\n",
       "      <td>SY</td>\n",
       "      <td>True</td>\n",
       "      <td>0.518751</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.587173</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.537291</td>\n",
       "      <td>...</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.481249</td>\n",
       "      <td>0.587173</td>\n",
       "      <td>0.462709</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>202212</td>\n",
       "      <td>SY</td>\n",
       "      <td>True</td>\n",
       "      <td>0.602737</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.699577</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.541852</td>\n",
       "      <td>...</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.397263</td>\n",
       "      <td>0.699577</td>\n",
       "      <td>0.458148</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>202301</td>\n",
       "      <td>SY</td>\n",
       "      <td>True</td>\n",
       "      <td>0.546697</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.661985</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.534842</td>\n",
       "      <td>...</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.546697</td>\n",
       "      <td>0.661985</td>\n",
       "      <td>0.534842</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>202211</td>\n",
       "      <td>CE</td>\n",
       "      <td>False</td>\n",
       "      <td>0.445699</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.462320</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.355650</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.554301</td>\n",
       "      <td>0.462320</td>\n",
       "      <td>0.644350</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>202212</td>\n",
       "      <td>CE</td>\n",
       "      <td>False</td>\n",
       "      <td>0.305748</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.656604</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.344619</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.305748</td>\n",
       "      <td>0.343396</td>\n",
       "      <td>0.344619</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>202301</td>\n",
       "      <td>CE</td>\n",
       "      <td>False</td>\n",
       "      <td>0.445123</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.596229</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.357513</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.445123</td>\n",
       "      <td>0.596229</td>\n",
       "      <td>0.357513</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>202211</td>\n",
       "      <td>MY</td>\n",
       "      <td>True</td>\n",
       "      <td>0.728585</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438278</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.350027</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.728585</td>\n",
       "      <td>0.438278</td>\n",
       "      <td>0.350027</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>202212</td>\n",
       "      <td>MY</td>\n",
       "      <td>True</td>\n",
       "      <td>0.686038</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.509619</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.349988</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.686038</td>\n",
       "      <td>0.509619</td>\n",
       "      <td>0.349988</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>202211</td>\n",
       "      <td>JA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.163859</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.205914</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.273060</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.163859</td>\n",
       "      <td>0.205914</td>\n",
       "      <td>0.273060</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>202212</td>\n",
       "      <td>JA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191392</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.209022</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.272838</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.191392</td>\n",
       "      <td>0.209022</td>\n",
       "      <td>0.272838</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35 rows × 1349 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    yearmonth fips  y_pred_transformer  y_pred_proba_transformer  \\\n",
       "6      202211   IS                True                  0.634716   \n",
       "7      202212   IS                True                  0.692216   \n",
       "8      202301   IS                True                  0.687682   \n",
       "9      202211   LE                True                  0.587201   \n",
       "10     202212   LE                True                  0.578990   \n",
       "11     202301   LE                True                  0.534593   \n",
       "15     202211   QA               False                  0.176723   \n",
       "16     202212   QA               False                  0.177739   \n",
       "17     202211   KU               False                  0.174353   \n",
       "18     202212   KU               False                  0.189701   \n",
       "19     202211   IZ               False                  0.266301   \n",
       "20     202212   IZ               False                  0.336891   \n",
       "21     202301   IZ                True                  0.572735   \n",
       "22     202211   MU               False                  0.243252   \n",
       "23     202212   MU               False                  0.273943   \n",
       "29     202211   BM               False                  0.444116   \n",
       "30     202212   BM               False                  0.449590   \n",
       "31     202301   BM                True                  0.520781   \n",
       "32     202211   VM               False                  0.478212   \n",
       "33     202212   VM               False                  0.237275   \n",
       "34     202211   MG               False                  0.450012   \n",
       "35     202212   MG               False                  0.339055   \n",
       "48     202211   AF               False                  0.357150   \n",
       "49     202212   AF                True                  0.644641   \n",
       "50     202301   AF               False                  0.423742   \n",
       "54     202211   SY                True                  0.518751   \n",
       "55     202212   SY                True                  0.602737   \n",
       "56     202301   SY                True                  0.546697   \n",
       "60     202211   CE               False                  0.445699   \n",
       "61     202212   CE               False                  0.305748   \n",
       "62     202301   CE               False                  0.445123   \n",
       "69     202211   MY                True                  0.728585   \n",
       "70     202212   MY                True                  0.686038   \n",
       "71     202211   JA               False                  0.163859   \n",
       "72     202212   JA               False                  0.191392   \n",
       "\n",
       "    y_true_transformer  y_pred_xgboost  y_pred_proba_xgboost  y_true_xgboost  \\\n",
       "6                False            True              0.738002           False   \n",
       "7                 True            True              0.711610           False   \n",
       "8                False            True              0.608835            True   \n",
       "9                False            True              0.669344            True   \n",
       "10               False            True              0.536716           False   \n",
       "11                True            True              0.690374           False   \n",
       "15               False           False              0.070106           False   \n",
       "16               False           False              0.064143           False   \n",
       "17               False           False              0.075832           False   \n",
       "18               False           False              0.074495           False   \n",
       "19               False            True              0.637357           False   \n",
       "20               False            True              0.663939           False   \n",
       "21               False            True              0.663939           False   \n",
       "22               False           False              0.100111           False   \n",
       "23               False           False              0.129337           False   \n",
       "29               False            True              0.763934           False   \n",
       "30               False            True              0.758278           False   \n",
       "31               False            True              0.764942           False   \n",
       "32               False           False              0.065058           False   \n",
       "33               False           False              0.067476           False   \n",
       "34               False           False              0.405012           False   \n",
       "35               False           False              0.093121           False   \n",
       "48               False           False              0.386776           False   \n",
       "49               False            True              0.533442           False   \n",
       "50               False           False              0.430771           False   \n",
       "54                True            True              0.587173           False   \n",
       "55                True            True              0.699577           False   \n",
       "56               False            True              0.661985           False   \n",
       "60                True           False              0.462320           False   \n",
       "61               False            True              0.656604            True   \n",
       "62               False            True              0.596229           False   \n",
       "69               False           False              0.438278           False   \n",
       "70               False            True              0.509619           False   \n",
       "71               False           False              0.205914           False   \n",
       "72               False           False              0.209022           False   \n",
       "\n",
       "    y_pred_ffnn  y_pred_proba_ffnn  ...  fsi_c1:_security_apparatus  \\\n",
       "6         False           0.343657  ...                         2.6   \n",
       "7         False           0.341547  ...                         2.6   \n",
       "8         False           0.344979  ...                         2.6   \n",
       "9         False           0.398378  ...                         7.3   \n",
       "10        False           0.400631  ...                         7.3   \n",
       "11        False           0.398455  ...                         7.3   \n",
       "15        False           0.274388  ...                         1.0   \n",
       "16        False           0.271447  ...                         1.0   \n",
       "17        False           0.322281  ...                         2.4   \n",
       "18        False           0.323783  ...                         2.4   \n",
       "19        False           0.456745  ...                         7.5   \n",
       "20        False           0.460606  ...                         7.5   \n",
       "21        False           0.452974  ...                         7.5   \n",
       "22        False           0.318327  ...                         2.4   \n",
       "23        False           0.321544  ...                         2.4   \n",
       "29        False           0.395985  ...                         9.1   \n",
       "30        False           0.384911  ...                         9.1   \n",
       "31        False           0.380714  ...                         9.1   \n",
       "32        False           0.345246  ...                         3.5   \n",
       "33        False           0.345988  ...                         3.5   \n",
       "34        False           0.368454  ...                         2.9   \n",
       "35        False           0.366858  ...                         2.9   \n",
       "48         True           0.546216  ...                         9.7   \n",
       "49         True           0.552699  ...                         9.7   \n",
       "50         True           0.551422  ...                         9.7   \n",
       "54         True           0.537291  ...                         9.4   \n",
       "55         True           0.541852  ...                         9.4   \n",
       "56         True           0.534842  ...                         9.4   \n",
       "60        False           0.355650  ...                         6.8   \n",
       "61        False           0.344619  ...                         6.8   \n",
       "62        False           0.357513  ...                         6.8   \n",
       "69        False           0.350027  ...                         4.8   \n",
       "70        False           0.349988  ...                         4.8   \n",
       "71        False           0.273060  ...                         1.5   \n",
       "72        False           0.272838  ...                         1.5   \n",
       "\n",
       "   fsi_c2:_factionalized_elites  fsi_x1:_external_intervention  fsi_category  \\\n",
       "6                           8.3                            4.8        Stable   \n",
       "7                           8.3                            4.8        Stable   \n",
       "8                           8.3                            4.8        Stable   \n",
       "9                           9.6                            8.3         Alert   \n",
       "10                          9.6                            8.3         Alert   \n",
       "11                          9.6                            8.3         Alert   \n",
       "15                          5.0                            5.7        Stable   \n",
       "16                          5.0                            5.7        Stable   \n",
       "17                          7.5                            3.0        Stable   \n",
       "18                          7.5                            3.0        Stable   \n",
       "19                          9.6                            7.9         Alert   \n",
       "20                          9.6                            7.9         Alert   \n",
       "21                          9.6                            7.9         Alert   \n",
       "22                          6.6                            4.1        Stable   \n",
       "23                          6.6                            4.1        Stable   \n",
       "29                          9.0                            7.3         Alert   \n",
       "30                          9.0                            7.3         Alert   \n",
       "31                          9.0                            7.3         Alert   \n",
       "32                          6.9                            3.7        Stable   \n",
       "33                          6.9                            3.7        Stable   \n",
       "34                          5.5                            6.0        Stable   \n",
       "35                          5.5                            6.0        Stable   \n",
       "48                          8.7                            7.7         Alert   \n",
       "49                          8.7                            7.7         Alert   \n",
       "50                          8.7                            7.7         Alert   \n",
       "54                          9.9                           10.0         Alert   \n",
       "55                          9.9                           10.0         Alert   \n",
       "56                          9.9                           10.0         Alert   \n",
       "60                          9.1                            7.9         Alert   \n",
       "61                          9.1                            7.9         Alert   \n",
       "62                          9.1                            7.9         Alert   \n",
       "69                          6.8                            2.0        Stable   \n",
       "70                          6.8                            2.0        Stable   \n",
       "71                          2.6                            2.0        Stable   \n",
       "72                          2.6                            2.0        Stable   \n",
       "\n",
       "    transformer_probability_prediction_error  \\\n",
       "6                                   0.634716   \n",
       "7                                   0.307784   \n",
       "8                                   0.687682   \n",
       "9                                   0.587201   \n",
       "10                                  0.578990   \n",
       "11                                  0.465407   \n",
       "15                                  0.176723   \n",
       "16                                  0.177739   \n",
       "17                                  0.174353   \n",
       "18                                  0.189701   \n",
       "19                                  0.266301   \n",
       "20                                  0.336891   \n",
       "21                                  0.572735   \n",
       "22                                  0.243252   \n",
       "23                                  0.273943   \n",
       "29                                  0.444116   \n",
       "30                                  0.449590   \n",
       "31                                  0.520781   \n",
       "32                                  0.478212   \n",
       "33                                  0.237275   \n",
       "34                                  0.450012   \n",
       "35                                  0.339055   \n",
       "48                                  0.357150   \n",
       "49                                  0.644641   \n",
       "50                                  0.423742   \n",
       "54                                  0.481249   \n",
       "55                                  0.397263   \n",
       "56                                  0.546697   \n",
       "60                                  0.554301   \n",
       "61                                  0.305748   \n",
       "62                                  0.445123   \n",
       "69                                  0.728585   \n",
       "70                                  0.686038   \n",
       "71                                  0.163859   \n",
       "72                                  0.191392   \n",
       "\n",
       "    xgboost_probability_prediction_error  ffnn_probability_prediction_error  \\\n",
       "6                               0.738002                           0.343657   \n",
       "7                               0.711610                           0.658453   \n",
       "8                               0.391165                           0.344979   \n",
       "9                               0.330656                           0.398378   \n",
       "10                              0.536716                           0.400631   \n",
       "11                              0.690374                           0.601545   \n",
       "15                              0.070106                           0.274388   \n",
       "16                              0.064143                           0.271447   \n",
       "17                              0.075832                           0.322281   \n",
       "18                              0.074495                           0.323783   \n",
       "19                              0.637357                           0.456745   \n",
       "20                              0.663939                           0.460606   \n",
       "21                              0.663939                           0.452974   \n",
       "22                              0.100111                           0.318327   \n",
       "23                              0.129337                           0.321544   \n",
       "29                              0.763934                           0.395985   \n",
       "30                              0.758278                           0.384911   \n",
       "31                              0.764942                           0.380714   \n",
       "32                              0.065058                           0.345246   \n",
       "33                              0.067476                           0.345988   \n",
       "34                              0.405012                           0.368454   \n",
       "35                              0.093121                           0.366858   \n",
       "48                              0.386776                           0.546216   \n",
       "49                              0.533442                           0.552699   \n",
       "50                              0.430771                           0.551422   \n",
       "54                              0.587173                           0.462709   \n",
       "55                              0.699577                           0.458148   \n",
       "56                              0.661985                           0.534842   \n",
       "60                              0.462320                           0.644350   \n",
       "61                              0.343396                           0.344619   \n",
       "62                              0.596229                           0.357513   \n",
       "69                              0.438278                           0.350027   \n",
       "70                              0.509619                           0.349988   \n",
       "71                              0.205914                           0.273060   \n",
       "72                              0.209022                           0.272838   \n",
       "\n",
       "    transformer_classifcation_performance_outcome  \\\n",
       "6                    wrongly predicted escalation   \n",
       "7                  correctly predicted escalation   \n",
       "8                    wrongly predicted escalation   \n",
       "9                    wrongly predicted escalation   \n",
       "10                   wrongly predicted escalation   \n",
       "11                 correctly predicted escalation   \n",
       "15              correctly predicted no escalation   \n",
       "16              correctly predicted no escalation   \n",
       "17              correctly predicted no escalation   \n",
       "18              correctly predicted no escalation   \n",
       "19              correctly predicted no escalation   \n",
       "20              correctly predicted no escalation   \n",
       "21                   wrongly predicted escalation   \n",
       "22              correctly predicted no escalation   \n",
       "23              correctly predicted no escalation   \n",
       "29              correctly predicted no escalation   \n",
       "30              correctly predicted no escalation   \n",
       "31                   wrongly predicted escalation   \n",
       "32              correctly predicted no escalation   \n",
       "33              correctly predicted no escalation   \n",
       "34              correctly predicted no escalation   \n",
       "35              correctly predicted no escalation   \n",
       "48              correctly predicted no escalation   \n",
       "49                   wrongly predicted escalation   \n",
       "50              correctly predicted no escalation   \n",
       "54                 correctly predicted escalation   \n",
       "55                 correctly predicted escalation   \n",
       "56                   wrongly predicted escalation   \n",
       "60                wrongly predicted no escalation   \n",
       "61              correctly predicted no escalation   \n",
       "62              correctly predicted no escalation   \n",
       "69                   wrongly predicted escalation   \n",
       "70                   wrongly predicted escalation   \n",
       "71              correctly predicted no escalation   \n",
       "72              correctly predicted no escalation   \n",
       "\n",
       "    xgboost_classifcation_performance_outcome  \\\n",
       "6                wrongly predicted escalation   \n",
       "7              correctly predicted escalation   \n",
       "8                wrongly predicted escalation   \n",
       "9                wrongly predicted escalation   \n",
       "10               wrongly predicted escalation   \n",
       "11             correctly predicted escalation   \n",
       "15          correctly predicted no escalation   \n",
       "16          correctly predicted no escalation   \n",
       "17          correctly predicted no escalation   \n",
       "18          correctly predicted no escalation   \n",
       "19          correctly predicted no escalation   \n",
       "20          correctly predicted no escalation   \n",
       "21               wrongly predicted escalation   \n",
       "22          correctly predicted no escalation   \n",
       "23          correctly predicted no escalation   \n",
       "29          correctly predicted no escalation   \n",
       "30          correctly predicted no escalation   \n",
       "31               wrongly predicted escalation   \n",
       "32          correctly predicted no escalation   \n",
       "33          correctly predicted no escalation   \n",
       "34          correctly predicted no escalation   \n",
       "35          correctly predicted no escalation   \n",
       "48          correctly predicted no escalation   \n",
       "49               wrongly predicted escalation   \n",
       "50          correctly predicted no escalation   \n",
       "54             correctly predicted escalation   \n",
       "55             correctly predicted escalation   \n",
       "56               wrongly predicted escalation   \n",
       "60            wrongly predicted no escalation   \n",
       "61          correctly predicted no escalation   \n",
       "62          correctly predicted no escalation   \n",
       "69               wrongly predicted escalation   \n",
       "70               wrongly predicted escalation   \n",
       "71          correctly predicted no escalation   \n",
       "72          correctly predicted no escalation   \n",
       "\n",
       "    ffnn_classifcation_performance_outcome  \n",
       "6             wrongly predicted escalation  \n",
       "7           correctly predicted escalation  \n",
       "8             wrongly predicted escalation  \n",
       "9             wrongly predicted escalation  \n",
       "10            wrongly predicted escalation  \n",
       "11          correctly predicted escalation  \n",
       "15       correctly predicted no escalation  \n",
       "16       correctly predicted no escalation  \n",
       "17       correctly predicted no escalation  \n",
       "18       correctly predicted no escalation  \n",
       "19       correctly predicted no escalation  \n",
       "20       correctly predicted no escalation  \n",
       "21            wrongly predicted escalation  \n",
       "22       correctly predicted no escalation  \n",
       "23       correctly predicted no escalation  \n",
       "29       correctly predicted no escalation  \n",
       "30       correctly predicted no escalation  \n",
       "31            wrongly predicted escalation  \n",
       "32       correctly predicted no escalation  \n",
       "33       correctly predicted no escalation  \n",
       "34       correctly predicted no escalation  \n",
       "35       correctly predicted no escalation  \n",
       "48       correctly predicted no escalation  \n",
       "49            wrongly predicted escalation  \n",
       "50       correctly predicted no escalation  \n",
       "54          correctly predicted escalation  \n",
       "55          correctly predicted escalation  \n",
       "56            wrongly predicted escalation  \n",
       "60         wrongly predicted no escalation  \n",
       "61       correctly predicted no escalation  \n",
       "62       correctly predicted no escalation  \n",
       "69            wrongly predicted escalation  \n",
       "70            wrongly predicted escalation  \n",
       "71       correctly predicted no escalation  \n",
       "72       correctly predicted no escalation  \n",
       "\n",
       "[35 rows x 1349 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ffnn\n",
    "data_2 = df[df['fsi_category'] != 'Warning']\n",
    "dataerror = data_2['ffnn_probability_prediction_error']\n",
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f44c75ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2857142857142857"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_2.ffnn_classifcation_performance_outcome == 'wrongly predicted escalation').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f2b64d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02857142857142857"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_2.ffnn_classifcation_performance_outcome == 'wrongly predicted no escalation').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5c5658d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31427"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.2857+0.02857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1e578a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f5737fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4249548570731707"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1 = df[df['fsi_category'] == 'Warning']\n",
    "dataerror_1 = data_1['ffnn_probability_prediction_error']\n",
    "np.mean(dataerror_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4274b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41f6c2b4",
   "metadata": {},
   "source": [
    "xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f6cf95df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearmonth</th>\n",
       "      <th>fips</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>y_pred_proba_transformer</th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_xgboost</th>\n",
       "      <th>y_pred_proba_xgboost</th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_ffnn</th>\n",
       "      <th>y_pred_proba_ffnn</th>\n",
       "      <th>...</th>\n",
       "      <th>fsi_c1:_security_apparatus</th>\n",
       "      <th>fsi_c2:_factionalized_elites</th>\n",
       "      <th>fsi_x1:_external_intervention</th>\n",
       "      <th>fsi_category</th>\n",
       "      <th>transformer_probability_prediction_error</th>\n",
       "      <th>xgboost_probability_prediction_error</th>\n",
       "      <th>ffnn_probability_prediction_error</th>\n",
       "      <th>transformer_classifcation_performance_outcome</th>\n",
       "      <th>xgboost_classifcation_performance_outcome</th>\n",
       "      <th>ffnn_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202211</td>\n",
       "      <td>IS</td>\n",
       "      <td>True</td>\n",
       "      <td>0.634716</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.738002</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.343657</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.634716</td>\n",
       "      <td>0.738002</td>\n",
       "      <td>0.343657</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202212</td>\n",
       "      <td>IS</td>\n",
       "      <td>True</td>\n",
       "      <td>0.692216</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.711610</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.341547</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.307784</td>\n",
       "      <td>0.711610</td>\n",
       "      <td>0.658453</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202301</td>\n",
       "      <td>IS</td>\n",
       "      <td>True</td>\n",
       "      <td>0.687682</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.608835</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.344979</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.687682</td>\n",
       "      <td>0.391165</td>\n",
       "      <td>0.344979</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>202211</td>\n",
       "      <td>QA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.176723</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.070106</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.274388</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.176723</td>\n",
       "      <td>0.070106</td>\n",
       "      <td>0.274388</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>202212</td>\n",
       "      <td>QA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.177739</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.064143</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.271447</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.177739</td>\n",
       "      <td>0.064143</td>\n",
       "      <td>0.271447</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>202211</td>\n",
       "      <td>KU</td>\n",
       "      <td>False</td>\n",
       "      <td>0.174353</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.075832</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.322281</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.174353</td>\n",
       "      <td>0.075832</td>\n",
       "      <td>0.322281</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>202212</td>\n",
       "      <td>KU</td>\n",
       "      <td>False</td>\n",
       "      <td>0.189701</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.074495</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.323783</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.189701</td>\n",
       "      <td>0.074495</td>\n",
       "      <td>0.323783</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>202211</td>\n",
       "      <td>MU</td>\n",
       "      <td>False</td>\n",
       "      <td>0.243252</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100111</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.318327</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.243252</td>\n",
       "      <td>0.100111</td>\n",
       "      <td>0.318327</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>202212</td>\n",
       "      <td>MU</td>\n",
       "      <td>False</td>\n",
       "      <td>0.273943</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.129337</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.321544</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.273943</td>\n",
       "      <td>0.129337</td>\n",
       "      <td>0.321544</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>202211</td>\n",
       "      <td>JA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.163859</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.205914</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.273060</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.163859</td>\n",
       "      <td>0.205914</td>\n",
       "      <td>0.273060</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>202212</td>\n",
       "      <td>JA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191392</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.209022</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.272838</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.191392</td>\n",
       "      <td>0.209022</td>\n",
       "      <td>0.272838</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>202211</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.450048</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.495618</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.365198</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.450048</td>\n",
       "      <td>0.504382</td>\n",
       "      <td>0.365198</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>202212</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.443690</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.428008</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.366745</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.443690</td>\n",
       "      <td>0.428008</td>\n",
       "      <td>0.366745</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>202301</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.315053</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.618117</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.367574</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.684947</td>\n",
       "      <td>0.618117</td>\n",
       "      <td>0.632426</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 1349 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    yearmonth fips  y_pred_transformer  y_pred_proba_transformer  \\\n",
       "6      202211   IS                True                  0.634716   \n",
       "7      202212   IS                True                  0.692216   \n",
       "8      202301   IS                True                  0.687682   \n",
       "15     202211   QA               False                  0.176723   \n",
       "16     202212   QA               False                  0.177739   \n",
       "17     202211   KU               False                  0.174353   \n",
       "18     202212   KU               False                  0.189701   \n",
       "22     202211   MU               False                  0.243252   \n",
       "23     202212   MU               False                  0.273943   \n",
       "71     202211   JA               False                  0.163859   \n",
       "72     202212   JA               False                  0.191392   \n",
       "73     202211   SA               False                  0.450048   \n",
       "74     202212   SA               False                  0.443690   \n",
       "75     202301   SA               False                  0.315053   \n",
       "\n",
       "    y_true_transformer  y_pred_xgboost  y_pred_proba_xgboost  y_true_xgboost  \\\n",
       "6                False            True              0.738002           False   \n",
       "7                 True            True              0.711610           False   \n",
       "8                False            True              0.608835            True   \n",
       "15               False           False              0.070106           False   \n",
       "16               False           False              0.064143           False   \n",
       "17               False           False              0.075832           False   \n",
       "18               False           False              0.074495           False   \n",
       "22               False           False              0.100111           False   \n",
       "23               False           False              0.129337           False   \n",
       "71               False           False              0.205914           False   \n",
       "72               False           False              0.209022           False   \n",
       "73               False           False              0.495618            True   \n",
       "74               False           False              0.428008           False   \n",
       "75                True            True              0.618117           False   \n",
       "\n",
       "    y_pred_ffnn  y_pred_proba_ffnn  ...  fsi_c1:_security_apparatus  \\\n",
       "6         False           0.343657  ...                         2.6   \n",
       "7         False           0.341547  ...                         2.6   \n",
       "8         False           0.344979  ...                         2.6   \n",
       "15        False           0.274388  ...                         1.0   \n",
       "16        False           0.271447  ...                         1.0   \n",
       "17        False           0.322281  ...                         2.4   \n",
       "18        False           0.323783  ...                         2.4   \n",
       "22        False           0.318327  ...                         2.4   \n",
       "23        False           0.321544  ...                         2.4   \n",
       "71        False           0.273060  ...                         1.5   \n",
       "72        False           0.272838  ...                         1.5   \n",
       "73        False           0.365198  ...                         5.1   \n",
       "74        False           0.366745  ...                         5.1   \n",
       "75        False           0.367574  ...                         5.1   \n",
       "\n",
       "   fsi_c2:_factionalized_elites  fsi_x1:_external_intervention  fsi_category  \\\n",
       "6                           8.3                            4.8        Stable   \n",
       "7                           8.3                            4.8        Stable   \n",
       "8                           8.3                            4.8        Stable   \n",
       "15                          5.0                            5.7        Stable   \n",
       "16                          5.0                            5.7        Stable   \n",
       "17                          7.5                            3.0        Stable   \n",
       "18                          7.5                            3.0        Stable   \n",
       "22                          6.6                            4.1        Stable   \n",
       "23                          6.6                            4.1        Stable   \n",
       "71                          2.6                            2.0        Stable   \n",
       "72                          2.6                            2.0        Stable   \n",
       "73                          8.5                            4.1       Warning   \n",
       "74                          8.5                            4.1       Warning   \n",
       "75                          8.5                            4.1       Warning   \n",
       "\n",
       "    transformer_probability_prediction_error  \\\n",
       "6                                   0.634716   \n",
       "7                                   0.307784   \n",
       "8                                   0.687682   \n",
       "15                                  0.176723   \n",
       "16                                  0.177739   \n",
       "17                                  0.174353   \n",
       "18                                  0.189701   \n",
       "22                                  0.243252   \n",
       "23                                  0.273943   \n",
       "71                                  0.163859   \n",
       "72                                  0.191392   \n",
       "73                                  0.450048   \n",
       "74                                  0.443690   \n",
       "75                                  0.684947   \n",
       "\n",
       "    xgboost_probability_prediction_error  ffnn_probability_prediction_error  \\\n",
       "6                               0.738002                           0.343657   \n",
       "7                               0.711610                           0.658453   \n",
       "8                               0.391165                           0.344979   \n",
       "15                              0.070106                           0.274388   \n",
       "16                              0.064143                           0.271447   \n",
       "17                              0.075832                           0.322281   \n",
       "18                              0.074495                           0.323783   \n",
       "22                              0.100111                           0.318327   \n",
       "23                              0.129337                           0.321544   \n",
       "71                              0.205914                           0.273060   \n",
       "72                              0.209022                           0.272838   \n",
       "73                              0.504382                           0.365198   \n",
       "74                              0.428008                           0.366745   \n",
       "75                              0.618117                           0.632426   \n",
       "\n",
       "    transformer_classifcation_performance_outcome  \\\n",
       "6                    wrongly predicted escalation   \n",
       "7                  correctly predicted escalation   \n",
       "8                    wrongly predicted escalation   \n",
       "15              correctly predicted no escalation   \n",
       "16              correctly predicted no escalation   \n",
       "17              correctly predicted no escalation   \n",
       "18              correctly predicted no escalation   \n",
       "22              correctly predicted no escalation   \n",
       "23              correctly predicted no escalation   \n",
       "71              correctly predicted no escalation   \n",
       "72              correctly predicted no escalation   \n",
       "73              correctly predicted no escalation   \n",
       "74              correctly predicted no escalation   \n",
       "75                wrongly predicted no escalation   \n",
       "\n",
       "    xgboost_classifcation_performance_outcome  \\\n",
       "6                wrongly predicted escalation   \n",
       "7              correctly predicted escalation   \n",
       "8                wrongly predicted escalation   \n",
       "15          correctly predicted no escalation   \n",
       "16          correctly predicted no escalation   \n",
       "17          correctly predicted no escalation   \n",
       "18          correctly predicted no escalation   \n",
       "22          correctly predicted no escalation   \n",
       "23          correctly predicted no escalation   \n",
       "71          correctly predicted no escalation   \n",
       "72          correctly predicted no escalation   \n",
       "73          correctly predicted no escalation   \n",
       "74          correctly predicted no escalation   \n",
       "75            wrongly predicted no escalation   \n",
       "\n",
       "    ffnn_classifcation_performance_outcome  \n",
       "6             wrongly predicted escalation  \n",
       "7           correctly predicted escalation  \n",
       "8             wrongly predicted escalation  \n",
       "15       correctly predicted no escalation  \n",
       "16       correctly predicted no escalation  \n",
       "17       correctly predicted no escalation  \n",
       "18       correctly predicted no escalation  \n",
       "22       correctly predicted no escalation  \n",
       "23       correctly predicted no escalation  \n",
       "71       correctly predicted no escalation  \n",
       "72       correctly predicted no escalation  \n",
       "73       correctly predicted no escalation  \n",
       "74       correctly predicted no escalation  \n",
       "75         wrongly predicted no escalation  \n",
       "\n",
       "[14 rows x 1349 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgboost\n",
    "data_1 = df[df['wbi_income_group'] == 'High income']\n",
    "dataerror_1 = data_1['xgboost_probability_prediction_error']\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7667a82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_1.xgboost_classifcation_performance_outcome == 'correctly predicted no escalation').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2bbfb0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07142857142857142"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_1.xgboost_classifcation_performance_outcome == 'correctly predicted escalation').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c691cc32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearmonth</th>\n",
       "      <th>fips</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>y_pred_proba_transformer</th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_xgboost</th>\n",
       "      <th>y_pred_proba_xgboost</th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_ffnn</th>\n",
       "      <th>y_pred_proba_ffnn</th>\n",
       "      <th>...</th>\n",
       "      <th>fsi_c1:_security_apparatus</th>\n",
       "      <th>fsi_c2:_factionalized_elites</th>\n",
       "      <th>fsi_x1:_external_intervention</th>\n",
       "      <th>fsi_category</th>\n",
       "      <th>transformer_probability_prediction_error</th>\n",
       "      <th>xgboost_probability_prediction_error</th>\n",
       "      <th>ffnn_probability_prediction_error</th>\n",
       "      <th>transformer_classifcation_performance_outcome</th>\n",
       "      <th>xgboost_classifcation_performance_outcome</th>\n",
       "      <th>ffnn_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202211</td>\n",
       "      <td>UZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.535385</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.660580</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.381938</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.535385</td>\n",
       "      <td>0.660580</td>\n",
       "      <td>0.381938</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202212</td>\n",
       "      <td>UZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.538211</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.579952</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.364793</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.538211</td>\n",
       "      <td>0.579952</td>\n",
       "      <td>0.364793</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202301</td>\n",
       "      <td>UZ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.204810</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.652542</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.364343</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.204810</td>\n",
       "      <td>0.652542</td>\n",
       "      <td>0.364343</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202211</td>\n",
       "      <td>ID</td>\n",
       "      <td>False</td>\n",
       "      <td>0.461546</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.480096</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.398537</td>\n",
       "      <td>...</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.461546</td>\n",
       "      <td>0.480096</td>\n",
       "      <td>0.398537</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202212</td>\n",
       "      <td>ID</td>\n",
       "      <td>False</td>\n",
       "      <td>0.346367</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.589674</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>...</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.346367</td>\n",
       "      <td>0.410326</td>\n",
       "      <td>0.395459</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202301</td>\n",
       "      <td>ID</td>\n",
       "      <td>False</td>\n",
       "      <td>0.398960</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.488815</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.401349</td>\n",
       "      <td>...</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.398960</td>\n",
       "      <td>0.488815</td>\n",
       "      <td>0.401349</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202211</td>\n",
       "      <td>LE</td>\n",
       "      <td>True</td>\n",
       "      <td>0.587201</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.669344</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.398378</td>\n",
       "      <td>...</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.587201</td>\n",
       "      <td>0.330656</td>\n",
       "      <td>0.398378</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>202212</td>\n",
       "      <td>LE</td>\n",
       "      <td>True</td>\n",
       "      <td>0.578990</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.536716</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.400631</td>\n",
       "      <td>...</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.578990</td>\n",
       "      <td>0.536716</td>\n",
       "      <td>0.400631</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>202301</td>\n",
       "      <td>LE</td>\n",
       "      <td>True</td>\n",
       "      <td>0.534593</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.690374</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.398455</td>\n",
       "      <td>...</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.465407</td>\n",
       "      <td>0.690374</td>\n",
       "      <td>0.601545</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>202211</td>\n",
       "      <td>CB</td>\n",
       "      <td>True</td>\n",
       "      <td>0.622624</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.441517</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.394288</td>\n",
       "      <td>...</td>\n",
       "      <td>6.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.622624</td>\n",
       "      <td>0.441517</td>\n",
       "      <td>0.394288</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>202212</td>\n",
       "      <td>CB</td>\n",
       "      <td>False</td>\n",
       "      <td>0.430438</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.495520</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.398258</td>\n",
       "      <td>...</td>\n",
       "      <td>6.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.430438</td>\n",
       "      <td>0.495520</td>\n",
       "      <td>0.398258</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>202211</td>\n",
       "      <td>BM</td>\n",
       "      <td>False</td>\n",
       "      <td>0.444116</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.763934</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.395985</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.444116</td>\n",
       "      <td>0.763934</td>\n",
       "      <td>0.395985</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>202212</td>\n",
       "      <td>BM</td>\n",
       "      <td>False</td>\n",
       "      <td>0.449590</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.758278</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.384911</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.449590</td>\n",
       "      <td>0.758278</td>\n",
       "      <td>0.384911</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>202301</td>\n",
       "      <td>BM</td>\n",
       "      <td>True</td>\n",
       "      <td>0.520781</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.764942</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.380714</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.520781</td>\n",
       "      <td>0.764942</td>\n",
       "      <td>0.380714</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>202211</td>\n",
       "      <td>VM</td>\n",
       "      <td>False</td>\n",
       "      <td>0.478212</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.065058</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.345246</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.478212</td>\n",
       "      <td>0.065058</td>\n",
       "      <td>0.345246</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>202212</td>\n",
       "      <td>VM</td>\n",
       "      <td>False</td>\n",
       "      <td>0.237275</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.067476</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.345988</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.237275</td>\n",
       "      <td>0.067476</td>\n",
       "      <td>0.345988</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>202211</td>\n",
       "      <td>MG</td>\n",
       "      <td>False</td>\n",
       "      <td>0.450012</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.405012</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.368454</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.450012</td>\n",
       "      <td>0.405012</td>\n",
       "      <td>0.368454</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>202212</td>\n",
       "      <td>MG</td>\n",
       "      <td>False</td>\n",
       "      <td>0.339055</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.093121</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.366858</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.339055</td>\n",
       "      <td>0.093121</td>\n",
       "      <td>0.366858</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>202211</td>\n",
       "      <td>IN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.542866</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.527862</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.386045</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.542866</td>\n",
       "      <td>0.527862</td>\n",
       "      <td>0.386045</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>202212</td>\n",
       "      <td>IN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.707988</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.550853</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.387514</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.707988</td>\n",
       "      <td>0.449147</td>\n",
       "      <td>0.387514</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>202301</td>\n",
       "      <td>IN</td>\n",
       "      <td>True</td>\n",
       "      <td>0.793501</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.545930</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.384485</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.793501</td>\n",
       "      <td>0.545930</td>\n",
       "      <td>0.384485</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>202211</td>\n",
       "      <td>BG</td>\n",
       "      <td>True</td>\n",
       "      <td>0.619812</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.564092</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.417691</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.619812</td>\n",
       "      <td>0.564092</td>\n",
       "      <td>0.417691</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>202212</td>\n",
       "      <td>BG</td>\n",
       "      <td>True</td>\n",
       "      <td>0.625523</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.552029</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.416145</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.625523</td>\n",
       "      <td>0.552029</td>\n",
       "      <td>0.416145</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>202301</td>\n",
       "      <td>BG</td>\n",
       "      <td>True</td>\n",
       "      <td>0.624302</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.576891</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.428320</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.624302</td>\n",
       "      <td>0.576891</td>\n",
       "      <td>0.428320</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>202211</td>\n",
       "      <td>NP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.541297</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.691555</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.464957</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.458703</td>\n",
       "      <td>0.691555</td>\n",
       "      <td>0.535043</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>202212</td>\n",
       "      <td>NP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.686276</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.668246</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.443688</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.686276</td>\n",
       "      <td>0.668246</td>\n",
       "      <td>0.443688</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>202301</td>\n",
       "      <td>NP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.630345</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.641119</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.521024</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.630345</td>\n",
       "      <td>0.641119</td>\n",
       "      <td>0.521024</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>202211</td>\n",
       "      <td>PK</td>\n",
       "      <td>True</td>\n",
       "      <td>0.792848</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.741170</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.506878</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.792848</td>\n",
       "      <td>0.258830</td>\n",
       "      <td>0.506878</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>202212</td>\n",
       "      <td>PK</td>\n",
       "      <td>True</td>\n",
       "      <td>0.732578</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.704396</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.512946</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.732578</td>\n",
       "      <td>0.704396</td>\n",
       "      <td>0.512946</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>202301</td>\n",
       "      <td>PK</td>\n",
       "      <td>True</td>\n",
       "      <td>0.756767</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.686989</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.509882</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.243233</td>\n",
       "      <td>0.686989</td>\n",
       "      <td>0.490118</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>202211</td>\n",
       "      <td>KG</td>\n",
       "      <td>False</td>\n",
       "      <td>0.448226</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.528620</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.387699</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.448226</td>\n",
       "      <td>0.528620</td>\n",
       "      <td>0.387699</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>202212</td>\n",
       "      <td>KG</td>\n",
       "      <td>False</td>\n",
       "      <td>0.203963</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.457680</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.203963</td>\n",
       "      <td>0.457680</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>202301</td>\n",
       "      <td>KG</td>\n",
       "      <td>False</td>\n",
       "      <td>0.455062</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.450184</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.388959</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.455062</td>\n",
       "      <td>0.450184</td>\n",
       "      <td>0.388959</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>202211</td>\n",
       "      <td>CE</td>\n",
       "      <td>False</td>\n",
       "      <td>0.445699</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.462320</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.355650</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.554301</td>\n",
       "      <td>0.462320</td>\n",
       "      <td>0.644350</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>202212</td>\n",
       "      <td>CE</td>\n",
       "      <td>False</td>\n",
       "      <td>0.305748</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.656604</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.344619</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.305748</td>\n",
       "      <td>0.343396</td>\n",
       "      <td>0.344619</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>202301</td>\n",
       "      <td>CE</td>\n",
       "      <td>False</td>\n",
       "      <td>0.445123</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.596229</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.357513</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.445123</td>\n",
       "      <td>0.596229</td>\n",
       "      <td>0.357513</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>202211</td>\n",
       "      <td>RP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.679475</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.695254</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.414133</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.320525</td>\n",
       "      <td>0.695254</td>\n",
       "      <td>0.585867</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>202212</td>\n",
       "      <td>RP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.620710</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.677803</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.414881</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.620710</td>\n",
       "      <td>0.322197</td>\n",
       "      <td>0.414881</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>202301</td>\n",
       "      <td>RP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.729239</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.641753</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.416434</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.729239</td>\n",
       "      <td>0.641753</td>\n",
       "      <td>0.416434</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39 rows × 1349 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    yearmonth fips  y_pred_transformer  y_pred_proba_transformer  \\\n",
       "0      202211   UZ                True                  0.535385   \n",
       "1      202212   UZ                True                  0.538211   \n",
       "2      202301   UZ               False                  0.204810   \n",
       "3      202211   ID               False                  0.461546   \n",
       "4      202212   ID               False                  0.346367   \n",
       "5      202301   ID               False                  0.398960   \n",
       "9      202211   LE                True                  0.587201   \n",
       "10     202212   LE                True                  0.578990   \n",
       "11     202301   LE                True                  0.534593   \n",
       "24     202211   CB                True                  0.622624   \n",
       "25     202212   CB               False                  0.430438   \n",
       "29     202211   BM               False                  0.444116   \n",
       "30     202212   BM               False                  0.449590   \n",
       "31     202301   BM                True                  0.520781   \n",
       "32     202211   VM               False                  0.478212   \n",
       "33     202212   VM               False                  0.237275   \n",
       "34     202211   MG               False                  0.450012   \n",
       "35     202212   MG               False                  0.339055   \n",
       "36     202211   IN                True                  0.542866   \n",
       "37     202212   IN                True                  0.707988   \n",
       "38     202301   IN                True                  0.793501   \n",
       "39     202211   BG                True                  0.619812   \n",
       "40     202212   BG                True                  0.625523   \n",
       "41     202301   BG                True                  0.624302   \n",
       "42     202211   NP                True                  0.541297   \n",
       "43     202212   NP                True                  0.686276   \n",
       "44     202301   NP                True                  0.630345   \n",
       "45     202211   PK                True                  0.792848   \n",
       "46     202212   PK                True                  0.732578   \n",
       "47     202301   PK                True                  0.756767   \n",
       "51     202211   KG               False                  0.448226   \n",
       "52     202212   KG               False                  0.203963   \n",
       "53     202301   KG               False                  0.455062   \n",
       "60     202211   CE               False                  0.445699   \n",
       "61     202212   CE               False                  0.305748   \n",
       "62     202301   CE               False                  0.445123   \n",
       "66     202211   RP                True                  0.679475   \n",
       "67     202212   RP                True                  0.620710   \n",
       "68     202301   RP                True                  0.729239   \n",
       "\n",
       "    y_true_transformer  y_pred_xgboost  y_pred_proba_xgboost  y_true_xgboost  \\\n",
       "0                False            True              0.660580           False   \n",
       "1                False            True              0.579952           False   \n",
       "2                False            True              0.652542           False   \n",
       "3                False           False              0.480096           False   \n",
       "4                False            True              0.589674            True   \n",
       "5                False           False              0.488815           False   \n",
       "9                False            True              0.669344            True   \n",
       "10               False            True              0.536716           False   \n",
       "11                True            True              0.690374           False   \n",
       "24               False           False              0.441517           False   \n",
       "25               False           False              0.495520           False   \n",
       "29               False            True              0.763934           False   \n",
       "30               False            True              0.758278           False   \n",
       "31               False            True              0.764942           False   \n",
       "32               False           False              0.065058           False   \n",
       "33               False           False              0.067476           False   \n",
       "34               False           False              0.405012           False   \n",
       "35               False           False              0.093121           False   \n",
       "36               False            True              0.527862           False   \n",
       "37               False            True              0.550853            True   \n",
       "38               False            True              0.545930           False   \n",
       "39               False            True              0.564092           False   \n",
       "40               False            True              0.552029           False   \n",
       "41               False            True              0.576891           False   \n",
       "42                True            True              0.691555           False   \n",
       "43               False            True              0.668246           False   \n",
       "44               False            True              0.641119           False   \n",
       "45               False            True              0.741170            True   \n",
       "46               False            True              0.704396           False   \n",
       "47                True            True              0.686989           False   \n",
       "51               False            True              0.528620           False   \n",
       "52               False           False              0.457680           False   \n",
       "53               False           False              0.450184           False   \n",
       "60                True           False              0.462320           False   \n",
       "61               False            True              0.656604            True   \n",
       "62               False            True              0.596229           False   \n",
       "66                True            True              0.695254           False   \n",
       "67               False            True              0.677803            True   \n",
       "68               False            True              0.641753           False   \n",
       "\n",
       "    y_pred_ffnn  y_pred_proba_ffnn  ...  fsi_c1:_security_apparatus  \\\n",
       "0         False           0.381938  ...                         5.6   \n",
       "1         False           0.364793  ...                         5.6   \n",
       "2         False           0.364343  ...                         5.6   \n",
       "3         False           0.398537  ...                         5.2   \n",
       "4         False           0.395459  ...                         5.2   \n",
       "5         False           0.401349  ...                         5.2   \n",
       "9         False           0.398378  ...                         7.3   \n",
       "10        False           0.400631  ...                         7.3   \n",
       "11        False           0.398455  ...                         7.3   \n",
       "24        False           0.394288  ...                         6.4   \n",
       "25        False           0.398258  ...                         6.4   \n",
       "29        False           0.395985  ...                         9.1   \n",
       "30        False           0.384911  ...                         9.1   \n",
       "31        False           0.380714  ...                         9.1   \n",
       "32        False           0.345246  ...                         3.5   \n",
       "33        False           0.345988  ...                         3.5   \n",
       "34        False           0.368454  ...                         2.9   \n",
       "35        False           0.366858  ...                         2.9   \n",
       "36        False           0.386045  ...                         6.0   \n",
       "37        False           0.387514  ...                         6.0   \n",
       "38        False           0.384485  ...                         6.0   \n",
       "39        False           0.417691  ...                         6.8   \n",
       "40        False           0.416145  ...                         6.8   \n",
       "41        False           0.428320  ...                         6.8   \n",
       "42        False           0.464957  ...                         5.5   \n",
       "43        False           0.443688  ...                         5.5   \n",
       "44         True           0.521024  ...                         5.5   \n",
       "45         True           0.506878  ...                         7.6   \n",
       "46         True           0.512946  ...                         7.6   \n",
       "47         True           0.509882  ...                         7.6   \n",
       "51        False           0.387699  ...                         5.6   \n",
       "52        False           0.383262  ...                         5.6   \n",
       "53        False           0.388959  ...                         5.6   \n",
       "60        False           0.355650  ...                         6.8   \n",
       "61        False           0.344619  ...                         6.8   \n",
       "62        False           0.357513  ...                         6.8   \n",
       "66        False           0.414133  ...                         9.1   \n",
       "67        False           0.414881  ...                         9.1   \n",
       "68        False           0.416434  ...                         9.1   \n",
       "\n",
       "   fsi_c2:_factionalized_elites  fsi_x1:_external_intervention  fsi_category  \\\n",
       "0                           8.8                            3.4       Warning   \n",
       "1                           8.8                            3.4       Warning   \n",
       "2                           8.8                            3.4       Warning   \n",
       "3                           7.1                            3.7       Warning   \n",
       "4                           7.1                            3.7       Warning   \n",
       "5                           7.1                            3.7       Warning   \n",
       "9                           9.6                            8.3         Alert   \n",
       "10                          9.6                            8.3         Alert   \n",
       "11                          9.6                            8.3         Alert   \n",
       "24                          8.7                            7.0       Warning   \n",
       "25                          8.7                            7.0       Warning   \n",
       "29                          9.0                            7.3         Alert   \n",
       "30                          9.0                            7.3         Alert   \n",
       "31                          9.0                            7.3         Alert   \n",
       "32                          6.9                            3.7        Stable   \n",
       "33                          6.9                            3.7        Stable   \n",
       "34                          5.5                            6.0        Stable   \n",
       "35                          5.5                            6.0        Stable   \n",
       "36                          7.3                            3.9       Warning   \n",
       "37                          7.3                            3.9       Warning   \n",
       "38                          7.3                            3.9       Warning   \n",
       "39                          9.3                            4.6       Warning   \n",
       "40                          9.3                            4.6       Warning   \n",
       "41                          9.3                            4.6       Warning   \n",
       "42                          8.8                            5.9       Warning   \n",
       "43                          8.8                            5.9       Warning   \n",
       "44                          8.8                            5.9       Warning   \n",
       "45                          9.3                            8.3       Warning   \n",
       "46                          9.3                            8.3       Warning   \n",
       "47                          9.3                            8.3       Warning   \n",
       "51                          8.2                            6.3       Warning   \n",
       "52                          8.2                            6.3       Warning   \n",
       "53                          8.2                            6.3       Warning   \n",
       "60                          9.1                            7.9         Alert   \n",
       "61                          9.1                            7.9         Alert   \n",
       "62                          9.1                            7.9         Alert   \n",
       "66                          8.0                            5.4       Warning   \n",
       "67                          8.0                            5.4       Warning   \n",
       "68                          8.0                            5.4       Warning   \n",
       "\n",
       "    transformer_probability_prediction_error  \\\n",
       "0                                   0.535385   \n",
       "1                                   0.538211   \n",
       "2                                   0.204810   \n",
       "3                                   0.461546   \n",
       "4                                   0.346367   \n",
       "5                                   0.398960   \n",
       "9                                   0.587201   \n",
       "10                                  0.578990   \n",
       "11                                  0.465407   \n",
       "24                                  0.622624   \n",
       "25                                  0.430438   \n",
       "29                                  0.444116   \n",
       "30                                  0.449590   \n",
       "31                                  0.520781   \n",
       "32                                  0.478212   \n",
       "33                                  0.237275   \n",
       "34                                  0.450012   \n",
       "35                                  0.339055   \n",
       "36                                  0.542866   \n",
       "37                                  0.707988   \n",
       "38                                  0.793501   \n",
       "39                                  0.619812   \n",
       "40                                  0.625523   \n",
       "41                                  0.624302   \n",
       "42                                  0.458703   \n",
       "43                                  0.686276   \n",
       "44                                  0.630345   \n",
       "45                                  0.792848   \n",
       "46                                  0.732578   \n",
       "47                                  0.243233   \n",
       "51                                  0.448226   \n",
       "52                                  0.203963   \n",
       "53                                  0.455062   \n",
       "60                                  0.554301   \n",
       "61                                  0.305748   \n",
       "62                                  0.445123   \n",
       "66                                  0.320525   \n",
       "67                                  0.620710   \n",
       "68                                  0.729239   \n",
       "\n",
       "    xgboost_probability_prediction_error  ffnn_probability_prediction_error  \\\n",
       "0                               0.660580                           0.381938   \n",
       "1                               0.579952                           0.364793   \n",
       "2                               0.652542                           0.364343   \n",
       "3                               0.480096                           0.398537   \n",
       "4                               0.410326                           0.395459   \n",
       "5                               0.488815                           0.401349   \n",
       "9                               0.330656                           0.398378   \n",
       "10                              0.536716                           0.400631   \n",
       "11                              0.690374                           0.601545   \n",
       "24                              0.441517                           0.394288   \n",
       "25                              0.495520                           0.398258   \n",
       "29                              0.763934                           0.395985   \n",
       "30                              0.758278                           0.384911   \n",
       "31                              0.764942                           0.380714   \n",
       "32                              0.065058                           0.345246   \n",
       "33                              0.067476                           0.345988   \n",
       "34                              0.405012                           0.368454   \n",
       "35                              0.093121                           0.366858   \n",
       "36                              0.527862                           0.386045   \n",
       "37                              0.449147                           0.387514   \n",
       "38                              0.545930                           0.384485   \n",
       "39                              0.564092                           0.417691   \n",
       "40                              0.552029                           0.416145   \n",
       "41                              0.576891                           0.428320   \n",
       "42                              0.691555                           0.535043   \n",
       "43                              0.668246                           0.443688   \n",
       "44                              0.641119                           0.521024   \n",
       "45                              0.258830                           0.506878   \n",
       "46                              0.704396                           0.512946   \n",
       "47                              0.686989                           0.490118   \n",
       "51                              0.528620                           0.387699   \n",
       "52                              0.457680                           0.383262   \n",
       "53                              0.450184                           0.388959   \n",
       "60                              0.462320                           0.644350   \n",
       "61                              0.343396                           0.344619   \n",
       "62                              0.596229                           0.357513   \n",
       "66                              0.695254                           0.585867   \n",
       "67                              0.322197                           0.414881   \n",
       "68                              0.641753                           0.416434   \n",
       "\n",
       "    transformer_classifcation_performance_outcome  \\\n",
       "0                    wrongly predicted escalation   \n",
       "1                    wrongly predicted escalation   \n",
       "2               correctly predicted no escalation   \n",
       "3               correctly predicted no escalation   \n",
       "4               correctly predicted no escalation   \n",
       "5               correctly predicted no escalation   \n",
       "9                    wrongly predicted escalation   \n",
       "10                   wrongly predicted escalation   \n",
       "11                 correctly predicted escalation   \n",
       "24                   wrongly predicted escalation   \n",
       "25              correctly predicted no escalation   \n",
       "29              correctly predicted no escalation   \n",
       "30              correctly predicted no escalation   \n",
       "31                   wrongly predicted escalation   \n",
       "32              correctly predicted no escalation   \n",
       "33              correctly predicted no escalation   \n",
       "34              correctly predicted no escalation   \n",
       "35              correctly predicted no escalation   \n",
       "36                   wrongly predicted escalation   \n",
       "37                   wrongly predicted escalation   \n",
       "38                   wrongly predicted escalation   \n",
       "39                   wrongly predicted escalation   \n",
       "40                   wrongly predicted escalation   \n",
       "41                   wrongly predicted escalation   \n",
       "42                 correctly predicted escalation   \n",
       "43                   wrongly predicted escalation   \n",
       "44                   wrongly predicted escalation   \n",
       "45                   wrongly predicted escalation   \n",
       "46                   wrongly predicted escalation   \n",
       "47                 correctly predicted escalation   \n",
       "51              correctly predicted no escalation   \n",
       "52              correctly predicted no escalation   \n",
       "53              correctly predicted no escalation   \n",
       "60                wrongly predicted no escalation   \n",
       "61              correctly predicted no escalation   \n",
       "62              correctly predicted no escalation   \n",
       "66                 correctly predicted escalation   \n",
       "67                   wrongly predicted escalation   \n",
       "68                   wrongly predicted escalation   \n",
       "\n",
       "    xgboost_classifcation_performance_outcome  \\\n",
       "0                wrongly predicted escalation   \n",
       "1                wrongly predicted escalation   \n",
       "2           correctly predicted no escalation   \n",
       "3           correctly predicted no escalation   \n",
       "4           correctly predicted no escalation   \n",
       "5           correctly predicted no escalation   \n",
       "9                wrongly predicted escalation   \n",
       "10               wrongly predicted escalation   \n",
       "11             correctly predicted escalation   \n",
       "24               wrongly predicted escalation   \n",
       "25          correctly predicted no escalation   \n",
       "29          correctly predicted no escalation   \n",
       "30          correctly predicted no escalation   \n",
       "31               wrongly predicted escalation   \n",
       "32          correctly predicted no escalation   \n",
       "33          correctly predicted no escalation   \n",
       "34          correctly predicted no escalation   \n",
       "35          correctly predicted no escalation   \n",
       "36               wrongly predicted escalation   \n",
       "37               wrongly predicted escalation   \n",
       "38               wrongly predicted escalation   \n",
       "39               wrongly predicted escalation   \n",
       "40               wrongly predicted escalation   \n",
       "41               wrongly predicted escalation   \n",
       "42             correctly predicted escalation   \n",
       "43               wrongly predicted escalation   \n",
       "44               wrongly predicted escalation   \n",
       "45               wrongly predicted escalation   \n",
       "46               wrongly predicted escalation   \n",
       "47             correctly predicted escalation   \n",
       "51          correctly predicted no escalation   \n",
       "52          correctly predicted no escalation   \n",
       "53          correctly predicted no escalation   \n",
       "60            wrongly predicted no escalation   \n",
       "61          correctly predicted no escalation   \n",
       "62          correctly predicted no escalation   \n",
       "66             correctly predicted escalation   \n",
       "67               wrongly predicted escalation   \n",
       "68               wrongly predicted escalation   \n",
       "\n",
       "    ffnn_classifcation_performance_outcome  \n",
       "0             wrongly predicted escalation  \n",
       "1             wrongly predicted escalation  \n",
       "2        correctly predicted no escalation  \n",
       "3        correctly predicted no escalation  \n",
       "4        correctly predicted no escalation  \n",
       "5        correctly predicted no escalation  \n",
       "9             wrongly predicted escalation  \n",
       "10            wrongly predicted escalation  \n",
       "11          correctly predicted escalation  \n",
       "24            wrongly predicted escalation  \n",
       "25       correctly predicted no escalation  \n",
       "29       correctly predicted no escalation  \n",
       "30       correctly predicted no escalation  \n",
       "31            wrongly predicted escalation  \n",
       "32       correctly predicted no escalation  \n",
       "33       correctly predicted no escalation  \n",
       "34       correctly predicted no escalation  \n",
       "35       correctly predicted no escalation  \n",
       "36            wrongly predicted escalation  \n",
       "37            wrongly predicted escalation  \n",
       "38            wrongly predicted escalation  \n",
       "39            wrongly predicted escalation  \n",
       "40            wrongly predicted escalation  \n",
       "41            wrongly predicted escalation  \n",
       "42          correctly predicted escalation  \n",
       "43            wrongly predicted escalation  \n",
       "44            wrongly predicted escalation  \n",
       "45            wrongly predicted escalation  \n",
       "46            wrongly predicted escalation  \n",
       "47          correctly predicted escalation  \n",
       "51       correctly predicted no escalation  \n",
       "52       correctly predicted no escalation  \n",
       "53       correctly predicted no escalation  \n",
       "60         wrongly predicted no escalation  \n",
       "61       correctly predicted no escalation  \n",
       "62       correctly predicted no escalation  \n",
       "66          correctly predicted escalation  \n",
       "67            wrongly predicted escalation  \n",
       "68            wrongly predicted escalation  \n",
       "\n",
       "[39 rows x 1349 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2 = df[df['wbi_income_group'] == 'Lower middle income']\n",
    "dataerror = data_2['xgboost_probability_prediction_error']\n",
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c5b12fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41025641025641024"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_2.xgboost_classifcation_performance_outcome == 'correctly predicted no escalation').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fdd55ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10256410256410256"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_2.xgboost_classifcation_performance_outcome == 'correctly predicted escalation').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b00abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2615e1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5493496651571941"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1 = df[df['fsi_category'] == 'Warning']\n",
    "dataerror_1 = data_1['xgboost_probability_prediction_error']\n",
    "np.mean(dataerror_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e4fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42224f76",
   "metadata": {},
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "62dee079",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearmonth</th>\n",
       "      <th>fips</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>y_pred_proba_transformer</th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_xgboost</th>\n",
       "      <th>y_pred_proba_xgboost</th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_ffnn</th>\n",
       "      <th>y_pred_proba_ffnn</th>\n",
       "      <th>...</th>\n",
       "      <th>fsi_c1:_security_apparatus</th>\n",
       "      <th>fsi_c2:_factionalized_elites</th>\n",
       "      <th>fsi_x1:_external_intervention</th>\n",
       "      <th>fsi_category</th>\n",
       "      <th>transformer_probability_prediction_error</th>\n",
       "      <th>xgboost_probability_prediction_error</th>\n",
       "      <th>ffnn_probability_prediction_error</th>\n",
       "      <th>transformer_classifcation_performance_outcome</th>\n",
       "      <th>xgboost_classifcation_performance_outcome</th>\n",
       "      <th>ffnn_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>202211</td>\n",
       "      <td>CB</td>\n",
       "      <td>True</td>\n",
       "      <td>0.622624</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.441517</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.394288</td>\n",
       "      <td>...</td>\n",
       "      <td>6.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.622624</td>\n",
       "      <td>0.441517</td>\n",
       "      <td>0.394288</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>202212</td>\n",
       "      <td>CB</td>\n",
       "      <td>False</td>\n",
       "      <td>0.430438</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.495520</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.398258</td>\n",
       "      <td>...</td>\n",
       "      <td>6.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.430438</td>\n",
       "      <td>0.495520</td>\n",
       "      <td>0.398258</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>202211</td>\n",
       "      <td>BM</td>\n",
       "      <td>False</td>\n",
       "      <td>0.444116</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.763934</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.395985</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.444116</td>\n",
       "      <td>0.763934</td>\n",
       "      <td>0.395985</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>202212</td>\n",
       "      <td>BM</td>\n",
       "      <td>False</td>\n",
       "      <td>0.449590</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.758278</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.384911</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.449590</td>\n",
       "      <td>0.758278</td>\n",
       "      <td>0.384911</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>202301</td>\n",
       "      <td>BM</td>\n",
       "      <td>True</td>\n",
       "      <td>0.520781</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.764942</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.380714</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.520781</td>\n",
       "      <td>0.764942</td>\n",
       "      <td>0.380714</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>202211</td>\n",
       "      <td>BG</td>\n",
       "      <td>True</td>\n",
       "      <td>0.619812</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.564092</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.417691</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.619812</td>\n",
       "      <td>0.564092</td>\n",
       "      <td>0.417691</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>202212</td>\n",
       "      <td>BG</td>\n",
       "      <td>True</td>\n",
       "      <td>0.625523</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.552029</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.416145</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.625523</td>\n",
       "      <td>0.552029</td>\n",
       "      <td>0.416145</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>202301</td>\n",
       "      <td>BG</td>\n",
       "      <td>True</td>\n",
       "      <td>0.624302</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.576891</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.428320</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.624302</td>\n",
       "      <td>0.576891</td>\n",
       "      <td>0.428320</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>202211</td>\n",
       "      <td>NP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.541297</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.691555</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.464957</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.458703</td>\n",
       "      <td>0.691555</td>\n",
       "      <td>0.535043</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>202212</td>\n",
       "      <td>NP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.686276</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.668246</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.443688</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.686276</td>\n",
       "      <td>0.668246</td>\n",
       "      <td>0.443688</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>202301</td>\n",
       "      <td>NP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.630345</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.641119</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.521024</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.630345</td>\n",
       "      <td>0.641119</td>\n",
       "      <td>0.521024</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>202211</td>\n",
       "      <td>AF</td>\n",
       "      <td>False</td>\n",
       "      <td>0.357150</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.386776</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.546216</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.357150</td>\n",
       "      <td>0.386776</td>\n",
       "      <td>0.546216</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>202212</td>\n",
       "      <td>AF</td>\n",
       "      <td>True</td>\n",
       "      <td>0.644641</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.533442</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.552699</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.644641</td>\n",
       "      <td>0.533442</td>\n",
       "      <td>0.552699</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>202301</td>\n",
       "      <td>AF</td>\n",
       "      <td>False</td>\n",
       "      <td>0.423742</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.430771</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.551422</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.423742</td>\n",
       "      <td>0.430771</td>\n",
       "      <td>0.551422</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>202211</td>\n",
       "      <td>KG</td>\n",
       "      <td>False</td>\n",
       "      <td>0.448226</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.528620</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.387699</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.448226</td>\n",
       "      <td>0.528620</td>\n",
       "      <td>0.387699</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>202212</td>\n",
       "      <td>KG</td>\n",
       "      <td>False</td>\n",
       "      <td>0.203963</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.457680</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.203963</td>\n",
       "      <td>0.457680</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>202301</td>\n",
       "      <td>KG</td>\n",
       "      <td>False</td>\n",
       "      <td>0.455062</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.450184</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.388959</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.455062</td>\n",
       "      <td>0.450184</td>\n",
       "      <td>0.388959</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>202211</td>\n",
       "      <td>SY</td>\n",
       "      <td>True</td>\n",
       "      <td>0.518751</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.587173</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.537291</td>\n",
       "      <td>...</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.481249</td>\n",
       "      <td>0.587173</td>\n",
       "      <td>0.462709</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>202212</td>\n",
       "      <td>SY</td>\n",
       "      <td>True</td>\n",
       "      <td>0.602737</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.699577</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.541852</td>\n",
       "      <td>...</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.397263</td>\n",
       "      <td>0.699577</td>\n",
       "      <td>0.458148</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>202301</td>\n",
       "      <td>SY</td>\n",
       "      <td>True</td>\n",
       "      <td>0.546697</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.661985</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.534842</td>\n",
       "      <td>...</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.546697</td>\n",
       "      <td>0.661985</td>\n",
       "      <td>0.534842</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>202211</td>\n",
       "      <td>CE</td>\n",
       "      <td>False</td>\n",
       "      <td>0.445699</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.462320</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.355650</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.554301</td>\n",
       "      <td>0.462320</td>\n",
       "      <td>0.644350</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>202212</td>\n",
       "      <td>CE</td>\n",
       "      <td>False</td>\n",
       "      <td>0.305748</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.656604</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.344619</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.305748</td>\n",
       "      <td>0.343396</td>\n",
       "      <td>0.344619</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>202301</td>\n",
       "      <td>CE</td>\n",
       "      <td>False</td>\n",
       "      <td>0.445123</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.596229</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.357513</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.445123</td>\n",
       "      <td>0.596229</td>\n",
       "      <td>0.357513</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23 rows × 1349 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    yearmonth fips  y_pred_transformer  y_pred_proba_transformer  \\\n",
       "24     202211   CB                True                  0.622624   \n",
       "25     202212   CB               False                  0.430438   \n",
       "29     202211   BM               False                  0.444116   \n",
       "30     202212   BM               False                  0.449590   \n",
       "31     202301   BM                True                  0.520781   \n",
       "39     202211   BG                True                  0.619812   \n",
       "40     202212   BG                True                  0.625523   \n",
       "41     202301   BG                True                  0.624302   \n",
       "42     202211   NP                True                  0.541297   \n",
       "43     202212   NP                True                  0.686276   \n",
       "44     202301   NP                True                  0.630345   \n",
       "48     202211   AF               False                  0.357150   \n",
       "49     202212   AF                True                  0.644641   \n",
       "50     202301   AF               False                  0.423742   \n",
       "51     202211   KG               False                  0.448226   \n",
       "52     202212   KG               False                  0.203963   \n",
       "53     202301   KG               False                  0.455062   \n",
       "54     202211   SY                True                  0.518751   \n",
       "55     202212   SY                True                  0.602737   \n",
       "56     202301   SY                True                  0.546697   \n",
       "60     202211   CE               False                  0.445699   \n",
       "61     202212   CE               False                  0.305748   \n",
       "62     202301   CE               False                  0.445123   \n",
       "\n",
       "    y_true_transformer  y_pred_xgboost  y_pred_proba_xgboost  y_true_xgboost  \\\n",
       "24               False           False              0.441517           False   \n",
       "25               False           False              0.495520           False   \n",
       "29               False            True              0.763934           False   \n",
       "30               False            True              0.758278           False   \n",
       "31               False            True              0.764942           False   \n",
       "39               False            True              0.564092           False   \n",
       "40               False            True              0.552029           False   \n",
       "41               False            True              0.576891           False   \n",
       "42                True            True              0.691555           False   \n",
       "43               False            True              0.668246           False   \n",
       "44               False            True              0.641119           False   \n",
       "48               False           False              0.386776           False   \n",
       "49               False            True              0.533442           False   \n",
       "50               False           False              0.430771           False   \n",
       "51               False            True              0.528620           False   \n",
       "52               False           False              0.457680           False   \n",
       "53               False           False              0.450184           False   \n",
       "54                True            True              0.587173           False   \n",
       "55                True            True              0.699577           False   \n",
       "56               False            True              0.661985           False   \n",
       "60                True           False              0.462320           False   \n",
       "61               False            True              0.656604            True   \n",
       "62               False            True              0.596229           False   \n",
       "\n",
       "    y_pred_ffnn  y_pred_proba_ffnn  ...  fsi_c1:_security_apparatus  \\\n",
       "24        False           0.394288  ...                         6.4   \n",
       "25        False           0.398258  ...                         6.4   \n",
       "29        False           0.395985  ...                         9.1   \n",
       "30        False           0.384911  ...                         9.1   \n",
       "31        False           0.380714  ...                         9.1   \n",
       "39        False           0.417691  ...                         6.8   \n",
       "40        False           0.416145  ...                         6.8   \n",
       "41        False           0.428320  ...                         6.8   \n",
       "42        False           0.464957  ...                         5.5   \n",
       "43        False           0.443688  ...                         5.5   \n",
       "44         True           0.521024  ...                         5.5   \n",
       "48         True           0.546216  ...                         9.7   \n",
       "49         True           0.552699  ...                         9.7   \n",
       "50         True           0.551422  ...                         9.7   \n",
       "51        False           0.387699  ...                         5.6   \n",
       "52        False           0.383262  ...                         5.6   \n",
       "53        False           0.388959  ...                         5.6   \n",
       "54         True           0.537291  ...                         9.4   \n",
       "55         True           0.541852  ...                         9.4   \n",
       "56         True           0.534842  ...                         9.4   \n",
       "60        False           0.355650  ...                         6.8   \n",
       "61        False           0.344619  ...                         6.8   \n",
       "62        False           0.357513  ...                         6.8   \n",
       "\n",
       "   fsi_c2:_factionalized_elites  fsi_x1:_external_intervention  fsi_category  \\\n",
       "24                          8.7                            7.0       Warning   \n",
       "25                          8.7                            7.0       Warning   \n",
       "29                          9.0                            7.3         Alert   \n",
       "30                          9.0                            7.3         Alert   \n",
       "31                          9.0                            7.3         Alert   \n",
       "39                          9.3                            4.6       Warning   \n",
       "40                          9.3                            4.6       Warning   \n",
       "41                          9.3                            4.6       Warning   \n",
       "42                          8.8                            5.9       Warning   \n",
       "43                          8.8                            5.9       Warning   \n",
       "44                          8.8                            5.9       Warning   \n",
       "48                          8.7                            7.7         Alert   \n",
       "49                          8.7                            7.7         Alert   \n",
       "50                          8.7                            7.7         Alert   \n",
       "51                          8.2                            6.3       Warning   \n",
       "52                          8.2                            6.3       Warning   \n",
       "53                          8.2                            6.3       Warning   \n",
       "54                          9.9                           10.0         Alert   \n",
       "55                          9.9                           10.0         Alert   \n",
       "56                          9.9                           10.0         Alert   \n",
       "60                          9.1                            7.9         Alert   \n",
       "61                          9.1                            7.9         Alert   \n",
       "62                          9.1                            7.9         Alert   \n",
       "\n",
       "    transformer_probability_prediction_error  \\\n",
       "24                                  0.622624   \n",
       "25                                  0.430438   \n",
       "29                                  0.444116   \n",
       "30                                  0.449590   \n",
       "31                                  0.520781   \n",
       "39                                  0.619812   \n",
       "40                                  0.625523   \n",
       "41                                  0.624302   \n",
       "42                                  0.458703   \n",
       "43                                  0.686276   \n",
       "44                                  0.630345   \n",
       "48                                  0.357150   \n",
       "49                                  0.644641   \n",
       "50                                  0.423742   \n",
       "51                                  0.448226   \n",
       "52                                  0.203963   \n",
       "53                                  0.455062   \n",
       "54                                  0.481249   \n",
       "55                                  0.397263   \n",
       "56                                  0.546697   \n",
       "60                                  0.554301   \n",
       "61                                  0.305748   \n",
       "62                                  0.445123   \n",
       "\n",
       "    xgboost_probability_prediction_error  ffnn_probability_prediction_error  \\\n",
       "24                              0.441517                           0.394288   \n",
       "25                              0.495520                           0.398258   \n",
       "29                              0.763934                           0.395985   \n",
       "30                              0.758278                           0.384911   \n",
       "31                              0.764942                           0.380714   \n",
       "39                              0.564092                           0.417691   \n",
       "40                              0.552029                           0.416145   \n",
       "41                              0.576891                           0.428320   \n",
       "42                              0.691555                           0.535043   \n",
       "43                              0.668246                           0.443688   \n",
       "44                              0.641119                           0.521024   \n",
       "48                              0.386776                           0.546216   \n",
       "49                              0.533442                           0.552699   \n",
       "50                              0.430771                           0.551422   \n",
       "51                              0.528620                           0.387699   \n",
       "52                              0.457680                           0.383262   \n",
       "53                              0.450184                           0.388959   \n",
       "54                              0.587173                           0.462709   \n",
       "55                              0.699577                           0.458148   \n",
       "56                              0.661985                           0.534842   \n",
       "60                              0.462320                           0.644350   \n",
       "61                              0.343396                           0.344619   \n",
       "62                              0.596229                           0.357513   \n",
       "\n",
       "    transformer_classifcation_performance_outcome  \\\n",
       "24                   wrongly predicted escalation   \n",
       "25              correctly predicted no escalation   \n",
       "29              correctly predicted no escalation   \n",
       "30              correctly predicted no escalation   \n",
       "31                   wrongly predicted escalation   \n",
       "39                   wrongly predicted escalation   \n",
       "40                   wrongly predicted escalation   \n",
       "41                   wrongly predicted escalation   \n",
       "42                 correctly predicted escalation   \n",
       "43                   wrongly predicted escalation   \n",
       "44                   wrongly predicted escalation   \n",
       "48              correctly predicted no escalation   \n",
       "49                   wrongly predicted escalation   \n",
       "50              correctly predicted no escalation   \n",
       "51              correctly predicted no escalation   \n",
       "52              correctly predicted no escalation   \n",
       "53              correctly predicted no escalation   \n",
       "54                 correctly predicted escalation   \n",
       "55                 correctly predicted escalation   \n",
       "56                   wrongly predicted escalation   \n",
       "60                wrongly predicted no escalation   \n",
       "61              correctly predicted no escalation   \n",
       "62              correctly predicted no escalation   \n",
       "\n",
       "    xgboost_classifcation_performance_outcome  \\\n",
       "24               wrongly predicted escalation   \n",
       "25          correctly predicted no escalation   \n",
       "29          correctly predicted no escalation   \n",
       "30          correctly predicted no escalation   \n",
       "31               wrongly predicted escalation   \n",
       "39               wrongly predicted escalation   \n",
       "40               wrongly predicted escalation   \n",
       "41               wrongly predicted escalation   \n",
       "42             correctly predicted escalation   \n",
       "43               wrongly predicted escalation   \n",
       "44               wrongly predicted escalation   \n",
       "48          correctly predicted no escalation   \n",
       "49               wrongly predicted escalation   \n",
       "50          correctly predicted no escalation   \n",
       "51          correctly predicted no escalation   \n",
       "52          correctly predicted no escalation   \n",
       "53          correctly predicted no escalation   \n",
       "54             correctly predicted escalation   \n",
       "55             correctly predicted escalation   \n",
       "56               wrongly predicted escalation   \n",
       "60            wrongly predicted no escalation   \n",
       "61          correctly predicted no escalation   \n",
       "62          correctly predicted no escalation   \n",
       "\n",
       "    ffnn_classifcation_performance_outcome  \n",
       "24            wrongly predicted escalation  \n",
       "25       correctly predicted no escalation  \n",
       "29       correctly predicted no escalation  \n",
       "30       correctly predicted no escalation  \n",
       "31            wrongly predicted escalation  \n",
       "39            wrongly predicted escalation  \n",
       "40            wrongly predicted escalation  \n",
       "41            wrongly predicted escalation  \n",
       "42          correctly predicted escalation  \n",
       "43            wrongly predicted escalation  \n",
       "44            wrongly predicted escalation  \n",
       "48       correctly predicted no escalation  \n",
       "49            wrongly predicted escalation  \n",
       "50       correctly predicted no escalation  \n",
       "51       correctly predicted no escalation  \n",
       "52       correctly predicted no escalation  \n",
       "53       correctly predicted no escalation  \n",
       "54          correctly predicted escalation  \n",
       "55          correctly predicted escalation  \n",
       "56            wrongly predicted escalation  \n",
       "60         wrongly predicted no escalation  \n",
       "61       correctly predicted no escalation  \n",
       "62       correctly predicted no escalation  \n",
       "\n",
       "[23 rows x 1349 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformer\n",
    "data_1 = df[df['wbi_lending_category'] == 'IDA']\n",
    "dataerror_1 = data_1['transformer_probability_prediction_error']\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0ee7b25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43478260869565216"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_1.transformer_classifcation_performance_outcome == 'correctly predicted no escalation').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f1f000d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13043478260869565"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_1.transformer_classifcation_performance_outcome == 'correctly predicted escalation').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9a14f4db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearmonth</th>\n",
       "      <th>fips</th>\n",
       "      <th>y_pred_transformer</th>\n",
       "      <th>y_pred_proba_transformer</th>\n",
       "      <th>y_true_transformer</th>\n",
       "      <th>y_pred_xgboost</th>\n",
       "      <th>y_pred_proba_xgboost</th>\n",
       "      <th>y_true_xgboost</th>\n",
       "      <th>y_pred_ffnn</th>\n",
       "      <th>y_pred_proba_ffnn</th>\n",
       "      <th>...</th>\n",
       "      <th>fsi_c1:_security_apparatus</th>\n",
       "      <th>fsi_c2:_factionalized_elites</th>\n",
       "      <th>fsi_x1:_external_intervention</th>\n",
       "      <th>fsi_category</th>\n",
       "      <th>transformer_probability_prediction_error</th>\n",
       "      <th>xgboost_probability_prediction_error</th>\n",
       "      <th>ffnn_probability_prediction_error</th>\n",
       "      <th>transformer_classifcation_performance_outcome</th>\n",
       "      <th>xgboost_classifcation_performance_outcome</th>\n",
       "      <th>ffnn_classifcation_performance_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202211</td>\n",
       "      <td>UZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.535385</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.660580</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.381938</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.535385</td>\n",
       "      <td>0.660580</td>\n",
       "      <td>0.381938</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202212</td>\n",
       "      <td>UZ</td>\n",
       "      <td>True</td>\n",
       "      <td>0.538211</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.579952</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.364793</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.538211</td>\n",
       "      <td>0.579952</td>\n",
       "      <td>0.364793</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202301</td>\n",
       "      <td>UZ</td>\n",
       "      <td>False</td>\n",
       "      <td>0.204810</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.652542</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.364343</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.204810</td>\n",
       "      <td>0.652542</td>\n",
       "      <td>0.364343</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202211</td>\n",
       "      <td>IS</td>\n",
       "      <td>True</td>\n",
       "      <td>0.634716</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.738002</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.343657</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.634716</td>\n",
       "      <td>0.738002</td>\n",
       "      <td>0.343657</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202212</td>\n",
       "      <td>IS</td>\n",
       "      <td>True</td>\n",
       "      <td>0.692216</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.711610</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.341547</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.307784</td>\n",
       "      <td>0.711610</td>\n",
       "      <td>0.658453</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202301</td>\n",
       "      <td>IS</td>\n",
       "      <td>True</td>\n",
       "      <td>0.687682</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.608835</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.344979</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.687682</td>\n",
       "      <td>0.391165</td>\n",
       "      <td>0.344979</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>202211</td>\n",
       "      <td>QA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.176723</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.070106</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.274388</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.176723</td>\n",
       "      <td>0.070106</td>\n",
       "      <td>0.274388</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>202212</td>\n",
       "      <td>QA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.177739</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.064143</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.271447</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.177739</td>\n",
       "      <td>0.064143</td>\n",
       "      <td>0.271447</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>202211</td>\n",
       "      <td>KU</td>\n",
       "      <td>False</td>\n",
       "      <td>0.174353</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.075832</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.322281</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.174353</td>\n",
       "      <td>0.075832</td>\n",
       "      <td>0.322281</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>202212</td>\n",
       "      <td>KU</td>\n",
       "      <td>False</td>\n",
       "      <td>0.189701</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.074495</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.323783</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.189701</td>\n",
       "      <td>0.074495</td>\n",
       "      <td>0.323783</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>202211</td>\n",
       "      <td>MU</td>\n",
       "      <td>False</td>\n",
       "      <td>0.243252</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.100111</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.318327</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.243252</td>\n",
       "      <td>0.100111</td>\n",
       "      <td>0.318327</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>202212</td>\n",
       "      <td>MU</td>\n",
       "      <td>False</td>\n",
       "      <td>0.273943</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.129337</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.321544</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.273943</td>\n",
       "      <td>0.129337</td>\n",
       "      <td>0.321544</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>202211</td>\n",
       "      <td>CB</td>\n",
       "      <td>True</td>\n",
       "      <td>0.622624</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.441517</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.394288</td>\n",
       "      <td>...</td>\n",
       "      <td>6.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.622624</td>\n",
       "      <td>0.441517</td>\n",
       "      <td>0.394288</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>202212</td>\n",
       "      <td>CB</td>\n",
       "      <td>False</td>\n",
       "      <td>0.430438</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.495520</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.398258</td>\n",
       "      <td>...</td>\n",
       "      <td>6.4</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.430438</td>\n",
       "      <td>0.495520</td>\n",
       "      <td>0.398258</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>202211</td>\n",
       "      <td>BM</td>\n",
       "      <td>False</td>\n",
       "      <td>0.444116</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.763934</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.395985</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.444116</td>\n",
       "      <td>0.763934</td>\n",
       "      <td>0.395985</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>202212</td>\n",
       "      <td>BM</td>\n",
       "      <td>False</td>\n",
       "      <td>0.449590</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.758278</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.384911</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.449590</td>\n",
       "      <td>0.758278</td>\n",
       "      <td>0.384911</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>202301</td>\n",
       "      <td>BM</td>\n",
       "      <td>True</td>\n",
       "      <td>0.520781</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.764942</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.380714</td>\n",
       "      <td>...</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.520781</td>\n",
       "      <td>0.764942</td>\n",
       "      <td>0.380714</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>202211</td>\n",
       "      <td>BG</td>\n",
       "      <td>True</td>\n",
       "      <td>0.619812</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.564092</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.417691</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.619812</td>\n",
       "      <td>0.564092</td>\n",
       "      <td>0.417691</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>202212</td>\n",
       "      <td>BG</td>\n",
       "      <td>True</td>\n",
       "      <td>0.625523</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.552029</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.416145</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.625523</td>\n",
       "      <td>0.552029</td>\n",
       "      <td>0.416145</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>202301</td>\n",
       "      <td>BG</td>\n",
       "      <td>True</td>\n",
       "      <td>0.624302</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.576891</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.428320</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.624302</td>\n",
       "      <td>0.576891</td>\n",
       "      <td>0.428320</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>202211</td>\n",
       "      <td>NP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.541297</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.691555</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.464957</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.458703</td>\n",
       "      <td>0.691555</td>\n",
       "      <td>0.535043</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>202212</td>\n",
       "      <td>NP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.686276</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.668246</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.443688</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.686276</td>\n",
       "      <td>0.668246</td>\n",
       "      <td>0.443688</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>202301</td>\n",
       "      <td>NP</td>\n",
       "      <td>True</td>\n",
       "      <td>0.630345</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.641119</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.521024</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.630345</td>\n",
       "      <td>0.641119</td>\n",
       "      <td>0.521024</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>202211</td>\n",
       "      <td>PK</td>\n",
       "      <td>True</td>\n",
       "      <td>0.792848</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.741170</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.506878</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.792848</td>\n",
       "      <td>0.258830</td>\n",
       "      <td>0.506878</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>202212</td>\n",
       "      <td>PK</td>\n",
       "      <td>True</td>\n",
       "      <td>0.732578</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.704396</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.512946</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.732578</td>\n",
       "      <td>0.704396</td>\n",
       "      <td>0.512946</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>202301</td>\n",
       "      <td>PK</td>\n",
       "      <td>True</td>\n",
       "      <td>0.756767</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.686989</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.509882</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.243233</td>\n",
       "      <td>0.686989</td>\n",
       "      <td>0.490118</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>202211</td>\n",
       "      <td>AF</td>\n",
       "      <td>False</td>\n",
       "      <td>0.357150</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.386776</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.546216</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.357150</td>\n",
       "      <td>0.386776</td>\n",
       "      <td>0.546216</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>202212</td>\n",
       "      <td>AF</td>\n",
       "      <td>True</td>\n",
       "      <td>0.644641</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.533442</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.552699</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.644641</td>\n",
       "      <td>0.533442</td>\n",
       "      <td>0.552699</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>202301</td>\n",
       "      <td>AF</td>\n",
       "      <td>False</td>\n",
       "      <td>0.423742</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.430771</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.551422</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.423742</td>\n",
       "      <td>0.430771</td>\n",
       "      <td>0.551422</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>202211</td>\n",
       "      <td>KG</td>\n",
       "      <td>False</td>\n",
       "      <td>0.448226</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.528620</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.387699</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.448226</td>\n",
       "      <td>0.528620</td>\n",
       "      <td>0.387699</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>202212</td>\n",
       "      <td>KG</td>\n",
       "      <td>False</td>\n",
       "      <td>0.203963</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.457680</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.203963</td>\n",
       "      <td>0.457680</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>202301</td>\n",
       "      <td>KG</td>\n",
       "      <td>False</td>\n",
       "      <td>0.455062</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.450184</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.388959</td>\n",
       "      <td>...</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.455062</td>\n",
       "      <td>0.450184</td>\n",
       "      <td>0.388959</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>202211</td>\n",
       "      <td>SY</td>\n",
       "      <td>True</td>\n",
       "      <td>0.518751</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.587173</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.537291</td>\n",
       "      <td>...</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.481249</td>\n",
       "      <td>0.587173</td>\n",
       "      <td>0.462709</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>202212</td>\n",
       "      <td>SY</td>\n",
       "      <td>True</td>\n",
       "      <td>0.602737</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.699577</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.541852</td>\n",
       "      <td>...</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.397263</td>\n",
       "      <td>0.699577</td>\n",
       "      <td>0.458148</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "      <td>correctly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>202301</td>\n",
       "      <td>SY</td>\n",
       "      <td>True</td>\n",
       "      <td>0.546697</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.661985</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.534842</td>\n",
       "      <td>...</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.546697</td>\n",
       "      <td>0.661985</td>\n",
       "      <td>0.534842</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "      <td>wrongly predicted escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>202211</td>\n",
       "      <td>CE</td>\n",
       "      <td>False</td>\n",
       "      <td>0.445699</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.462320</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.355650</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.554301</td>\n",
       "      <td>0.462320</td>\n",
       "      <td>0.644350</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>202212</td>\n",
       "      <td>CE</td>\n",
       "      <td>False</td>\n",
       "      <td>0.305748</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.656604</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.344619</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.305748</td>\n",
       "      <td>0.343396</td>\n",
       "      <td>0.344619</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>202301</td>\n",
       "      <td>CE</td>\n",
       "      <td>False</td>\n",
       "      <td>0.445123</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.596229</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.357513</td>\n",
       "      <td>...</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Alert</td>\n",
       "      <td>0.445123</td>\n",
       "      <td>0.596229</td>\n",
       "      <td>0.357513</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>202211</td>\n",
       "      <td>JA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.163859</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.205914</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.273060</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.163859</td>\n",
       "      <td>0.205914</td>\n",
       "      <td>0.273060</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>202212</td>\n",
       "      <td>JA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.191392</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.209022</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.272838</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Stable</td>\n",
       "      <td>0.191392</td>\n",
       "      <td>0.209022</td>\n",
       "      <td>0.272838</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>202211</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.450048</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.495618</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.365198</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.450048</td>\n",
       "      <td>0.504382</td>\n",
       "      <td>0.365198</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>202212</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.443690</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.428008</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.366745</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.443690</td>\n",
       "      <td>0.428008</td>\n",
       "      <td>0.366745</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "      <td>correctly predicted no escalation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>202301</td>\n",
       "      <td>SA</td>\n",
       "      <td>False</td>\n",
       "      <td>0.315053</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.618117</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.367574</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>Warning</td>\n",
       "      <td>0.684947</td>\n",
       "      <td>0.618117</td>\n",
       "      <td>0.632426</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "      <td>wrongly predicted no escalation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43 rows × 1349 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    yearmonth fips  y_pred_transformer  y_pred_proba_transformer  \\\n",
       "0      202211   UZ                True                  0.535385   \n",
       "1      202212   UZ                True                  0.538211   \n",
       "2      202301   UZ               False                  0.204810   \n",
       "6      202211   IS                True                  0.634716   \n",
       "7      202212   IS                True                  0.692216   \n",
       "8      202301   IS                True                  0.687682   \n",
       "15     202211   QA               False                  0.176723   \n",
       "16     202212   QA               False                  0.177739   \n",
       "17     202211   KU               False                  0.174353   \n",
       "18     202212   KU               False                  0.189701   \n",
       "22     202211   MU               False                  0.243252   \n",
       "23     202212   MU               False                  0.273943   \n",
       "24     202211   CB                True                  0.622624   \n",
       "25     202212   CB               False                  0.430438   \n",
       "29     202211   BM               False                  0.444116   \n",
       "30     202212   BM               False                  0.449590   \n",
       "31     202301   BM                True                  0.520781   \n",
       "39     202211   BG                True                  0.619812   \n",
       "40     202212   BG                True                  0.625523   \n",
       "41     202301   BG                True                  0.624302   \n",
       "42     202211   NP                True                  0.541297   \n",
       "43     202212   NP                True                  0.686276   \n",
       "44     202301   NP                True                  0.630345   \n",
       "45     202211   PK                True                  0.792848   \n",
       "46     202212   PK                True                  0.732578   \n",
       "47     202301   PK                True                  0.756767   \n",
       "48     202211   AF               False                  0.357150   \n",
       "49     202212   AF                True                  0.644641   \n",
       "50     202301   AF               False                  0.423742   \n",
       "51     202211   KG               False                  0.448226   \n",
       "52     202212   KG               False                  0.203963   \n",
       "53     202301   KG               False                  0.455062   \n",
       "54     202211   SY                True                  0.518751   \n",
       "55     202212   SY                True                  0.602737   \n",
       "56     202301   SY                True                  0.546697   \n",
       "60     202211   CE               False                  0.445699   \n",
       "61     202212   CE               False                  0.305748   \n",
       "62     202301   CE               False                  0.445123   \n",
       "71     202211   JA               False                  0.163859   \n",
       "72     202212   JA               False                  0.191392   \n",
       "73     202211   SA               False                  0.450048   \n",
       "74     202212   SA               False                  0.443690   \n",
       "75     202301   SA               False                  0.315053   \n",
       "\n",
       "    y_true_transformer  y_pred_xgboost  y_pred_proba_xgboost  y_true_xgboost  \\\n",
       "0                False            True              0.660580           False   \n",
       "1                False            True              0.579952           False   \n",
       "2                False            True              0.652542           False   \n",
       "6                False            True              0.738002           False   \n",
       "7                 True            True              0.711610           False   \n",
       "8                False            True              0.608835            True   \n",
       "15               False           False              0.070106           False   \n",
       "16               False           False              0.064143           False   \n",
       "17               False           False              0.075832           False   \n",
       "18               False           False              0.074495           False   \n",
       "22               False           False              0.100111           False   \n",
       "23               False           False              0.129337           False   \n",
       "24               False           False              0.441517           False   \n",
       "25               False           False              0.495520           False   \n",
       "29               False            True              0.763934           False   \n",
       "30               False            True              0.758278           False   \n",
       "31               False            True              0.764942           False   \n",
       "39               False            True              0.564092           False   \n",
       "40               False            True              0.552029           False   \n",
       "41               False            True              0.576891           False   \n",
       "42                True            True              0.691555           False   \n",
       "43               False            True              0.668246           False   \n",
       "44               False            True              0.641119           False   \n",
       "45               False            True              0.741170            True   \n",
       "46               False            True              0.704396           False   \n",
       "47                True            True              0.686989           False   \n",
       "48               False           False              0.386776           False   \n",
       "49               False            True              0.533442           False   \n",
       "50               False           False              0.430771           False   \n",
       "51               False            True              0.528620           False   \n",
       "52               False           False              0.457680           False   \n",
       "53               False           False              0.450184           False   \n",
       "54                True            True              0.587173           False   \n",
       "55                True            True              0.699577           False   \n",
       "56               False            True              0.661985           False   \n",
       "60                True           False              0.462320           False   \n",
       "61               False            True              0.656604            True   \n",
       "62               False            True              0.596229           False   \n",
       "71               False           False              0.205914           False   \n",
       "72               False           False              0.209022           False   \n",
       "73               False           False              0.495618            True   \n",
       "74               False           False              0.428008           False   \n",
       "75                True            True              0.618117           False   \n",
       "\n",
       "    y_pred_ffnn  y_pred_proba_ffnn  ...  fsi_c1:_security_apparatus  \\\n",
       "0         False           0.381938  ...                         5.6   \n",
       "1         False           0.364793  ...                         5.6   \n",
       "2         False           0.364343  ...                         5.6   \n",
       "6         False           0.343657  ...                         2.6   \n",
       "7         False           0.341547  ...                         2.6   \n",
       "8         False           0.344979  ...                         2.6   \n",
       "15        False           0.274388  ...                         1.0   \n",
       "16        False           0.271447  ...                         1.0   \n",
       "17        False           0.322281  ...                         2.4   \n",
       "18        False           0.323783  ...                         2.4   \n",
       "22        False           0.318327  ...                         2.4   \n",
       "23        False           0.321544  ...                         2.4   \n",
       "24        False           0.394288  ...                         6.4   \n",
       "25        False           0.398258  ...                         6.4   \n",
       "29        False           0.395985  ...                         9.1   \n",
       "30        False           0.384911  ...                         9.1   \n",
       "31        False           0.380714  ...                         9.1   \n",
       "39        False           0.417691  ...                         6.8   \n",
       "40        False           0.416145  ...                         6.8   \n",
       "41        False           0.428320  ...                         6.8   \n",
       "42        False           0.464957  ...                         5.5   \n",
       "43        False           0.443688  ...                         5.5   \n",
       "44         True           0.521024  ...                         5.5   \n",
       "45         True           0.506878  ...                         7.6   \n",
       "46         True           0.512946  ...                         7.6   \n",
       "47         True           0.509882  ...                         7.6   \n",
       "48         True           0.546216  ...                         9.7   \n",
       "49         True           0.552699  ...                         9.7   \n",
       "50         True           0.551422  ...                         9.7   \n",
       "51        False           0.387699  ...                         5.6   \n",
       "52        False           0.383262  ...                         5.6   \n",
       "53        False           0.388959  ...                         5.6   \n",
       "54         True           0.537291  ...                         9.4   \n",
       "55         True           0.541852  ...                         9.4   \n",
       "56         True           0.534842  ...                         9.4   \n",
       "60        False           0.355650  ...                         6.8   \n",
       "61        False           0.344619  ...                         6.8   \n",
       "62        False           0.357513  ...                         6.8   \n",
       "71        False           0.273060  ...                         1.5   \n",
       "72        False           0.272838  ...                         1.5   \n",
       "73        False           0.365198  ...                         5.1   \n",
       "74        False           0.366745  ...                         5.1   \n",
       "75        False           0.367574  ...                         5.1   \n",
       "\n",
       "   fsi_c2:_factionalized_elites  fsi_x1:_external_intervention  fsi_category  \\\n",
       "0                           8.8                            3.4       Warning   \n",
       "1                           8.8                            3.4       Warning   \n",
       "2                           8.8                            3.4       Warning   \n",
       "6                           8.3                            4.8        Stable   \n",
       "7                           8.3                            4.8        Stable   \n",
       "8                           8.3                            4.8        Stable   \n",
       "15                          5.0                            5.7        Stable   \n",
       "16                          5.0                            5.7        Stable   \n",
       "17                          7.5                            3.0        Stable   \n",
       "18                          7.5                            3.0        Stable   \n",
       "22                          6.6                            4.1        Stable   \n",
       "23                          6.6                            4.1        Stable   \n",
       "24                          8.7                            7.0       Warning   \n",
       "25                          8.7                            7.0       Warning   \n",
       "29                          9.0                            7.3         Alert   \n",
       "30                          9.0                            7.3         Alert   \n",
       "31                          9.0                            7.3         Alert   \n",
       "39                          9.3                            4.6       Warning   \n",
       "40                          9.3                            4.6       Warning   \n",
       "41                          9.3                            4.6       Warning   \n",
       "42                          8.8                            5.9       Warning   \n",
       "43                          8.8                            5.9       Warning   \n",
       "44                          8.8                            5.9       Warning   \n",
       "45                          9.3                            8.3       Warning   \n",
       "46                          9.3                            8.3       Warning   \n",
       "47                          9.3                            8.3       Warning   \n",
       "48                          8.7                            7.7         Alert   \n",
       "49                          8.7                            7.7         Alert   \n",
       "50                          8.7                            7.7         Alert   \n",
       "51                          8.2                            6.3       Warning   \n",
       "52                          8.2                            6.3       Warning   \n",
       "53                          8.2                            6.3       Warning   \n",
       "54                          9.9                           10.0         Alert   \n",
       "55                          9.9                           10.0         Alert   \n",
       "56                          9.9                           10.0         Alert   \n",
       "60                          9.1                            7.9         Alert   \n",
       "61                          9.1                            7.9         Alert   \n",
       "62                          9.1                            7.9         Alert   \n",
       "71                          2.6                            2.0        Stable   \n",
       "72                          2.6                            2.0        Stable   \n",
       "73                          8.5                            4.1       Warning   \n",
       "74                          8.5                            4.1       Warning   \n",
       "75                          8.5                            4.1       Warning   \n",
       "\n",
       "    transformer_probability_prediction_error  \\\n",
       "0                                   0.535385   \n",
       "1                                   0.538211   \n",
       "2                                   0.204810   \n",
       "6                                   0.634716   \n",
       "7                                   0.307784   \n",
       "8                                   0.687682   \n",
       "15                                  0.176723   \n",
       "16                                  0.177739   \n",
       "17                                  0.174353   \n",
       "18                                  0.189701   \n",
       "22                                  0.243252   \n",
       "23                                  0.273943   \n",
       "24                                  0.622624   \n",
       "25                                  0.430438   \n",
       "29                                  0.444116   \n",
       "30                                  0.449590   \n",
       "31                                  0.520781   \n",
       "39                                  0.619812   \n",
       "40                                  0.625523   \n",
       "41                                  0.624302   \n",
       "42                                  0.458703   \n",
       "43                                  0.686276   \n",
       "44                                  0.630345   \n",
       "45                                  0.792848   \n",
       "46                                  0.732578   \n",
       "47                                  0.243233   \n",
       "48                                  0.357150   \n",
       "49                                  0.644641   \n",
       "50                                  0.423742   \n",
       "51                                  0.448226   \n",
       "52                                  0.203963   \n",
       "53                                  0.455062   \n",
       "54                                  0.481249   \n",
       "55                                  0.397263   \n",
       "56                                  0.546697   \n",
       "60                                  0.554301   \n",
       "61                                  0.305748   \n",
       "62                                  0.445123   \n",
       "71                                  0.163859   \n",
       "72                                  0.191392   \n",
       "73                                  0.450048   \n",
       "74                                  0.443690   \n",
       "75                                  0.684947   \n",
       "\n",
       "    xgboost_probability_prediction_error  ffnn_probability_prediction_error  \\\n",
       "0                               0.660580                           0.381938   \n",
       "1                               0.579952                           0.364793   \n",
       "2                               0.652542                           0.364343   \n",
       "6                               0.738002                           0.343657   \n",
       "7                               0.711610                           0.658453   \n",
       "8                               0.391165                           0.344979   \n",
       "15                              0.070106                           0.274388   \n",
       "16                              0.064143                           0.271447   \n",
       "17                              0.075832                           0.322281   \n",
       "18                              0.074495                           0.323783   \n",
       "22                              0.100111                           0.318327   \n",
       "23                              0.129337                           0.321544   \n",
       "24                              0.441517                           0.394288   \n",
       "25                              0.495520                           0.398258   \n",
       "29                              0.763934                           0.395985   \n",
       "30                              0.758278                           0.384911   \n",
       "31                              0.764942                           0.380714   \n",
       "39                              0.564092                           0.417691   \n",
       "40                              0.552029                           0.416145   \n",
       "41                              0.576891                           0.428320   \n",
       "42                              0.691555                           0.535043   \n",
       "43                              0.668246                           0.443688   \n",
       "44                              0.641119                           0.521024   \n",
       "45                              0.258830                           0.506878   \n",
       "46                              0.704396                           0.512946   \n",
       "47                              0.686989                           0.490118   \n",
       "48                              0.386776                           0.546216   \n",
       "49                              0.533442                           0.552699   \n",
       "50                              0.430771                           0.551422   \n",
       "51                              0.528620                           0.387699   \n",
       "52                              0.457680                           0.383262   \n",
       "53                              0.450184                           0.388959   \n",
       "54                              0.587173                           0.462709   \n",
       "55                              0.699577                           0.458148   \n",
       "56                              0.661985                           0.534842   \n",
       "60                              0.462320                           0.644350   \n",
       "61                              0.343396                           0.344619   \n",
       "62                              0.596229                           0.357513   \n",
       "71                              0.205914                           0.273060   \n",
       "72                              0.209022                           0.272838   \n",
       "73                              0.504382                           0.365198   \n",
       "74                              0.428008                           0.366745   \n",
       "75                              0.618117                           0.632426   \n",
       "\n",
       "    transformer_classifcation_performance_outcome  \\\n",
       "0                    wrongly predicted escalation   \n",
       "1                    wrongly predicted escalation   \n",
       "2               correctly predicted no escalation   \n",
       "6                    wrongly predicted escalation   \n",
       "7                  correctly predicted escalation   \n",
       "8                    wrongly predicted escalation   \n",
       "15              correctly predicted no escalation   \n",
       "16              correctly predicted no escalation   \n",
       "17              correctly predicted no escalation   \n",
       "18              correctly predicted no escalation   \n",
       "22              correctly predicted no escalation   \n",
       "23              correctly predicted no escalation   \n",
       "24                   wrongly predicted escalation   \n",
       "25              correctly predicted no escalation   \n",
       "29              correctly predicted no escalation   \n",
       "30              correctly predicted no escalation   \n",
       "31                   wrongly predicted escalation   \n",
       "39                   wrongly predicted escalation   \n",
       "40                   wrongly predicted escalation   \n",
       "41                   wrongly predicted escalation   \n",
       "42                 correctly predicted escalation   \n",
       "43                   wrongly predicted escalation   \n",
       "44                   wrongly predicted escalation   \n",
       "45                   wrongly predicted escalation   \n",
       "46                   wrongly predicted escalation   \n",
       "47                 correctly predicted escalation   \n",
       "48              correctly predicted no escalation   \n",
       "49                   wrongly predicted escalation   \n",
       "50              correctly predicted no escalation   \n",
       "51              correctly predicted no escalation   \n",
       "52              correctly predicted no escalation   \n",
       "53              correctly predicted no escalation   \n",
       "54                 correctly predicted escalation   \n",
       "55                 correctly predicted escalation   \n",
       "56                   wrongly predicted escalation   \n",
       "60                wrongly predicted no escalation   \n",
       "61              correctly predicted no escalation   \n",
       "62              correctly predicted no escalation   \n",
       "71              correctly predicted no escalation   \n",
       "72              correctly predicted no escalation   \n",
       "73              correctly predicted no escalation   \n",
       "74              correctly predicted no escalation   \n",
       "75                wrongly predicted no escalation   \n",
       "\n",
       "    xgboost_classifcation_performance_outcome  \\\n",
       "0                wrongly predicted escalation   \n",
       "1                wrongly predicted escalation   \n",
       "2           correctly predicted no escalation   \n",
       "6                wrongly predicted escalation   \n",
       "7              correctly predicted escalation   \n",
       "8                wrongly predicted escalation   \n",
       "15          correctly predicted no escalation   \n",
       "16          correctly predicted no escalation   \n",
       "17          correctly predicted no escalation   \n",
       "18          correctly predicted no escalation   \n",
       "22          correctly predicted no escalation   \n",
       "23          correctly predicted no escalation   \n",
       "24               wrongly predicted escalation   \n",
       "25          correctly predicted no escalation   \n",
       "29          correctly predicted no escalation   \n",
       "30          correctly predicted no escalation   \n",
       "31               wrongly predicted escalation   \n",
       "39               wrongly predicted escalation   \n",
       "40               wrongly predicted escalation   \n",
       "41               wrongly predicted escalation   \n",
       "42             correctly predicted escalation   \n",
       "43               wrongly predicted escalation   \n",
       "44               wrongly predicted escalation   \n",
       "45               wrongly predicted escalation   \n",
       "46               wrongly predicted escalation   \n",
       "47             correctly predicted escalation   \n",
       "48          correctly predicted no escalation   \n",
       "49               wrongly predicted escalation   \n",
       "50          correctly predicted no escalation   \n",
       "51          correctly predicted no escalation   \n",
       "52          correctly predicted no escalation   \n",
       "53          correctly predicted no escalation   \n",
       "54             correctly predicted escalation   \n",
       "55             correctly predicted escalation   \n",
       "56               wrongly predicted escalation   \n",
       "60            wrongly predicted no escalation   \n",
       "61          correctly predicted no escalation   \n",
       "62          correctly predicted no escalation   \n",
       "71          correctly predicted no escalation   \n",
       "72          correctly predicted no escalation   \n",
       "73          correctly predicted no escalation   \n",
       "74          correctly predicted no escalation   \n",
       "75            wrongly predicted no escalation   \n",
       "\n",
       "    ffnn_classifcation_performance_outcome  \n",
       "0             wrongly predicted escalation  \n",
       "1             wrongly predicted escalation  \n",
       "2        correctly predicted no escalation  \n",
       "6             wrongly predicted escalation  \n",
       "7           correctly predicted escalation  \n",
       "8             wrongly predicted escalation  \n",
       "15       correctly predicted no escalation  \n",
       "16       correctly predicted no escalation  \n",
       "17       correctly predicted no escalation  \n",
       "18       correctly predicted no escalation  \n",
       "22       correctly predicted no escalation  \n",
       "23       correctly predicted no escalation  \n",
       "24            wrongly predicted escalation  \n",
       "25       correctly predicted no escalation  \n",
       "29       correctly predicted no escalation  \n",
       "30       correctly predicted no escalation  \n",
       "31            wrongly predicted escalation  \n",
       "39            wrongly predicted escalation  \n",
       "40            wrongly predicted escalation  \n",
       "41            wrongly predicted escalation  \n",
       "42          correctly predicted escalation  \n",
       "43            wrongly predicted escalation  \n",
       "44            wrongly predicted escalation  \n",
       "45            wrongly predicted escalation  \n",
       "46            wrongly predicted escalation  \n",
       "47          correctly predicted escalation  \n",
       "48       correctly predicted no escalation  \n",
       "49            wrongly predicted escalation  \n",
       "50       correctly predicted no escalation  \n",
       "51       correctly predicted no escalation  \n",
       "52       correctly predicted no escalation  \n",
       "53       correctly predicted no escalation  \n",
       "54          correctly predicted escalation  \n",
       "55          correctly predicted escalation  \n",
       "56            wrongly predicted escalation  \n",
       "60         wrongly predicted no escalation  \n",
       "61       correctly predicted no escalation  \n",
       "62       correctly predicted no escalation  \n",
       "71       correctly predicted no escalation  \n",
       "72       correctly predicted no escalation  \n",
       "73       correctly predicted no escalation  \n",
       "74       correctly predicted no escalation  \n",
       "75         wrongly predicted no escalation  \n",
       "\n",
       "[43 rows x 1349 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2 = df[df['wbi_lending_category'] != 'IBRD']\n",
    "dataerror = data_2['transformer_probability_prediction_error']\n",
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9f01576f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3488372093023256"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_2.transformer_classifcation_performance_outcome == 'wrongly predicted escalation').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8746bf6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046511627906976744"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_2.transformer_classifcation_performance_outcome == 'wrongly predicted no escalation').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f28128ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "79dfdfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5253960597560975"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1 = df[df['fsi_category'] == 'Warning']\n",
    "dataerror_1 = data_1['transformer_probability_prediction_error']\n",
    "np.mean(dataerror_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f3f997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "991212bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39704471, 0.43680252])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ffnn bootstrap error\n",
    "data = df['ffnn_probability_prediction_error']\n",
    "bootstrap = []\n",
    "rep = 1000\n",
    "for i in range(rep):\n",
    "    bootstrap += [(np.random.choice(data,size = 76, replace = True)).mean()]\n",
    "\n",
    "confience_interval = np.quantile(bootstrap,[0.05,0.95])\n",
    "confience_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e221b995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45558976, 0.52770672])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgboost bootstrap error\n",
    "data = df['xgboost_probability_prediction_error']\n",
    "bootstrap = []\n",
    "rep = 1000\n",
    "for i in range(rep):\n",
    "    bootstrap += [(np.random.choice(data,size = 76, replace = True)).mean()]\n",
    "\n",
    "confience_interval = np.quantile(bootstrap,[0.05,0.95])\n",
    "confience_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b2995327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44061906, 0.50874468])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformer bootstrap error\n",
    "data = df['transformer_probability_prediction_error']\n",
    "bootstrap = []\n",
    "rep = 1000\n",
    "for i in range(rep):\n",
    "    bootstrap += [(np.random.choice(data,size = 76, replace = True)).mean()]\n",
    "\n",
    "confience_interval = np.quantile(bootstrap,[0.05,0.95])\n",
    "confience_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ee0389",
   "metadata": {},
   "source": [
    "# Step4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3f2dfd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00108323 0.06286678]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "reps = 1000\n",
    "rep = 1000\n",
    "bootstrap_differences = np.zeros(rep)\n",
    "group1 = df[df.fsi_category == 'Warning']['ffnn_probability_prediction_error']\n",
    "group2 = df[df.fsi_category != 'Warning']['ffnn_probability_prediction_error']\n",
    "for i in range(rep):\n",
    "    sample1 = group1.sample(41, replace=True)\n",
    "    sample2 = group2.sample(35, replace=True)\n",
    "    difference = sample1.mean() - sample2.mean()\n",
    "    bootstrap_differences[i] = abs(difference)\n",
    "confidence_interval = np.percentile(bootstrap_differences, [2.5, 97.5])\n",
    "print(confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e3105d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03057455 0.18677983]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "reps = 1000\n",
    "rep = 1000\n",
    "bootstrap_differences = np.zeros(rep)\n",
    "group1 = df[df.fsi_category == 'Warning']['transformer_probability_prediction_error']\n",
    "group2 = df[df.fsi_category != 'Warning']['transformer_probability_prediction_error']\n",
    "for i in range(rep):\n",
    "    sample1 = group1.sample(41, replace=True)\n",
    "    sample2 = group2.sample(35, replace=True)\n",
    "    difference = sample1.mean() - sample2.mean()\n",
    "    bootstrap_differences[i] = abs(difference)\n",
    "confidence_interval = np.percentile(bootstrap_differences, [2.5, 97.5])\n",
    "print(confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "916cba30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02933472 0.21934281]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "reps = 1000\n",
    "rep = 1000\n",
    "bootstrap_differences = np.zeros(rep)\n",
    "group1 = df[df.fsi_category == 'Warning']['xgboost_probability_prediction_error']\n",
    "group2 = df[df.fsi_category != 'Warning']['xgboost_probability_prediction_error']\n",
    "for i in range(rep):\n",
    "    sample1 = group1.sample(41, replace=True)\n",
    "    sample2 = group2.sample(35, replace=True)\n",
    "    difference = sample1.mean() - sample2.mean()\n",
    "    bootstrap_differences[i] = abs(difference)\n",
    "confidence_interval = np.percentile(bootstrap_differences, [2.5, 97.5])\n",
    "print(confidence_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b47761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
